key,title,description,type,text
JENA-413,Illegal serialization of null xsd:duration,"XSDDuration.toString does not correctly handle the case where all fields are zero.
",Bug,"Illegal serialization of null xsd:duration XSDDuration.toString does not correctly handle the case where all fields are zero.
"
JENA-411,tdbloader2 script references tdb_init,"The tdbloader2 script is broken in 2.10.0.

The script included in 2.10.0 is different to that in 2.7.4. The 2.7.4 version works correctly and only requires a JENA_HOME environment variable. 

But the version in 2.10.0 references a tdb_init script that isn't included in the release. This causes the script to quit with an error. It also references TDB_ROOT.

I tried to trace this back to files in SVN, but I'm not clear how the packaging works. The version in the 2.7.4 SVN also seems to reference tdb_init so presumably the scripts are altered during packaging.
",Bug,"tdbloader2 script references tdb_init The tdbloader2 script is broken in 2.10.0.

The script included in 2.10.0 is different to that in 2.7.4. The 2.7.4 version works correctly and only requires a JENA_HOME environment variable. 

But the version in 2.10.0 references a tdb_init script that isn't included in the release. This causes the script to quit with an error. It also references TDB_ROOT.

I tried to trace this back to files in SVN, but I'm not clear how the packaging works. The version in the 2.7.4 SVN also seems to reference tdb_init so presumably the scripts are altered during packaging.
"
JENA-409,Test failures building on windows after GIT pull,"On windows (8):

  Pull all branches from the GIT mirror
  Switch to trunk branch
  mvn clean install

results in test failures.

The tests that are failing are RIOT Turtle parser tests involving multiline literals.  The input files are:

jena-arq/testing/RIOT/Lang/Turtle/turtle-subm-15.ttl
jena-arq/testing/RIOT/Lang/Turtle/turtle-subm-16.ttl
jena-arq/testing/RIOT/Lang/TurtleSubm/test-17.ttl
jena-arq/testing/RIOT/Lang/TurtleSubm/test-18.ttl

The reason the tests are failing is that by default, GIT changes the line endings of text files to the platform default line endings on checkout.  Therefore, on checking out from GIT, the LF characters within the multiline literals in these files are replaced by CR LF.  When parsed the literals then do not match the expected results.  They have unexpected CR characters in them.

To fix this, I have created a .gitattributes file in the Jena root directory that tells GIT to use LF line endings for these four files.

After checking this file in and then doing:

git rm --cached -r .
git reset --hard
git add .
git commit -m ""Normalize line endings""

then Jena builds fine.  I would expect that if such a .gitattributes file were in the GIT repository when I did the pull, the build would just work out of the box, but I don't know that to be the case.
 




",Bug,"Test failures building on windows after GIT pull On windows (8):

  Pull all branches from the GIT mirror
  Switch to trunk branch
  mvn clean install

results in test failures.

The tests that are failing are RIOT Turtle parser tests involving multiline literals.  The input files are:

jena-arq/testing/RIOT/Lang/Turtle/turtle-subm-15.ttl
jena-arq/testing/RIOT/Lang/Turtle/turtle-subm-16.ttl
jena-arq/testing/RIOT/Lang/TurtleSubm/test-17.ttl
jena-arq/testing/RIOT/Lang/TurtleSubm/test-18.ttl

The reason the tests are failing is that by default, GIT changes the line endings of text files to the platform default line endings on checkout.  Therefore, on checking out from GIT, the LF characters within the multiline literals in these files are replaced by CR LF.  When parsed the literals then do not match the expected results.  They have unexpected CR characters in them.

To fix this, I have created a .gitattributes file in the Jena root directory that tells GIT to use LF line endings for these four files.

After checking this file in and then doing:

git rm --cached -r .
git reset --hard
git add .
git commit -m ""Normalize line endings""

then Jena builds fine.  I would expect that if such a .gitattributes file were in the GIT repository when I did the pull, the build would just work out of the box, but I don't know that to be the case.
 




"
JENA-407,toLowerCase without Locale.English causing trouble in some language regions (Turkey especially),"The instance I am referring to concretely is the language tag constructor: LanguageTag. 

It makes the following call on line 41:  String lc = tag.toLowerCase(); This should be corrected to  String lc = tag.toLowerCase(Locale.English);

The problem is that otherwise, it use the machine default language to produce the lower cases which in some Locales (Turkey being one of them) incorrectly lowercases letters like 'I'. Because the tag is a 'technical' term (not an actual piece of language) it should lowercase in English

The effect of this particular instance is that we see 

System.err.println(""Internal Error in static initializer of IanaLnaguageTag."")

appear in std.err and it has raised concerns with our customers.

In general, any occurrence of toLowerCase should be adjusted if it lowercases a technical term.",Bug,"toLowerCase without Locale.English causing trouble in some language regions (Turkey especially) The instance I am referring to concretely is the language tag constructor: LanguageTag. 

It makes the following call on line 41:  String lc = tag.toLowerCase(); This should be corrected to  String lc = tag.toLowerCase(Locale.English);

The problem is that otherwise, it use the machine default language to produce the lower cases which in some Locales (Turkey being one of them) incorrectly lowercases letters like 'I'. Because the tag is a 'technical' term (not an actual piece of language) it should lowercase in English

The effect of this particular instance is that we see 

System.err.println(""Internal Error in static initializer of IanaLnaguageTag."")

appear in std.err and it has raised concerns with our customers.

In general, any occurrence of toLowerCase should be adjusted if it lowercases a technical term."
JENA-406,NullPointerException while loading NQuad with xsd:anySimpleType object type.,"tdbloader crashes with NullPointerException while loading NQuad with xsd:anySimpleType object:

egor@egorov:~/semsearch-2011/dataset/fixed$ tdbloader --mem=bad_quad.nq 
Exception in thread ""main"" java.lang.NullPointerException
	at com.hp.hpl.jena.datatypes.xsd.XSDDatatype.getFoundingType(XSDDatatype.java:522)
	at com.hp.hpl.jena.datatypes.xsd.XSDDatatype.isBaseTypeCompatible(XSDDatatype.java:505)
	at com.hp.hpl.jena.datatypes.xsd.impl.XSDBaseNumericType.isValidLiteral(XSDBaseNumericType.java:67)
	at com.hp.hpl.jena.tdb.store.NodeId.inline(NodeId.java:208)
	at com.hp.hpl.jena.tdb.nodetable.NodeTableInline.getAllocateNodeId(NodeTableInline.java:49)
	at com.hp.hpl.jena.tdb.nodetable.NodeTupleTableConcrete.addRow(NodeTupleTableConcrete.java:84)
	at com.hp.hpl.jena.tdb.store.QuadTable.add(QuadTable.java:63)
	at com.hp.hpl.jena.tdb.store.DatasetGraphTDB.addToNamedGraph(DatasetGraphTDB.java:144)
	at com.hp.hpl.jena.sparql.core.DatasetGraphTriplesQuads.add(DatasetGraphTriplesQuads.java:49)
	at com.hp.hpl.jena.sparql.core.DatasetGraphTriplesQuads.add(DatasetGraphTriplesQuads.java:33)
	at com.hp.hpl.jena.sparql.core.DatasetGraphTrackActive.add(DatasetGraphTrackActive.java:127)
	at org.apache.jena.riot.system.StreamRDFLib$ParserOutputDataset.quad(StreamRDFLib.java:183)
	at org.apache.jena.riot.lang.LangNQuads.runParser(LangNQuads.java:56)
	at org.apache.jena.riot.lang.LangBase.parse(LangBase.java:42)
	at org.apache.jena.riot.RDFParserRegistry$ReaderRIOTFactoryImpl$1.read(RDFParserRegistry.java:148)
	at org.apache.jena.riot.RDFDataMgr.process(RDFDataMgr.java:751)
	at org.apache.jena.riot.RDFDataMgr.parse(RDFDataMgr.java:652)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:510)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:479)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:435)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:425)
	at tdb.cmdline.ModTDBDataset.createDataset(ModTDBDataset.java:75)
	at arq.cmdline.ModDataset.getDataset(ModDataset.java:34)
	at tdb.cmdline.CmdTDB.getDataset(CmdTDB.java:111)
	at tdb.cmdline.CmdTDB.getDatasetGraph(CmdTDB.java:100)
	at tdb.cmdline.CmdTDB.getDatasetGraphTDB(CmdTDB.java:105)
	at tdb.tdbloader.loadQuads(tdbloader.java:164)
	at tdb.tdbloader.exec(tdbloader.java:123)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:101)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:63)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:50)
	at tdb.tdbloader.main(tdbloader.java:54)
egor@egorov:~/semsearch-2011/dataset/fixed$ ",Bug,"NullPointerException while loading NQuad with xsd:anySimpleType object type. tdbloader crashes with NullPointerException while loading NQuad with xsd:anySimpleType object:

egor@egorov:~/semsearch-2011/dataset/fixed$ tdbloader --mem=bad_quad.nq 
Exception in thread ""main"" java.lang.NullPointerException
	at com.hp.hpl.jena.datatypes.xsd.XSDDatatype.getFoundingType(XSDDatatype.java:522)
	at com.hp.hpl.jena.datatypes.xsd.XSDDatatype.isBaseTypeCompatible(XSDDatatype.java:505)
	at com.hp.hpl.jena.datatypes.xsd.impl.XSDBaseNumericType.isValidLiteral(XSDBaseNumericType.java:67)
	at com.hp.hpl.jena.tdb.store.NodeId.inline(NodeId.java:208)
	at com.hp.hpl.jena.tdb.nodetable.NodeTableInline.getAllocateNodeId(NodeTableInline.java:49)
	at com.hp.hpl.jena.tdb.nodetable.NodeTupleTableConcrete.addRow(NodeTupleTableConcrete.java:84)
	at com.hp.hpl.jena.tdb.store.QuadTable.add(QuadTable.java:63)
	at com.hp.hpl.jena.tdb.store.DatasetGraphTDB.addToNamedGraph(DatasetGraphTDB.java:144)
	at com.hp.hpl.jena.sparql.core.DatasetGraphTriplesQuads.add(DatasetGraphTriplesQuads.java:49)
	at com.hp.hpl.jena.sparql.core.DatasetGraphTriplesQuads.add(DatasetGraphTriplesQuads.java:33)
	at com.hp.hpl.jena.sparql.core.DatasetGraphTrackActive.add(DatasetGraphTrackActive.java:127)
	at org.apache.jena.riot.system.StreamRDFLib$ParserOutputDataset.quad(StreamRDFLib.java:183)
	at org.apache.jena.riot.lang.LangNQuads.runParser(LangNQuads.java:56)
	at org.apache.jena.riot.lang.LangBase.parse(LangBase.java:42)
	at org.apache.jena.riot.RDFParserRegistry$ReaderRIOTFactoryImpl$1.read(RDFParserRegistry.java:148)
	at org.apache.jena.riot.RDFDataMgr.process(RDFDataMgr.java:751)
	at org.apache.jena.riot.RDFDataMgr.parse(RDFDataMgr.java:652)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:510)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:479)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:435)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:425)
	at tdb.cmdline.ModTDBDataset.createDataset(ModTDBDataset.java:75)
	at arq.cmdline.ModDataset.getDataset(ModDataset.java:34)
	at tdb.cmdline.CmdTDB.getDataset(CmdTDB.java:111)
	at tdb.cmdline.CmdTDB.getDatasetGraph(CmdTDB.java:100)
	at tdb.cmdline.CmdTDB.getDatasetGraphTDB(CmdTDB.java:105)
	at tdb.tdbloader.loadQuads(tdbloader.java:164)
	at tdb.tdbloader.exec(tdbloader.java:123)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:101)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:63)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:50)
	at tdb.tdbloader.main(tdbloader.java:54)
egor@egorov:~/semsearch-2011/dataset/fixed$ "
JENA-403,sparql -q doesn't suppress riot warnings,"With an example input file test.ttl containing this single line:
<> a < >.

I run this command:

bin/sparql --quiet --data test.ttl ""SELECT * { ?s ?p ?o }""

The output:

15:04:56 WARN  riot                 :: [line: 1, col: 6 ] Bad IRI: <file:///Users/RichardCyganiak/Desktop/Jena/ > Code: 18/DOUBLE_WHITESPACE in PATH: Either two or more consecutive whitespace characters, or leading or trailing whitespace. These match no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, but not XML Schema anyURIs.
------------------------------------------------------------------------
| s          | p                                                 | o   |
========================================================================
| <test.ttl> | <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> | < > |
------------------------------------------------------------------------

While the warning from riot is generally helpful, I would have expected it to be suppressed by the -q parameter. Having a way of suppressing such warnings would be rather useful for things like CONSTRUCT output, where the warnings make the output invalid.

From a brief look through the code, it looks like CmdGeneral.isQuiet() is correctly initialized but then never read.",Bug,"sparql -q doesn't suppress riot warnings With an example input file test.ttl containing this single line:
<> a < >.

I run this command:

bin/sparql --quiet --data test.ttl ""SELECT * { ?s ?p ?o }""

The output:

15:04:56 WARN  riot                 :: [line: 1, col: 6 ] Bad IRI: <file:///Users/RichardCyganiak/Desktop/Jena/ > Code: 18/DOUBLE_WHITESPACE in PATH: Either two or more consecutive whitespace characters, or leading or trailing whitespace. These match no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, but not XML Schema anyURIs.
------------------------------------------------------------------------
| s          | p                                                 | o   |
========================================================================
| <test.ttl> | <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> | < > |
------------------------------------------------------------------------

While the warning from riot is generally helpful, I would have expected it to be suppressed by the -q parameter. Having a way of suppressing such warnings would be rather useful for things like CONSTRUCT output, where the warnings make the output invalid.

From a brief look through the code, it looks like CmdGeneral.isQuiet() is correctly initialized but then never read."
JENA-400,Hang when running tests that depend on Jena in parallel using Maven,"Running multiple test classes that use Jena can cause a hang during JUnit test execution. We reduced this to two separate test classes, each with only one test, roughly as follows:

import java.io.IOException;
import org.junit.Test;
import com.hp.hpl.jena.rdf.model.ModelFactory;

public class FirstJenaTest 
{
	@Test
	public void test() throws IOException
	{
		ModelFactory.createDefaultModel();
	}
}

TEST 2:

import org.junit.Test;
import com.hp.hpl.jena.query.Query;

public class SecondJenaTest
{
	@Test
	public void test()
	{
		new Query();
	}
}


pom.xml: 
...
<plugin>
	<groupId>org.apache.maven.plugins</groupId>
	<artifactId>maven-surefire-plugin</artifactId>
	<configuration>
		<parallel>classes</parallel>
		<includes>
               	  <include>**/FirstJenaTest.java</include>
               	  <include>**/SecondJenaTest.java</include>
               </includes>
	</configuration>
	. . .
</plugin>
...


Here's part of the thread dump we captured:
""pool-1-thread-2"" prio=5 tid=7fb9be6f5800 nid=0x1159a7000 in Object.wait() [1159a4000]
   java.lang.Thread.State: RUNNABLE
	at org.apache.jena.riot.RIOT.<clinit>(RIOT.java:38)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:169)
	at com.hp.hpl.jena.rdf.model.impl.IO_Ctl.callByRefection(IO_Ctl.java:54)
	at com.hp.hpl.jena.rdf.model.impl.IO_Ctl.init(IO_Ctl.java:36)
	- locked <7f3883170> (a java.lang.Object)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.<clinit>(ModelCom.java:65)
	at com.hp.hpl.jena.rdf.model.ModelFactory.createDefaultModel(ModelFactory.java:140)
	at xx.FirstJenaTest.test(FirstJenaTest.java:xx)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junitcore.ClassDemarcatingRunner.run(ClassDemarcatingRunner.java:58)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)

""pool-1-thread-1"" prio=5 tid=7fb9be0d8000 nid=0x1158a4000 in Object.wait() [1158a1000]
   java.lang.Thread.State: RUNNABLE
	at com.hp.hpl.jena.rdf.model.ModelFactory.createDefaultModel(ModelFactory.java:140)
	at com.hp.hpl.jena.vocabulary.OWL.<clinit>(OWL.java:36)
	at com.hp.hpl.jena.sparql.ARQConstants.<clinit>(ARQConstants.java:44)
	at com.hp.hpl.jena.query.ARQ.<clinit>(ARQ.java:70)
	at com.hp.hpl.jena.query.Query.<clinit>(Query.java:63)
	at xx.SecondJenaTest.test(SecondJenaTest.java:xx)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junitcore.ClassDemarcatingRunner.run(ClassDemarcatingRunner.java:58)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)


",Bug,"Hang when running tests that depend on Jena in parallel using Maven Running multiple test classes that use Jena can cause a hang during JUnit test execution. We reduced this to two separate test classes, each with only one test, roughly as follows:

import java.io.IOException;
import org.junit.Test;
import com.hp.hpl.jena.rdf.model.ModelFactory;

public class FirstJenaTest 
{
	@Test
	public void test() throws IOException
	{
		ModelFactory.createDefaultModel();
	}
}

TEST 2:

import org.junit.Test;
import com.hp.hpl.jena.query.Query;

public class SecondJenaTest
{
	@Test
	public void test()
	{
		new Query();
	}
}


pom.xml: 
...
<plugin>
	<groupId>org.apache.maven.plugins</groupId>
	<artifactId>maven-surefire-plugin</artifactId>
	<configuration>
		<parallel>classes</parallel>
		<includes>
               	  <include>**/FirstJenaTest.java</include>
               	  <include>**/SecondJenaTest.java</include>
               </includes>
	</configuration>
	. . .
</plugin>
...


Here's part of the thread dump we captured:
""pool-1-thread-2"" prio=5 tid=7fb9be6f5800 nid=0x1159a7000 in Object.wait() [1159a4000]
   java.lang.Thread.State: RUNNABLE
	at org.apache.jena.riot.RIOT.<clinit>(RIOT.java:38)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:169)
	at com.hp.hpl.jena.rdf.model.impl.IO_Ctl.callByRefection(IO_Ctl.java:54)
	at com.hp.hpl.jena.rdf.model.impl.IO_Ctl.init(IO_Ctl.java:36)
	- locked <7f3883170> (a java.lang.Object)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.<clinit>(ModelCom.java:65)
	at com.hp.hpl.jena.rdf.model.ModelFactory.createDefaultModel(ModelFactory.java:140)
	at xx.FirstJenaTest.test(FirstJenaTest.java:xx)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junitcore.ClassDemarcatingRunner.run(ClassDemarcatingRunner.java:58)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)

""pool-1-thread-1"" prio=5 tid=7fb9be0d8000 nid=0x1158a4000 in Object.wait() [1158a1000]
   java.lang.Thread.State: RUNNABLE
	at com.hp.hpl.jena.rdf.model.ModelFactory.createDefaultModel(ModelFactory.java:140)
	at com.hp.hpl.jena.vocabulary.OWL.<clinit>(OWL.java:36)
	at com.hp.hpl.jena.sparql.ARQConstants.<clinit>(ARQConstants.java:44)
	at com.hp.hpl.jena.query.ARQ.<clinit>(ARQ.java:70)
	at com.hp.hpl.jena.query.Query.<clinit>(Query.java:63)
	at xx.SecondJenaTest.test(SecondJenaTest.java:xx)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junitcore.ClassDemarcatingRunner.run(ClassDemarcatingRunner.java:58)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)


"
JENA-395,Model events not firing for Model.removeAll + TDB,"Events not being triggered when using a TDB backed model, and model.removeAll.  They are fired for a memory model.",Bug,"Model events not firing for Model.removeAll + TDB Events not being triggered when using a TDB backed model, and model.removeAll.  They are fired for a memory model."
JENA-394,RDF/XML parser incorrectly disallows some Unicode characters,"The Unicode character 'KATAKANA MIDDLE DOT' (U+30FB) in the local part of a property name causes a parse exception in the RDF/XML parser. This seems to be incorrect, as the character is allowed in IRIs and is allowed in XML local names, as far as I can tell.

Example file:

<?xml version=""1.0"" encoding=""utf-8"" ?>
<rdf:RDF xmlns:rdf=""http://www.w3.org/1999/02/22-rdf-syntax-ns#"" xmlns=""http://example.com/ns#"">
  <rdf:Description rdf:about=""#this"">
    <隣接自治体・行政区 rdf:resource=""#that""/>
  </rdf:Description>
</rdf:RDF>

The offending character is the “dot” in the middle of the property name.

rdfcat execution with stack trace:

$ bin/rdfcat ~/katakana-middle-dot.xml 
18:09:37 ERROR riot                 :: Element type ""?????"" must be followed by either attribute specifications, "">"" or ""/>"".
Exception in thread ""main"" org.apache.jena.riot.RiotException: Element type ""?????"" must be followed by either attribute specifications, "">"" or ""/>"".
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:132)
	at org.apache.jena.riot.lang.LangRDFXML$ErrorHandlerBridge.fatalError(LangRDFXML.java:242)
	at com.hp.hpl.jena.rdf.arp.impl.ARPSaxErrorHandler.fatalError(ARPSaxErrorHandler.java:48)
	at com.hp.hpl.jena.rdf.arp.impl.XMLHandler.warning(XMLHandler.java:209)
	at com.hp.hpl.jena.rdf.arp.impl.XMLHandler.fatalError(XMLHandler.java:239)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.DTDConfiguration.parse(Unknown Source)
	at org.apache.xerces.parsers.DTDConfiguration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at com.hp.hpl.jena.rdf.arp.impl.RDFXMLParser.parse(RDFXMLParser.java:151)
	at com.hp.hpl.jena.rdf.arp.ARP.load(ARP.java:119)
	at org.apache.jena.riot.lang.LangRDFXML.parse(LangRDFXML.java:141)
	at org.apache.jena.riot.RDFParserRegistry$ReaderRIOTFactoryImpl$1.read(RDFParserRegistry.java:148)
	at org.apache.jena.riot.RDFDataMgr.process(RDFDataMgr.java:749)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:258)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:244)
	at org.apache.jena.riot.adapters.RDFReaderRIOT.read(RDFReaderRIOT.java:65)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:276)
	at com.hp.hpl.jena.util.FileManager.readModelWorker(FileManager.java:403)
	at com.hp.hpl.jena.util.FileManager.readModel(FileManager.java:342)
	at jena.rdfcat.readInput(rdfcat.java:375)
	at jena.rdfcat$ReadAction.run(rdfcat.java:552)
	at jena.rdfcat.go(rdfcat.java:278)
	at jena.rdfcat.main(rdfcat.java:260)
 ",Bug,"RDF/XML parser incorrectly disallows some Unicode characters The Unicode character 'KATAKANA MIDDLE DOT' (U+30FB) in the local part of a property name causes a parse exception in the RDF/XML parser. This seems to be incorrect, as the character is allowed in IRIs and is allowed in XML local names, as far as I can tell.

Example file:

<?xml version=""1.0"" encoding=""utf-8"" ?>
<rdf:RDF xmlns:rdf=""http://www.w3.org/1999/02/22-rdf-syntax-ns#"" xmlns=""http://example.com/ns#"">
  <rdf:Description rdf:about=""#this"">
    <Lin Jie Zi Zhi Ti Xing Zheng Qu  rdf:resource=""#that""/>
  </rdf:Description>
</rdf:RDF>

The offending character is the ""dot"" in the middle of the property name.

rdfcat execution with stack trace:

$ bin/rdfcat ~/katakana-middle-dot.xml 
18:09:37 ERROR riot                 :: Element type ""?????"" must be followed by either attribute specifications, "">"" or ""/>"".
Exception in thread ""main"" org.apache.jena.riot.RiotException: Element type ""?????"" must be followed by either attribute specifications, "">"" or ""/>"".
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:132)
	at org.apache.jena.riot.lang.LangRDFXML$ErrorHandlerBridge.fatalError(LangRDFXML.java:242)
	at com.hp.hpl.jena.rdf.arp.impl.ARPSaxErrorHandler.fatalError(ARPSaxErrorHandler.java:48)
	at com.hp.hpl.jena.rdf.arp.impl.XMLHandler.warning(XMLHandler.java:209)
	at com.hp.hpl.jena.rdf.arp.impl.XMLHandler.fatalError(XMLHandler.java:239)
	at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
	at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.DTDConfiguration.parse(Unknown Source)
	at org.apache.xerces.parsers.DTDConfiguration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at com.hp.hpl.jena.rdf.arp.impl.RDFXMLParser.parse(RDFXMLParser.java:151)
	at com.hp.hpl.jena.rdf.arp.ARP.load(ARP.java:119)
	at org.apache.jena.riot.lang.LangRDFXML.parse(LangRDFXML.java:141)
	at org.apache.jena.riot.RDFParserRegistry$ReaderRIOTFactoryImpl$1.read(RDFParserRegistry.java:148)
	at org.apache.jena.riot.RDFDataMgr.process(RDFDataMgr.java:749)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:258)
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:244)
	at org.apache.jena.riot.adapters.RDFReaderRIOT.read(RDFReaderRIOT.java:65)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:276)
	at com.hp.hpl.jena.util.FileManager.readModelWorker(FileManager.java:403)
	at com.hp.hpl.jena.util.FileManager.readModel(FileManager.java:342)
	at jena.rdfcat.readInput(rdfcat.java:375)
	at jena.rdfcat$ReadAction.run(rdfcat.java:552)
	at jena.rdfcat.go(rdfcat.java:278)
	at jena.rdfcat.main(rdfcat.java:260)
 "
JENA-389,Subquery containing a FILTER NOT EXISTS can cause wrong results,"Highlighted by Tim Harsch on Answers.SemanticWeb.com - http://answers.semanticweb.com/questions/20737/why-doesnt-subquery-variable-get-projected

He found a couple of queries (run against the trivial books database on sparql.org which should give the same results yet yield entirely different results).

Query 1:

SELECT *
{
  SELECT (COUNT(?x1) as ?openTriplets)
  WHERE {
    ?x1 ?a1 ?y1 .
    ?y1 ?b1 ?z1 .
    FILTER NOT EXISTS {?z1 ?c1 ?x1}
  }
}

Result 1 - ?openTriplets has count of 6

Query 2:

SELECT ?openTriplets
{
  SELECT (COUNT(?x1) as ?openTriplets)
  WHERE {
    ?x1 ?a1 ?y1 .
    ?y1 ?b1 ?z1 .
    FILTER NOT EXISTS {?z1 ?c1 ?x1}
  }
}

Result 2 - ?openTriplets = 0

This seems to be because the explicit mention of the variable name in Query 2 results in a different algebra being generated because of how ARQ renames variables to give correct scoping.

Algebra for Query 1:

(base <http://example/base/>
   (project (?openTriplets)
     (extend ((?openTriplets ?.0))
      (group () ((?.0 (count ?x1)))
        (filter (notexists (bgp (triple ?z1 ?c1 ?x1)))
          (bgp
            (triple ?x1 ?a1 ?y1)
           (triple ?y1 ?b1 ?z1)
         ))))))

Algebra for Query 2:

(base <http://example/base/>
   (project (?openTriplets)
     (project (?openTriplets)
       (extend ((?openTriplets ?/.0))
         (group () ((?/.0 (count ?/x1)))
           (filter (notexists (bgp (triple ?//z1 ?//c1 ?//x1)))
             (bgp
               (triple ?/x1 ?/a1 ?/y1)
               (triple ?/y1 ?/b1 ?/z1)
             )))))))

As can be seen with the second algebra the extra project appears to cause ARQ to rename variables differently.  This results in the NOT EXISTS being treated as distinct from the BGP it encloses meaning it matches everything resulting in all values being eliminated hence the count of zero as the result of the second query.",Bug,"Subquery containing a FILTER NOT EXISTS can cause wrong results Highlighted by Tim Harsch on Answers.SemanticWeb.com - http://answers.semanticweb.com/questions/20737/why-doesnt-subquery-variable-get-projected

He found a couple of queries (run against the trivial books database on sparql.org which should give the same results yet yield entirely different results).

Query 1:

SELECT *
{
  SELECT (COUNT(?x1) as ?openTriplets)
  WHERE {
    ?x1 ?a1 ?y1 .
    ?y1 ?b1 ?z1 .
    FILTER NOT EXISTS {?z1 ?c1 ?x1}
  }
}

Result 1 - ?openTriplets has count of 6

Query 2:

SELECT ?openTriplets
{
  SELECT (COUNT(?x1) as ?openTriplets)
  WHERE {
    ?x1 ?a1 ?y1 .
    ?y1 ?b1 ?z1 .
    FILTER NOT EXISTS {?z1 ?c1 ?x1}
  }
}

Result 2 - ?openTriplets = 0

This seems to be because the explicit mention of the variable name in Query 2 results in a different algebra being generated because of how ARQ renames variables to give correct scoping.

Algebra for Query 1:

(base <http://example/base/>
   (project (?openTriplets)
     (extend ((?openTriplets ?.0))
      (group () ((?.0 (count ?x1)))
        (filter (notexists (bgp (triple ?z1 ?c1 ?x1)))
          (bgp
            (triple ?x1 ?a1 ?y1)
           (triple ?y1 ?b1 ?z1)
         ))))))

Algebra for Query 2:

(base <http://example/base/>
   (project (?openTriplets)
     (project (?openTriplets)
       (extend ((?openTriplets ?/.0))
         (group () ((?/.0 (count ?/x1)))
           (filter (notexists (bgp (triple ?//z1 ?//c1 ?//x1)))
             (bgp
               (triple ?/x1 ?/a1 ?/y1)
               (triple ?/y1 ?/b1 ?/z1)
             )))))))

As can be seen with the second algebra the extra project appears to cause ARQ to rename variables differently.  This results in the NOT EXISTS being treated as distinct from the BGP it encloses meaning it matches everything resulting in all values being eliminated hence the count of zero as the result of the second query."
JENA-385,NPE during abort,"we ran into a non-reproducible glitch where a transaction was unable to commit (we don't know exactly why - could be a network glitch or hard drive hickup). As a consequence, an abort was initiated which let to an NPE because the journalObjfile was already null. It happens in the following code in NodeTableTrans on the call to truncate. 

    public void abort(Transaction txn)
    {
        debug(""abort"") ;
        if ( nodeTableJournal == null )
            throw new TDBTransactionException(txn.getLabel()+"": Not in a transaction for a commit to happen"") ;
        // Ensure the cache does not flush.
        nodeTableJournal = null ;
        // then make sure the journal file is empty.
        journalObjFile.truncate(journalObjFileStartOffset) ;
        journalObjFile.sync() ;
        finish() ;
    }

Should there not just be a check here to verify if journalObjFile != null? So

    public void abort(Transaction txn)
    {
        debug(""abort"") ;
        if ( nodeTableJournal == null )
            throw new TDBTransactionException(txn.getLabel()+"": Not in a transaction for a commit to happen"") ;
        // Ensure the cache does not flush.
        nodeTableJournal = null ;
        // then make sure the journal file is empty.
        if (journalObjFile != null) {
           journalObjFile.truncate(journalObjFileStartOffset) ;
           journalObjFile.sync() ;
        }
        finish() ;
    }",Bug,"NPE during abort we ran into a non-reproducible glitch where a transaction was unable to commit (we don't know exactly why - could be a network glitch or hard drive hickup). As a consequence, an abort was initiated which let to an NPE because the journalObjfile was already null. It happens in the following code in NodeTableTrans on the call to truncate. 

    public void abort(Transaction txn)
    {
        debug(""abort"") ;
        if ( nodeTableJournal == null )
            throw new TDBTransactionException(txn.getLabel()+"": Not in a transaction for a commit to happen"") ;
        // Ensure the cache does not flush.
        nodeTableJournal = null ;
        // then make sure the journal file is empty.
        journalObjFile.truncate(journalObjFileStartOffset) ;
        journalObjFile.sync() ;
        finish() ;
    }

Should there not just be a check here to verify if journalObjFile != null? So

    public void abort(Transaction txn)
    {
        debug(""abort"") ;
        if ( nodeTableJournal == null )
            throw new TDBTransactionException(txn.getLabel()+"": Not in a transaction for a commit to happen"") ;
        // Ensure the cache does not flush.
        nodeTableJournal = null ;
        // then make sure the journal file is empty.
        if (journalObjFile != null) {
           journalObjFile.truncate(journalObjFileStartOffset) ;
           journalObjFile.sync() ;
        }
        finish() ;
    }"
JENA-381,Composed graphs do no generate listener event for deletion on iterator.,"Composed graphs do no generate listener event for deletion on iterator as indicated by failure of testEventDeleteByFind() in AbstractTestGraph

Analysis:

returned iterator is a composite of the iterators on the base graph. e.g. AIter.andThen( BIter ).  When remove is called it is executed against the base graph.  The composed graph does not listen to the base graphs and thus does not broadcast the subgraph deletion to its listeners.

Potential Solution:

Have the composite graph register as a listener to the base graphs and rebroadcast all events to its listeners.  I expect that this will cause duplicate notification for currently broadcast events and that several methods that modify the graph and broadcast the change will have to be modified so as not to announce the change but let the underlying graph announce it.

Alternative Solution:

Modify the iterator so that it wraps the currently returned iterator trap the delete method and announces the deletion to its listeners after calling the delete on the wrapped iterator.

The alternative solution is probably easier to implement.
",Bug,"Composed graphs do no generate listener event for deletion on iterator. Composed graphs do no generate listener event for deletion on iterator as indicated by failure of testEventDeleteByFind() in AbstractTestGraph

Analysis:

returned iterator is a composite of the iterators on the base graph. e.g. AIter.andThen( BIter ).  When remove is called it is executed against the base graph.  The composed graph does not listen to the base graphs and thus does not broadcast the subgraph deletion to its listeners.

Potential Solution:

Have the composite graph register as a listener to the base graphs and rebroadcast all events to its listeners.  I expect that this will cause duplicate notification for currently broadcast events and that several methods that modify the graph and broadcast the change will have to be modified so as not to announce the change but let the underlying graph announce it.

Alternative Solution:

Modify the iterator so that it wraps the currently returned iterator trap the delete method and announces the deletion to its listeners after calling the delete on the wrapped iterator.

The alternative solution is probably easier to implement.
"
JENA-379,SPARQL Property paths with the same variable for subject and object not handled correctly.,"Example:

:x :p :y .
:y :p :x .

and query SELECT * { ?z :p+ ?z }
=> Too many rows",Bug,"SPARQL Property paths with the same variable for subject and object not handled correctly. Example:

:x :p :y .
:y :p :x .

and query SELECT * { ?z :p+ ?z }
=> Too many rows"
JENA-378,Serialization of update requests isn't legal syntax,"arq.uparse.main(""INSERT {} WHERE { ?x ?p [ ?a  ?b ] } "") ; 

This then effects remote update requests.",Bug,"Serialization of update requests isn't legal syntax arq.uparse.main(""INSERT {} WHERE { ?x ?p [ ?a  ?b ] } "") ; 

This then effects remote update requests."
JENA-377,Documentation Error for Fuseki Setup,"In order to setup Fuseki the documentation instructs the user to execute the command: ""chmod +x fuseki-server s-\*"" when really the command should be ""chmod +x fuseki-server s-*"" without the backslash prior to the asterisk. ",Bug,"Documentation Error for Fuseki Setup In order to setup Fuseki the documentation instructs the user to execute the command: ""chmod +x fuseki-server s-\*"" when really the command should be ""chmod +x fuseki-server s-*"" without the backslash prior to the asterisk. "
JENA-376,Fuseki service script overrides log4j.configuration setting supplied in JAVA_OPTIONS,"I'm using the service script to start Fuseki as a service. I'd like to modify some log4j settings by specifying my own log4j.properties file, but I don't seem to be able to specify the location of my properties file.

I've tried setting the JAVA_OPTIONS environment variable to include the properties file location as a ""log4j.configuration"" property (with ""file:"" type) before invoking the script:

  JAVA_OPTIONS=""-Dlog4j.configuration=file:/home/jhigman/myProject/config/log4j.properties $JAVA_OPTIONS""

But the init script adds it's own default location for the log4j.configuration location:

  JAVA_OPTIONS+=(""-Dlog4j.configuration=log4j.properties"" ""-Xmx1200M"")

which overrides whatever I've set in the JAVA_OPTIONS.

I can't use the classpath to determine where the log4j properties file is because the service script uses the fuseki-server.jar to start the service.

Could the service script check for the presence of the log4j.configuration option before modifying the JAVA_OPTIONS? Or use another environment variable to allow the log4j.properties file location to be specified?


 
",Bug,"Fuseki service script overrides log4j.configuration setting supplied in JAVA_OPTIONS I'm using the service script to start Fuseki as a service. I'd like to modify some log4j settings by specifying my own log4j.properties file, but I don't seem to be able to specify the location of my properties file.

I've tried setting the JAVA_OPTIONS environment variable to include the properties file location as a ""log4j.configuration"" property (with ""file:"" type) before invoking the script:

  JAVA_OPTIONS=""-Dlog4j.configuration=file:/home/jhigman/myProject/config/log4j.properties $JAVA_OPTIONS""

But the init script adds it's own default location for the log4j.configuration location:

  JAVA_OPTIONS+=(""-Dlog4j.configuration=log4j.properties"" ""-Xmx1200M"")

which overrides whatever I've set in the JAVA_OPTIONS.

I can't use the classpath to determine where the log4j properties file is because the service script uses the fuseki-server.jar to start the service.

Could the service script check for the presence of the log4j.configuration option before modifying the JAVA_OPTIONS? Or use another environment variable to allow the log4j.properties file location to be specified?


 
"
JENA-364,RecordingListener does not always report equal values,"RecordingListener compares the results of the listener implementation with the expected results.  However, if the list of triples is equivalent but not the identical list the comparison fails.  This is fixed if the list of expected values and the list of results are compared as an array using deepEquals().

This does require Java 5.",Bug,"RecordingListener does not always report equal values RecordingListener compares the results of the listener implementation with the expected results.  However, if the list of triples is equivalent but not the identical list the comparison fails.  This is fixed if the list of expected values and the list of results are compared as an array using deepEquals().

This does require Java 5."
JENA-363,TDB round trip failures on 63bit integers,"The following example code attempts to store a large (63 bit) xsd:integer in a TDB instance.

  public void temp() throws Exception {
    String BASE = ""http://example.com/test#"";
    String lex63 = ""5823355717404272516"";

    Dataset ds = TDBFactory.createDataset(""data/tdb"");
    Model m = ds.getDefaultModel();

    Literal l = m.createTypedLiteral(lex63, XSDDatatype.XSDinteger);
    Resource r = m.createResource(BASE + ""i"").addProperty(RDF.value, l);

    System.out.println(""Val = "" + r.getProperty(RDF.value).getObject());
  }

This returns:

Val = -13309399667890300^^http://www.w3.org/2001/XMLSchema#integer 

A similar truncation occurs for xsd:long but strangely not for xsd:int.",Bug,"TDB round trip failures on 63bit integers The following example code attempts to store a large (63 bit) xsd:integer in a TDB instance.

  public void temp() throws Exception {
    String BASE = ""http://example.com/test#"";
    String lex63 = ""5823355717404272516"";

    Dataset ds = TDBFactory.createDataset(""data/tdb"");
    Model m = ds.getDefaultModel();

    Literal l = m.createTypedLiteral(lex63, XSDDatatype.XSDinteger);
    Resource r = m.createResource(BASE + ""i"").addProperty(RDF.value, l);

    System.out.println(""Val = "" + r.getProperty(RDF.value).getObject());
  }

This returns:

Val = -13309399667890300^^http://www.w3.org/2001/XMLSchema#integer 

A similar truncation occurs for xsd:long but strangely not for xsd:int."
JENA-362,"model.listStatements(s,p,o,lang) has problems when o or lang is null","1) model.listStatements(s,p,null,lang) doesn't filter on lang param
2) model.listStatements(s,p,o,null) only returns statements whose object has lang """" (when o != null)

TEST 1
import org.junit.Test;
import com.hp.hpl.jena.rdf.model.*;
public class LstStmt1 {
	@Test
	public final void test() {
		Model m = ModelFactory.createDefaultModel();
		Resource s = m.createResource(""http://www.a.com/s"");
		Property p = m.createProperty(""http://www.a.com/p"");

		m.add(s,p,m.createResource(""http://www.a.com/o""));
		m.add(s,p,""texte"",""fr"");
		m.add(s,p,""text"",""en"");
		
		StmtIterator it = m.listStatements(s, p, null,""en"");
		// list all the statements - not what one can expect
		for (;it.hasNext();) {
			System.out.println(it.next());
		}
	}
}

TEST2

public class LstStmt2 {
	@Test
	public final void test() {
		Model m = ModelFactory.createDefaultModel();
		Resource s = m.createResource(""http://www.a.com/s"");
		Property p = m.createProperty(""http://www.a.com/p"");

		m.add(s,p,""text"",""en"");
		m.add(s,p,""text"");
		
		StmtIterator it = m.listStatements(s, p,""text"",null);
		// should list the 2 statements, but doesn't: only the one without lang
		for (;it.hasNext();) {
			System.out.println(it.next());
		}
	}
}
",Bug,"model.listStatements(s,p,o,lang) has problems when o or lang is null 1) model.listStatements(s,p,null,lang) doesn't filter on lang param
2) model.listStatements(s,p,o,null) only returns statements whose object has lang """" (when o != null)

TEST 1
import org.junit.Test;
import com.hp.hpl.jena.rdf.model.*;
public class LstStmt1 {
	@Test
	public final void test() {
		Model m = ModelFactory.createDefaultModel();
		Resource s = m.createResource(""http://www.a.com/s"");
		Property p = m.createProperty(""http://www.a.com/p"");

		m.add(s,p,m.createResource(""http://www.a.com/o""));
		m.add(s,p,""texte"",""fr"");
		m.add(s,p,""text"",""en"");
		
		StmtIterator it = m.listStatements(s, p, null,""en"");
		// list all the statements - not what one can expect
		for (;it.hasNext();) {
			System.out.println(it.next());
		}
	}
}

TEST2

public class LstStmt2 {
	@Test
	public final void test() {
		Model m = ModelFactory.createDefaultModel();
		Resource s = m.createResource(""http://www.a.com/s"");
		Property p = m.createProperty(""http://www.a.com/p"");

		m.add(s,p,""text"",""en"");
		m.add(s,p,""text"");
		
		StmtIterator it = m.listStatements(s, p,""text"",null);
		// should list the 2 statements, but doesn't: only the one without lang
		for (;it.hasNext();) {
			System.out.println(it.next());
		}
	}
}
"
JENA-361,Printing queries restarts the bNode labels inside subqueries.,"Examples:

SELECT  *
  {  
    { SELECT  * { ?s1 ?p1 _:b0 } }
    { SELECT  * { ?s1 ?p1 _:b1 } }
  }

SELECT  *
  {  
    { SELECT  * { ?s1 ?p1 _:b0 } }
    ?s1 ?p1 _:b1
  }

Both the _:b1 become _:b0 when read in and printed out.
",Bug,"Printing queries restarts the bNode labels inside subqueries. Examples:

SELECT  *
  {  
    { SELECT  * { ?s1 ?p1 _:b0 } }
    { SELECT  * { ?s1 ?p1 _:b1 } }
  }

SELECT  *
  {  
    { SELECT  * { ?s1 ?p1 _:b0 } }
    ?s1 ?p1 _:b1
  }

Both the _:b1 become _:b0 when read in and printed out.
"
JENA-360,RDFListImpl.copy fails when list is empty.,"ModelFactory.createDefaultModel().createList().copy()
 will throw a NullPointerException because the list variable in the  RDFListImp.copy( iterator ) is not set when there are no elements in the iterator.
",Bug,"RDFListImpl.copy fails when list is empty. ModelFactory.createDefaultModel().createList().copy()
 will throw a NullPointerException because the list variable in the  RDFListImp.copy( iterator ) is not set when there are no elements in the iterator.
"
JENA-359,inModel() dependencies on ModelCom,"LiteralImpl.inModel( Model m ) and ResourceImpl.inModel( Model m ) cast the Model m to a ModelCom in some instances.

ResourecImpl.inModel() calls
asNode().isConcrete() == false ? (Resource) ((ModelCom) m).getRDFNode( asNode() )

this line handles working with variables and I am not sure how to fix that.

LiteralImpl.inModel()  calls
(Literal) ((ModelCom) m).getRDFNode( asNode() )

I think this can be replaced with
m.createTypedLiteral(getLexicalForm(), getDataType())

My issue is that I have a model implementation that does not derive from ModelCom so these methods fail some test cases.
",Bug,"inModel() dependencies on ModelCom LiteralImpl.inModel( Model m ) and ResourceImpl.inModel( Model m ) cast the Model m to a ModelCom in some instances.

ResourecImpl.inModel() calls
asNode().isConcrete() == false ? (Resource) ((ModelCom) m).getRDFNode( asNode() )

this line handles working with variables and I am not sure how to fix that.

LiteralImpl.inModel()  calls
(Literal) ((ModelCom) m).getRDFNode( asNode() )

I think this can be replaced with
m.createTypedLiteral(getLexicalForm(), getDataType())

My issue is that I have a model implementation that does not derive from ModelCom so these methods fail some test cases.
"
JENA-358,Remote SPARQL Update requests do not honor JVM proxy settings while queries do,"As i found, the remote SPARQL Update execution uses Apache HttpClient 4.1 which do not honor JVM proxy settings while the SPARQL Query execution does not rely on the HttpClient and the JVM proxy settings can be applied.
Maybe the HttpOp class could use  SystemDefaultHttpClient from HttpClient v4.2 instead of DefaultHttpClient.",Bug,"Remote SPARQL Update requests do not honor JVM proxy settings while queries do As i found, the remote SPARQL Update execution uses Apache HttpClient 4.1 which do not honor JVM proxy settings while the SPARQL Query execution does not rely on the HttpClient and the JVM proxy settings can be applied.
Maybe the HttpOp class could use  SystemDefaultHttpClient from HttpClient v4.2 instead of DefaultHttpClient."
JENA-352,Vast numbers of bNodes can overwhelm the parser,"The parsers need to keep a bNode label to bNode map which (unusual data) can grow too large.  As it takes unusual data, rated as ""minor"".

outline of solution: 

1/ switch to a bNode allocation scheme which has a seed (a large random number per parser run), and concat or XOR with the claimed bNode label to generate a unique label without state build up.

2/ (Turtle) don't remember [] bnodes past their usage scope.

3/ Partial - keep a sliding window of bNodes label mappings 

4/ Direct allocation for _:label and tracked allocation for []

e.g.
http://mail-archives.apache.org/mod_mbox/jena-users/201112.mbox/%3C4EDFE45F.6090202@apache.org%3E",Bug,"Vast numbers of bNodes can overwhelm the parser The parsers need to keep a bNode label to bNode map which (unusual data) can grow too large.  As it takes unusual data, rated as ""minor"".

outline of solution: 

1/ switch to a bNode allocation scheme which has a seed (a large random number per parser run), and concat or XOR with the claimed bNode label to generate a unique label without state build up.

2/ (Turtle) don't remember [] bnodes past their usage scope.

3/ Partial - keep a sliding window of bNodes label mappings 

4/ Direct allocation for _:label and tracked allocation for []

e.g.
http://mail-archives.apache.org/mod_mbox/jena-users/201112.mbox/%3C4EDFE45F.6090202@apache.org%3E"
JENA-347,NodecSSE decode problem,"Decode method of NodecSSE should be the inverse function of encode but it's not. In case of URI, decode create NodeURI from the string obtained from the whole ByteBuffer passed to decode. This results in URL that is not equal to the original URI (it's longer as it contains nonsensical suffix). I've temporarily fixed that by trimming the decoded string before creating URI:
if ( str.startsWith(""<"") )
        {
            // Do directly.
            // (is it quicker?)
            str = str.trim(); // !!!!!!!!!!! this line inserted
            str = str.substring(1,str.length()-1) ;
            str = StrUtils.unescapeString(str) ;
            str = StrUtils.decodeHex(str, MarkerChar) ;
            return Node.createURI(str) ;
        }

I'm using NodecSSE to encode Nodes in order to transfer them through network.",Bug,"NodecSSE decode problem Decode method of NodecSSE should be the inverse function of encode but it's not. In case of URI, decode create NodeURI from the string obtained from the whole ByteBuffer passed to decode. This results in URL that is not equal to the original URI (it's longer as it contains nonsensical suffix). I've temporarily fixed that by trimming the decoded string before creating URI:
if ( str.startsWith(""<"") )
        {
            // Do directly.
            // (is it quicker?)
            str = str.trim(); // !!!!!!!!!!! this line inserted
            str = str.substring(1,str.length()-1) ;
            str = StrUtils.unescapeString(str) ;
            str = StrUtils.decodeHex(str, MarkerChar) ;
            return Node.createURI(str) ;
        }

I'm using NodecSSE to encode Nodes in order to transfer them through network."
JENA-344,"SPARQL Update WHERE masks the real dataset, making evaluation not respect unionGraph.","If TDB unionGraph is set, it is not seen because the WHERE is evaluated on the graph store (GraphStoreBasic) and that is not recognized by the TDB query engine.  Hence it uses the general purpose query engine, and fails to honour unionGraph.",Bug,"SPARQL Update WHERE masks the real dataset, making evaluation not respect unionGraph. If TDB unionGraph is set, it is not seen because the WHERE is evaluated on the graph store (GraphStoreBasic) and that is not recognized by the TDB query engine.  Hence it uses the general purpose query engine, and fails to honour unionGraph."
JENA-343,Use of BNodes in the WHERE part of a SPARQL Update do not behave as variables.,"Correct in Jena 2.7.3, not in Jena 2.7.4

Test case:

INSERT DATA { <x:s> <x:p> ""OLD"" }
;
DELETE { <x:s> <x:p> ""OLD"" } 
INSERT { <x:s1> <x:p1> ""NEW"" } 
WHERE { [] ?p ?o }

Output Jena 2.7.3:
<x:s1> <x:p1> ""NEW"" .

Output Jena 2.7.4:
<x:s1> <x:p1> ""OLD"" .
",Bug,"Use of BNodes in the WHERE part of a SPARQL Update do not behave as variables. Correct in Jena 2.7.3, not in Jena 2.7.4

Test case:

INSERT DATA { <x:s> <x:p> ""OLD"" }
;
DELETE { <x:s> <x:p> ""OLD"" } 
INSERT { <x:s1> <x:p1> ""NEW"" } 
WHERE { [] ?p ?o }

Output Jena 2.7.3:
<x:s1> <x:p1> ""NEW"" .

Output Jena 2.7.4:
<x:s1> <x:p1> ""OLD"" .
"
JENA-342,TDB corruption,"It seems that the TDB can corrupt data (especially blank nodes) after certain data is uploaded.

To replicate this issue, follow these steps:
1. Start Fuseki with the supplied ""config-anon.ttl"" configuration.
2. Upload ""anonymized_prior.ttl"" via the web interface.
3. Upload ""anonymized_current.ttl"" via the web interface.
3a. Executing ""SELECT ?s ?p ?o WHERE { ?s ?p ?o }"" should return content as per ""second.txt"".
4. CTRL-C the Fuseki server.
5. Restart the Fuseki server.
6. Executing ""SELECT ?s ?p ?o WHERE { ?s ?p ?o }"" should now return content as per ""after_restart.txt"".

Notes:
* I think executing the SELECT between the uploads of the file prevented the problem, but I'm not able to reproduce that reliably.
* If further data is uploaded before the CTRL-C the problem will not occur.",Bug,"TDB corruption It seems that the TDB can corrupt data (especially blank nodes) after certain data is uploaded.

To replicate this issue, follow these steps:
1. Start Fuseki with the supplied ""config-anon.ttl"" configuration.
2. Upload ""anonymized_prior.ttl"" via the web interface.
3. Upload ""anonymized_current.ttl"" via the web interface.
3a. Executing ""SELECT ?s ?p ?o WHERE { ?s ?p ?o }"" should return content as per ""second.txt"".
4. CTRL-C the Fuseki server.
5. Restart the Fuseki server.
6. Executing ""SELECT ?s ?p ?o WHERE { ?s ?p ?o }"" should now return content as per ""after_restart.txt"".

Notes:
* I think executing the SELECT between the uploads of the file prevented the problem, but I'm not able to reproduce that reliably.
* If further data is uploaded before the CTRL-C the problem will not occur."
JENA-341,Jena breaks with Xerces 2.11.0 (XML Schema 1.1 branch),"Running Jena with a Xerces 2.11.0 build which is XML Schema 1.1 aware (the xerces-java-xml-schema-1.1-dev branch) breaks with a NPE:

ERROR [my.package.MyClass:105] An exception occured during data loading
java.lang.NullPointerException
at org.apache.xerces.impl.dv.xs.XSSimpleTypeDecl.getActualValue(Unknown Source)
	at org.apache.xerces.impl.dv.xs.XSSimpleTypeDecl.validate(Unknown Source)
	at com.hp.hpl.jena.datatypes.xsd.XSDDatatype.parse(XSDDatatype.java:272)
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.setValue(LiteralLabelImpl.java:213)
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.setLiteralLabel_1(LiteralLabelImpl.java:107)
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.<init>(LiteralLabelImpl.java:96)
	at com.hp.hpl.jena.graph.impl.LiteralLabelFactory.createLiteralLabel(LiteralLabelFactory.java:28)
	at com.hp.hpl.jena.graph.Node.createLiteral(Node.java:101)
	at com.hp.hpl.jena.rdf.arp.JenaReader.convert(JenaReader.java:120)
	at com.hp.hpl.jena.rdf.arp.JenaReader.convert(JenaReader.java:143)
	at com.hp.hpl.jena.rdf.arp.JenaHandler.statement(JenaHandler.java:89)
	at com.hp.hpl.jena.rdf.arp.impl.XMLHandler.triple(XMLHandler.java:86)
	at com.hp.hpl.jena.rdf.arp.impl.ParserSupport.triple(ParserSupport.java:228)
	at com.hp.hpl.jena.rdf.arp.states.WantDescription.aPredAndObj(WantDescription.java:116)
	at com.hp.hpl.jena.rdf.arp.states.WantPropertyElement.theObject(WantPropertyElement.java:213)
	at com.hp.hpl.jena.rdf.arp.states.WantTypedLiteral.endElement(WantTypedLiteral.java:50)
	at com.hp.hpl.jena.rdf.arp.impl.XMLHandler.endElement(XMLHandler.java:133)
	at org.apache.xerces.parsers.AbstractSAXParser.endElement(Unknown Source)
	at org.apache.xerces.impl.XMLNamespaceBinder.handleEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLNamespaceBinder.endElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.DTDConfiguration.parse(Unknown Source)
	at org.apache.xerces.parsers.DTDConfiguration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at com.hp.hpl.jena.rdf.arp.impl.RDFXMLParser.parse(RDFXMLParser.java:155)
	at com.hp.hpl.jena.rdf.arp.JenaReader.read(JenaReader.java:173)
	at com.hp.hpl.jena.rdf.arp.JenaReader.read(JenaReader.java:160)
	at com.hp.hpl.jena.rdf.arp.JenaReader.read(JenaReader.java:232)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:235)
	at my.package.MyClass.load(MyClass.java:97)

The org.apache.xerces.impl.validation.ValidationState you are passing to the Xerces XSSimpleTypeDecl has a NULL TypeValidatorHelper and the Xerces build which is XML Schema 1.1 aware looks a lot in the TypeValidatorHelper to see if it is running in XML Schema 1.1 compatibility mode like:

 final String options = context.getTypeValidatorHelper().isXMLSchema11() ? ""Xbh"" : ""X"";

The class org.apache.xerces.impl.dv.xs.XSSimpleTypeDecl is an internal Xerces class. Maybe you should try breaking dependencies to internal classes.",Bug,"Jena breaks with Xerces 2.11.0 (XML Schema 1.1 branch) Running Jena with a Xerces 2.11.0 build which is XML Schema 1.1 aware (the xerces-java-xml-schema-1.1-dev branch) breaks with a NPE:

ERROR [my.package.MyClass:105] An exception occured during data loading
java.lang.NullPointerException
at org.apache.xerces.impl.dv.xs.XSSimpleTypeDecl.getActualValue(Unknown Source)
	at org.apache.xerces.impl.dv.xs.XSSimpleTypeDecl.validate(Unknown Source)
	at com.hp.hpl.jena.datatypes.xsd.XSDDatatype.parse(XSDDatatype.java:272)
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.setValue(LiteralLabelImpl.java:213)
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.setLiteralLabel_1(LiteralLabelImpl.java:107)
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.<init>(LiteralLabelImpl.java:96)
	at com.hp.hpl.jena.graph.impl.LiteralLabelFactory.createLiteralLabel(LiteralLabelFactory.java:28)
	at com.hp.hpl.jena.graph.Node.createLiteral(Node.java:101)
	at com.hp.hpl.jena.rdf.arp.JenaReader.convert(JenaReader.java:120)
	at com.hp.hpl.jena.rdf.arp.JenaReader.convert(JenaReader.java:143)
	at com.hp.hpl.jena.rdf.arp.JenaHandler.statement(JenaHandler.java:89)
	at com.hp.hpl.jena.rdf.arp.impl.XMLHandler.triple(XMLHandler.java:86)
	at com.hp.hpl.jena.rdf.arp.impl.ParserSupport.triple(ParserSupport.java:228)
	at com.hp.hpl.jena.rdf.arp.states.WantDescription.aPredAndObj(WantDescription.java:116)
	at com.hp.hpl.jena.rdf.arp.states.WantPropertyElement.theObject(WantPropertyElement.java:213)
	at com.hp.hpl.jena.rdf.arp.states.WantTypedLiteral.endElement(WantTypedLiteral.java:50)
	at com.hp.hpl.jena.rdf.arp.impl.XMLHandler.endElement(XMLHandler.java:133)
	at org.apache.xerces.parsers.AbstractSAXParser.endElement(Unknown Source)
	at org.apache.xerces.impl.XMLNamespaceBinder.handleEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLNamespaceBinder.endElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanEndElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.DTDConfiguration.parse(Unknown Source)
	at org.apache.xerces.parsers.DTDConfiguration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at com.hp.hpl.jena.rdf.arp.impl.RDFXMLParser.parse(RDFXMLParser.java:155)
	at com.hp.hpl.jena.rdf.arp.JenaReader.read(JenaReader.java:173)
	at com.hp.hpl.jena.rdf.arp.JenaReader.read(JenaReader.java:160)
	at com.hp.hpl.jena.rdf.arp.JenaReader.read(JenaReader.java:232)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:235)
	at my.package.MyClass.load(MyClass.java:97)

The org.apache.xerces.impl.validation.ValidationState you are passing to the Xerces XSSimpleTypeDecl has a NULL TypeValidatorHelper and the Xerces build which is XML Schema 1.1 aware looks a lot in the TypeValidatorHelper to see if it is running in XML Schema 1.1 compatibility mode like:

 final String options = context.getTypeValidatorHelper().isXMLSchema11() ? ""Xbh"" : ""X"";

The class org.apache.xerces.impl.dv.xs.XSSimpleTypeDecl is an internal Xerces class. Maybe you should try breaking dependencies to internal classes."
JENA-340,Quad rewrite of NOT EXISTS does not notice inner GRAPH,"Test case:

PREFIX  :   <http://example/>
SELECT *
{
   FILTER NOT EXISTS{
     GRAPH :foo { ?s ?p ?o } 
}}
==>
(prefix ((: <http://example/>))
  (filter (notexists
             (quadpattern (quad <urn:x-arq:DefaultGraphNode> ?s ?p ?o)))
    (table unit)))

Should be (quad :foo ?s ?p ?o)


Triple-based execution works; quad based execution does not.",Bug,"Quad rewrite of NOT EXISTS does not notice inner GRAPH Test case:

PREFIX  :   <http://example/>
SELECT *
{
   FILTER NOT EXISTS{
     GRAPH :foo { ?s ?p ?o } 
}}
==>
(prefix ((: <http://example/>))
  (filter (notexists
             (quadpattern (quad <urn:x-arq:DefaultGraphNode> ?s ?p ?o)))
    (table unit)))

Should be (quad :foo ?s ?p ?o)


Triple-based execution works; quad based execution does not."
JENA-335,Node.hashCode of an illegal hexBinary causes a Xerces-originated exception.,"To reproduce in Jena core:

        Node n = Node.createLiteral(""AB CD"", XSDDatatype.XSDhexBinary) ;
        n.hashCode() ;

Effect

A bad lexical form for hexBinary causes problems for TDB: 

Example data:
---- D.ttl
{{
@prefix xsd:     <http://www.w3.org/2001/XMLSchema#> .
@prefix :        <http://example/> .

:s :p ""AB CD""^^xsd:hexBinary .
## :s :p ""AB CD""^^xsd:float .
}}

tdbloader --loc DB D.ttl ==>

WARN  [line: 4, col: 7 ] Lexical form 'AB CD' not valid for datatype http://www.w3.org/2001/XMLSchema#hexBinary
http://example/s http://example/p ""AB CD""^^http://www.w3.org/2001/XMLSchema#hexBinary
com.hp.hpl.jena.datatypes.DatatypeFormatException: Lexical form 'AB CD' is not a legal instance of Datatype[http://www.w3.org/2001/XMLSchema#hexBinary] Lexical form 'AB CD' is not a legal instance of Datatype[http://www.w3.org/2001/XMLSchema#hexBinary] during parse -org.apache.xerces.impl.dv.InvalidDatatypeValueException: cvc-datatype-valid.1.2.1: 'AB CD' is not a valid value for 'hexBinary'.
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.getValue(LiteralLabelImpl.java:326)
	at com.hp.hpl.jena.datatypes.xsd.XSDhexBinary.getHashCode(XSDhexBinary.java:81)
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.hashCode(LiteralLabelImpl.java:448)
	at com.hp.hpl.jena.graph.Node.hashCode(Node.java:331)
	at java.util.HashMap.hash(HashMap.java:351)

The WARN is right - the exception should not happen.  Looks like Xerces is behaving differently because 
a bad float only causes a wanring (which is correct) and TDB continues.



",Bug,"Node.hashCode of an illegal hexBinary causes a Xerces-originated exception. To reproduce in Jena core:

        Node n = Node.createLiteral(""AB CD"", XSDDatatype.XSDhexBinary) ;
        n.hashCode() ;

Effect

A bad lexical form for hexBinary causes problems for TDB: 

Example data:
---- D.ttl
{{
@prefix xsd:     <http://www.w3.org/2001/XMLSchema#> .
@prefix :        <http://example/> .

:s :p ""AB CD""^^xsd:hexBinary .
## :s :p ""AB CD""^^xsd:float .
}}

tdbloader --loc DB D.ttl ==>

WARN  [line: 4, col: 7 ] Lexical form 'AB CD' not valid for datatype http://www.w3.org/2001/XMLSchema#hexBinary
http://example/s http://example/p ""AB CD""^^http://www.w3.org/2001/XMLSchema#hexBinary
com.hp.hpl.jena.datatypes.DatatypeFormatException: Lexical form 'AB CD' is not a legal instance of Datatype[http://www.w3.org/2001/XMLSchema#hexBinary] Lexical form 'AB CD' is not a legal instance of Datatype[http://www.w3.org/2001/XMLSchema#hexBinary] during parse -org.apache.xerces.impl.dv.InvalidDatatypeValueException: cvc-datatype-valid.1.2.1: 'AB CD' is not a valid value for 'hexBinary'.
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.getValue(LiteralLabelImpl.java:326)
	at com.hp.hpl.jena.datatypes.xsd.XSDhexBinary.getHashCode(XSDhexBinary.java:81)
	at com.hp.hpl.jena.graph.impl.LiteralLabelImpl.hashCode(LiteralLabelImpl.java:448)
	at com.hp.hpl.jena.graph.Node.hashCode(Node.java:331)
	at java.util.HashMap.hash(HashMap.java:351)

The WARN is right - the exception should not happen.  Looks like Xerces is behaving differently because 
a bad float only causes a wanring (which is correct) and TDB continues.



"
JENA-332,Error in config.ttl file for fuseki,"In the config.ttl file that is bundled in jena-fuseki-0.2.4-distribution.zip , the dataset for books in defined as follows. 

<#books>    rdf:type ja:RDFDataset ;
    rdfs:label ""Books"" ;
    ja:defaultGraph 
      [ rdfs:label ""books.ttl"" ;
        a ja:MemoryModel ;
        ja:content [ja:externalContent <file:Data/books.ttl> ] ;
      ] ;
    .

But there is no such file   <file:Data/books.ttl> in the zip.  

So we get the following error.

com.hp.hpl.jena.assembler.exceptions.AssemblerException: caught: Not found: file
:///C%3A/Softwares/fuseki/jena-fuseki-0.2.4-distribution/jena-fuseki-0.2.4-SNAPS
HOT/Data/books.ttl


The definition should be changed to 

<#books>    rdf:type ja:RDFDataset ;
    rdfs:label ""Books"" ;
    ja:defaultGraph 
      [ rdfs:label ""books.ttl"" ;
        a ja:MemoryModel ;
        ja:content [ja:externalContent <file:pages/books.ttl> ] ;
      ] ;

",Bug,"Error in config.ttl file for fuseki In the config.ttl file that is bundled in jena-fuseki-0.2.4-distribution.zip , the dataset for books in defined as follows. 

<#books>    rdf:type ja:RDFDataset ;
    rdfs:label ""Books"" ;
    ja:defaultGraph 
      [ rdfs:label ""books.ttl"" ;
        a ja:MemoryModel ;
        ja:content [ja:externalContent <file:Data/books.ttl> ] ;
      ] ;
    .

But there is no such file   <file:Data/books.ttl> in the zip.  

So we get the following error.

com.hp.hpl.jena.assembler.exceptions.AssemblerException: caught: Not found: file
:///C%3A/Softwares/fuseki/jena-fuseki-0.2.4-distribution/jena-fuseki-0.2.4-SNAPS
HOT/Data/books.ttl


The definition should be changed to 

<#books>    rdf:type ja:RDFDataset ;
    rdfs:label ""Books"" ;
    ja:defaultGraph 
      [ rdfs:label ""books.ttl"" ;
        a ja:MemoryModel ;
        ja:content [ja:externalContent <file:pages/books.ttl> ] ;
      ] ;

"
JENA-326,NTripleReader needs a null-guard,"com.hp.hpl.jena.rdf.model.impl.NTripleReader.java line 140 has 


                try {
                    predicate = model.createProperty(readResource().getURI());
                } catch (Exception e1) {
                    errorHandler.fatalError(e1);
                }

In readResource() there is 
        if (badEOF())
            return null;

So when my test attempts to read truncated XML as NTriple, I get a null pointer exception. Other conditions in readResource() throw SyntaxErrors before returning, so that may be missing from this condtition.",Bug,"NTripleReader needs a null-guard com.hp.hpl.jena.rdf.model.impl.NTripleReader.java line 140 has 


                try {
                    predicate = model.createProperty(readResource().getURI());
                } catch (Exception e1) {
                    errorHandler.fatalError(e1);
                }

In readResource() there is 
        if (badEOF())
            return null;

So when my test attempts to read truncated XML as NTriple, I get a null pointer exception. Other conditions in readResource() throw SyntaxErrors before returning, so that may be missing from this condtition."
JENA-325,fuseki server corrupts TDB when killed,"if fuseki uses TDB store and killed by SIGINT, then TDB gets corrupted.

How to reproduce:

./fuseki-server --update --loc=qdb /ds

Either
rupdate --service=http://localhost:3030/ds/update --update=q.ru

Then Control-C to kill fuseki server.

Then after restart it either missing triples or corrupted index(i guess, because fuseki server gets exception on access to TDB).

I create TDB using tdbloader from a file. it doesn't matter i guess.



 ",Bug,"fuseki server corrupts TDB when killed if fuseki uses TDB store and killed by SIGINT, then TDB gets corrupted.

How to reproduce:

./fuseki-server --update --loc=qdb /ds

Either
rupdate --service=http://localhost:3030/ds/update --update=q.ru

Then Control-C to kill fuseki server.

Then after restart it either missing triples or corrupted index(i guess, because fuseki server gets exception on access to TDB).

I create TDB using tdbloader from a file. it doesn't matter i guess.



 "
JENA-324,An exception thrown from commit() leaves the StoreConnection in an inconsistent state.,"An exception thrown from commit() leaves the StoreConnection in an inconsistent state.

Example: After a commit() throws an IOException in prepare() due to insufficient disk space, I see the following behavior:
    dataset.isInTransaction() == false
    dataset.abort() throws TDBTransactionException: ""Transaction has already committed or aborted""
    dataset.end() appears OK
    dataset.begin(ReadWrite.READ) appears OK
    dataset.begin(ReadWrite.WRITE) blocks on writersWaiting.acquire()

 
The debugger shows that the transaction is stuck in limbo: active, closed, and unfinished.
    TransactionManager.activeWriters: 1
    TransactionManager.activeTransactions: 1
        [Transaction: 151 : Mode=WRITE : State=CLOSED : X:\RELM1\]
            changesPending=true
            outcome=UNFINISHED


Short of a fix, it looks like the only option to clear the stuck transaction is StoreConnection.expel(location, true), which has the comment ""testing only"".


There's also the indeterminacy of ending a transaction that, as far as I can tell at the Dataset level, may or may not be committed (""Transaction has already committed or aborted"").

Rough outline of a commit:
    state == TxnState.PREPARING
    -- commitPrepare()
    -- journal.write()
    -- journal.sync() // Commit point.
    state == TxnState.COMMITED
    -- noteTxnCommit()
    -- currentReaderView.set(null)
    -- writersWaiting.release()

noteTxnCommit() is called after the commit and performs IO, so it appears that if commit() throws an exception, it's not necessarily true that the transaction is effectively aborted.",Bug,"An exception thrown from commit() leaves the StoreConnection in an inconsistent state. An exception thrown from commit() leaves the StoreConnection in an inconsistent state.

Example: After a commit() throws an IOException in prepare() due to insufficient disk space, I see the following behavior:
    dataset.isInTransaction() == false
    dataset.abort() throws TDBTransactionException: ""Transaction has already committed or aborted""
    dataset.end() appears OK
    dataset.begin(ReadWrite.READ) appears OK
    dataset.begin(ReadWrite.WRITE) blocks on writersWaiting.acquire()

 
The debugger shows that the transaction is stuck in limbo: active, closed, and unfinished.
    TransactionManager.activeWriters: 1
    TransactionManager.activeTransactions: 1
        [Transaction: 151 : Mode=WRITE : State=CLOSED : X:\RELM1\]
            changesPending=true
            outcome=UNFINISHED


Short of a fix, it looks like the only option to clear the stuck transaction is StoreConnection.expel(location, true), which has the comment ""testing only"".


There's also the indeterminacy of ending a transaction that, as far as I can tell at the Dataset level, may or may not be committed (""Transaction has already committed or aborted"").

Rough outline of a commit:
    state == TxnState.PREPARING
    -- commitPrepare()
    -- journal.write()
    -- journal.sync() // Commit point.
    state == TxnState.COMMITED
    -- noteTxnCommit()
    -- currentReaderView.set(null)
    -- writersWaiting.release()

noteTxnCommit() is called after the commit and performs IO, so it appears that if commit() throws an exception, it's not necessarily true that the transaction is effectively aborted."
JENA-322,rupdate requires commoms-loggings,"rupdate exception 


Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/commons/logging/LogFactory
	at org.apache.http.impl.client.AbstractHttpClient.<init>(AbstractHttpClient.java:182)
	at org.apache.http.impl.client.DefaultHttpClient.<init>(DefaultHttpClient.java:150)
	at org.openjena.riot.web.HttpOp.execHttpPost(HttpOp.java:206)
	at org.openjena.riot.web.HttpOp.execHttpPost(HttpOp.java:154)
	at org.openjena.riot.web.HttpOp.execHttpPost(HttpOp.java:128)
	at com.hp.hpl.jena.sparql.modify.UpdateProcessRemote.execute(UpdateProcessRemote.java:60)
	at arq.rupdate.exec(rupdate.java:97)
	at arq.rupdate.exec(rupdate.java:82)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:101)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:63)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:50)
	at arq.rupdate.main(rupdate.java:44)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.logging.LogFactory
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
	... 12 more

Putting commons-logging.1.1.1.jar into lib directory fixes the problem
",Bug,"rupdate requires commoms-loggings rupdate exception 


Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/commons/logging/LogFactory
	at org.apache.http.impl.client.AbstractHttpClient.<init>(AbstractHttpClient.java:182)
	at org.apache.http.impl.client.DefaultHttpClient.<init>(DefaultHttpClient.java:150)
	at org.openjena.riot.web.HttpOp.execHttpPost(HttpOp.java:206)
	at org.openjena.riot.web.HttpOp.execHttpPost(HttpOp.java:154)
	at org.openjena.riot.web.HttpOp.execHttpPost(HttpOp.java:128)
	at com.hp.hpl.jena.sparql.modify.UpdateProcessRemote.execute(UpdateProcessRemote.java:60)
	at arq.rupdate.exec(rupdate.java:97)
	at arq.rupdate.exec(rupdate.java:82)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:101)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:63)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:50)
	at arq.rupdate.main(rupdate.java:44)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.logging.LogFactory
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
	... 12 more

Putting commons-logging.1.1.1.jar into lib directory fixes the problem
"
JENA-320,Unexpected result from SPARQL Tutorial - Filters,"The ""Testing Values"" section of the Apache Jena ""SPARQL Tutorial - Filters"" page(http://jena.apache.org/tutorials/sparql_filters.html) does not produce the expected results. I made sure to pull the example files from the site to ensure the issue was not due to typos in transcription:

$ wget ""http://jena.apache.org/tutorials/sparql_data/vc-db-2.rdf""
--2012-09-04 10:47:20-- http://jena.apache.org/tutorials/sparql_data/vc-db-2.rdf
Resolving jena.apache.org... 140.211.11.131, 192.87.106.229,2001:610:1:80bc:192:87:106:229
Connecting to jena.apache.org|140.211.11.131|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1149 (1.1K) [application/rdf+xml]
Saving to: `vc-db-2.rdf'
100%[=================================================================>] 1,149--.-K/s in 0s
2012-09-04 10:47:20 (99.6 MB/s) - `vc-db-2.rdf' saved [1149/1149]

$ wget ""http://jena.apache.org/tutorials/sparql_data/q-f2.rq""
--2012-09-04 10:48:03-- http://jena.apache.org/tutorials/sparql_data/q-f2.rq
Resolving jena.apache.org... 140.211.11.131, 192.87.106.229,2001:610:1:80bc:192:87:106:229
Connecting to jena.apache.org|140.211.11.131|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 148 [application/sparql-query]
Saving to: `q-f2.rq'
100%[=================================================================>] 148--.-K/s in 0s
2012-09-04 10:48:03 (990 KB/s) - `q-f2.rq' saved [148/148]

I then used the following query command:

$ sparql --data=vc-db-2.rdf --query=q-f2.rq
------------
| resource |
============
------------

The Tutorial page indicates that the result should have been:

---------------------------------
| resource |
=================================
| <http://somewhere/JohnSmith/> |
---------------------------------",Bug,"Unexpected result from SPARQL Tutorial - Filters The ""Testing Values"" section of the Apache Jena ""SPARQL Tutorial - Filters"" page(http://jena.apache.org/tutorials/sparql_filters.html) does not produce the expected results. I made sure to pull the example files from the site to ensure the issue was not due to typos in transcription:

$ wget ""http://jena.apache.org/tutorials/sparql_data/vc-db-2.rdf""
--2012-09-04 10:47:20-- http://jena.apache.org/tutorials/sparql_data/vc-db-2.rdf
Resolving jena.apache.org... 140.211.11.131, 192.87.106.229,2001:610:1:80bc:192:87:106:229
Connecting to jena.apache.org|140.211.11.131|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1149 (1.1K) [application/rdf+xml]
Saving to: `vc-db-2.rdf'
100%[=================================================================>] 1,149--.-K/s in 0s
2012-09-04 10:47:20 (99.6 MB/s) - `vc-db-2.rdf' saved [1149/1149]

$ wget ""http://jena.apache.org/tutorials/sparql_data/q-f2.rq""
--2012-09-04 10:48:03-- http://jena.apache.org/tutorials/sparql_data/q-f2.rq
Resolving jena.apache.org... 140.211.11.131, 192.87.106.229,2001:610:1:80bc:192:87:106:229
Connecting to jena.apache.org|140.211.11.131|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 148 [application/sparql-query]
Saving to: `q-f2.rq'
100%[=================================================================>] 148--.-K/s in 0s
2012-09-04 10:48:03 (990 KB/s) - `q-f2.rq' saved [148/148]

I then used the following query command:

$ sparql --data=vc-db-2.rdf --query=q-f2.rq
------------
| resource |
============
------------

The Tutorial page indicates that the result should have been:

---------------------------------
| resource |
=================================
| <http://somewhere/JohnSmith/> |
---------------------------------"
JENA-319,"If the URI for the named graph in a Dataset does not contain a colon "":"" it is accepted but can not be retrieved.","If dataset.addNamedModel(uri, m) is called and 'uri' does not have a colon the query select * { graph <uri> { ?s ?o ?p }} does not return any results even though select ?g { graph ?g { ?s ?o ?p }} will return the uri as ?g.

JUnit based test case attached.",Bug,"If the URI for the named graph in a Dataset does not contain a colon "":"" it is accepted but can not be retrieved. If dataset.addNamedModel(uri, m) is called and 'uri' does not have a colon the query select * { graph <uri> { ?s ?o ?p }} does not return any results even though select ?g { graph ?g { ?s ?o ?p }} will return the uri as ?g.

JUnit based test case attached."
JENA-318,Illegal language tags (in RDF/XML) can cause exceptions in Fuseki+TDB.,"(split from JENA-163)

Alexander Dutton writes:

It seems to be the following language tags in the data that cause this issue:

* i18n
* sr@latin

Both have invalid syntax as per BCP 47, but it might be worth catching this a little earlier and throwing a more appropriate error:

[alex@lucy jena-fuseki-0.2.4]$ curl -XPUT ""http://localhost:3030/public/data?graph=http://creativecommons.org/publicdomain/zero/1.0/rdf"" -d@rdf -H""Content-type: application/rdf+xml"" -i
HTTP/1.1 100 Continue

HTTP/1.1 500 Different ids for http://xmlns.com/foaf/0.1/logo: allocated: expected [000000000000041D], got [000000000000041A]
Access-Control-Allow-Origin: *
Server: Fuseki (0.2.4)
Content-Length: 0
",Bug,"Illegal language tags (in RDF/XML) can cause exceptions in Fuseki+TDB. (split from JENA-163)

Alexander Dutton writes:

It seems to be the following language tags in the data that cause this issue:

* i18n
* sr@latin

Both have invalid syntax as per BCP 47, but it might be worth catching this a little earlier and throwing a more appropriate error:

[alex@lucy jena-fuseki-0.2.4]$ curl -XPUT ""http://localhost:3030/public/data?graph=http://creativecommons.org/publicdomain/zero/1.0/rdf"" -d@rdf -H""Content-type: application/rdf+xml"" -i
HTTP/1.1 100 Continue

HTTP/1.1 500 Different ids for http://xmlns.com/foaf/0.1/logo: allocated: expected [000000000000041D], got [000000000000041A]
Access-Control-Allow-Origin: *
Server: Fuseki (0.2.4)
Content-Length: 0
"
JENA-317,xsd:decimal value does not roundtrip through inlining,"        Node n = SSE.parseNode(""2412.80478192688"") ;
        System.out.println(FmtUtils.stringForNode(n)) ;
        NodeId nid = NodeId.inline(n) ;
        System.out.printf(""0x%08X\n"", nid.getId()) ;
        Node n2 = NodeId.extract(nid) ;
        System.out.println(FmtUtils.stringForNode(n2)) ;",Bug,"xsd:decimal value does not roundtrip through inlining         Node n = SSE.parseNode(""2412.80478192688"") ;
        System.out.println(FmtUtils.stringForNode(n)) ;
        NodeId nid = NodeId.inline(n) ;
        System.out.printf(""0x%08X\n"", nid.getId()) ;
        Node n2 = NodeId.extract(nid) ;
        System.out.println(FmtUtils.stringForNode(n2)) ;"
JENA-315,Jena API code not always closing internally used iterators.,"Suggestions copied from users@ email list.
",Bug,"Jena API code not always closing internally used iterators. Suggestions copied from users@ email list.
"
JENA-314,RDFWriterFImpl.getWriter() does not work for all Lang values.,"Model.getWriter( Lang.NQUADS ) and Model.getWriter( Lang.TRIG ) fail with NoWriterForLanguageException.

Error appears to be in RDFWriterFImpl.getWriter()",Bug,"RDFWriterFImpl.getWriter() does not work for all Lang values. Model.getWriter( Lang.NQUADS ) and Model.getWriter( Lang.TRIG ) fail with NoWriterForLanguageException.

Error appears to be in RDFWriterFImpl.getWriter()"
JENA-313,"Lang.get( ""N3"" ) fails",Lang.get( N3.name() ) fails to find the N3 Lang,Bug,"Lang.get( ""N3"" ) fails Lang.get( N3.name() ) fails to find the N3 Lang"
JENA-311,Quad: object cannot be null,"I have attached a test case. If you first execute it and then execute it again you will hit

Exception in thread ""main"" java.lang.UnsupportedOperationException: Quad: object cannot be null
	at com.hp.hpl.jena.sparql.core.Quad.<init>(Quad.java:62)
	at com.hp.hpl.jena.tdb.lib.TupleLib.quad(TupleLib.java:162)
	at com.hp.hpl.jena.tdb.lib.TupleLib.quad(TupleLib.java:153)
	at com.hp.hpl.jena.tdb.lib.TupleLib.access$1(TupleLib.java:149)
	at com.hp.hpl.jena.tdb.lib.TupleLib$4.convert(TupleLib.java:87)
	at com.hp.hpl.jena.tdb.lib.TupleLib$4.convert(TupleLib.java:1)
	at org.openjena.atlas.iterator.Iter$4.next(Iter.java:301)
	at org.openjena.atlas.iterator.IteratorCons.next(IteratorCons.java:97)
	at org.openjena.atlas.iterator.Iter.sendToSink(Iter.java:572)
	at org.openjena.riot.out.NQuadsWriter.write(NQuadsWriter.java:51)
	at org.openjena.riot.out.NQuadsWriter.write(NQuadsWriter.java:38)
	at org.openjena.riot.RiotWriter.writeNQuads(RiotWriter.java:41)
	at com.ibm.jena.test.QuadsObjectIsNullTest.main(QuadsObjectIsNullTest.java:147)
",Bug,"Quad: object cannot be null I have attached a test case. If you first execute it and then execute it again you will hit

Exception in thread ""main"" java.lang.UnsupportedOperationException: Quad: object cannot be null
	at com.hp.hpl.jena.sparql.core.Quad.<init>(Quad.java:62)
	at com.hp.hpl.jena.tdb.lib.TupleLib.quad(TupleLib.java:162)
	at com.hp.hpl.jena.tdb.lib.TupleLib.quad(TupleLib.java:153)
	at com.hp.hpl.jena.tdb.lib.TupleLib.access$1(TupleLib.java:149)
	at com.hp.hpl.jena.tdb.lib.TupleLib$4.convert(TupleLib.java:87)
	at com.hp.hpl.jena.tdb.lib.TupleLib$4.convert(TupleLib.java:1)
	at org.openjena.atlas.iterator.Iter$4.next(Iter.java:301)
	at org.openjena.atlas.iterator.IteratorCons.next(IteratorCons.java:97)
	at org.openjena.atlas.iterator.Iter.sendToSink(Iter.java:572)
	at org.openjena.riot.out.NQuadsWriter.write(NQuadsWriter.java:51)
	at org.openjena.riot.out.NQuadsWriter.write(NQuadsWriter.java:38)
	at org.openjena.riot.RiotWriter.writeNQuads(RiotWriter.java:41)
	at com.ibm.jena.test.QuadsObjectIsNullTest.main(QuadsObjectIsNullTest.java:147)
"
JENA-310,Algebra#exec cannot be used within a transaction,"When Algebra#exec is used within a transaction I get:

Exception in thread ""main"" java.lang.ClassCastException: com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction cannot be cast to com.hp.hpl.jena.tdb.store.DatasetGraphTDB",Bug,"Algebra#exec cannot be used within a transaction When Algebra#exec is used within a transaction I get:

Exception in thread ""main"" java.lang.ClassCastException: com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction cannot be cast to com.hp.hpl.jena.tdb.store.DatasetGraphTDB"
JENA-308,Index corruption after killing process,"We are faced with a series of possible exceptions which may or may not occur after an active tdb store is killed. The most common exception has the form:

Exception in thread ""Thread-3"" com.hp.hpl.jena.tdb.transaction.TDBTransactionException: Feaild to read block checksum.
	at com.hp.hpl.jena.tdb.transaction.Journal._read(Journal.java:238)
	at com.hp.hpl.jena.tdb.transaction.Journal._readJournal(Journal.java:197)
	at com.hp.hpl.jena.tdb.transaction.Journal.access$1(Journal.java:192)
	at com.hp.hpl.jena.tdb.transaction.Journal$IteratorEntries.moveToNext(Journal.java:267)
	at com.hp.hpl.jena.tdb.transaction.Journal$IteratorEntries.moveToNext(Journal.java:1)
	at org.openjena.atlas.iterator.IteratorSlotted.hasNext(IteratorSlotted.java:67)
	at com.hp.hpl.jena.tdb.transaction.JournalControl.scanForCommit(JournalControl.java:148)
	at com.hp.hpl.jena.tdb.transaction.JournalControl.recoverFromJournal(JournalControl.java:127)
	at com.hp.hpl.jena.tdb.StoreConnection._makeAndCache(StoreConnection.java:234)
	at com.hp.hpl.jena.tdb.StoreConnection.make(StoreConnection.java:214)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction.<init>(DatasetGraphTransaction.java:76)
	at com.hp.hpl.jena.tdb.sys.TDBMaker._create(TDBMaker.java:57)
	at com.hp.hpl.jena.tdb.sys.TDBMaker.createDatasetGraphTransaction(TDBMaker.java:45)
	at com.hp.hpl.jena.tdb.TDBFactory._createDatasetGraph(TDBFactory.java:104)
	at com.hp.hpl.jena.tdb.TDBFactory.createDatasetGraph(TDBFactory.java:73)
	at com.hp.hpl.jena.tdb.TDBFactory.createDataset(TDBFactory.java:52)

Other exceptions are possible (see comments below). I have been able to produce a standalone java program/test case which simulates a process kill and is able to produce the exception after a non-deterministic time. It runs an iteration until it hits one of the possible problems. Sometimes, an exception hits after just 2 iterations, other times, it can take 40 runs or more before hitting a problem. Because I don't know what the cause is here, I have not been able to make the test case more specific",Bug,"Index corruption after killing process We are faced with a series of possible exceptions which may or may not occur after an active tdb store is killed. The most common exception has the form:

Exception in thread ""Thread-3"" com.hp.hpl.jena.tdb.transaction.TDBTransactionException: Feaild to read block checksum.
	at com.hp.hpl.jena.tdb.transaction.Journal._read(Journal.java:238)
	at com.hp.hpl.jena.tdb.transaction.Journal._readJournal(Journal.java:197)
	at com.hp.hpl.jena.tdb.transaction.Journal.access$1(Journal.java:192)
	at com.hp.hpl.jena.tdb.transaction.Journal$IteratorEntries.moveToNext(Journal.java:267)
	at com.hp.hpl.jena.tdb.transaction.Journal$IteratorEntries.moveToNext(Journal.java:1)
	at org.openjena.atlas.iterator.IteratorSlotted.hasNext(IteratorSlotted.java:67)
	at com.hp.hpl.jena.tdb.transaction.JournalControl.scanForCommit(JournalControl.java:148)
	at com.hp.hpl.jena.tdb.transaction.JournalControl.recoverFromJournal(JournalControl.java:127)
	at com.hp.hpl.jena.tdb.StoreConnection._makeAndCache(StoreConnection.java:234)
	at com.hp.hpl.jena.tdb.StoreConnection.make(StoreConnection.java:214)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction.<init>(DatasetGraphTransaction.java:76)
	at com.hp.hpl.jena.tdb.sys.TDBMaker._create(TDBMaker.java:57)
	at com.hp.hpl.jena.tdb.sys.TDBMaker.createDatasetGraphTransaction(TDBMaker.java:45)
	at com.hp.hpl.jena.tdb.TDBFactory._createDatasetGraph(TDBFactory.java:104)
	at com.hp.hpl.jena.tdb.TDBFactory.createDatasetGraph(TDBFactory.java:73)
	at com.hp.hpl.jena.tdb.TDBFactory.createDataset(TDBFactory.java:52)

Other exceptions are possible (see comments below). I have been able to produce a standalone java program/test case which simulates a process kill and is able to produce the exception after a non-deterministic time. It runs an iteration until it hits one of the possible problems. Sometimes, an exception hits after just 2 iterations, other times, it can take 40 runs or more before hitting a problem. Because I don't know what the cause is here, I have not been able to make the test case more specific"
JENA-304,unionDefaultGraph affects dynamic named dataset,"I am attaching a small set of n-quads. The following query

PREFIX p: <http://test.net/xmlns/indexing/v0.6/people_8Zu_BuiWEeGkOrh5i1Iazg#> 
PREFIX dc: <http://purl.org/dc/terms/> 
SELECT ?last 
FROM NAMED <https://localhost:9443/test/storage/IndexingAndQueryTests_test034_namedGraphsc07c8c3c-9cbc-4a76-9899-69714abf1e1e/people-02.xml> 
WHERE {  ?x dc:isPartOf <https://front.side/test/people> ; p:lastname ?last  } 
ORDER BY ?last 

returns 1 result when executed with unionDefaultGraph=true, but 0 results when unionDefaultGraph=false.",Bug,"unionDefaultGraph affects dynamic named dataset I am attaching a small set of n-quads. The following query

PREFIX p: <http://test.net/xmlns/indexing/v0.6/people_8Zu_BuiWEeGkOrh5i1Iazg#> 
PREFIX dc: <http://purl.org/dc/terms/> 
SELECT ?last 
FROM NAMED <https://localhost:9443/test/storage/IndexingAndQueryTests_test034_namedGraphsc07c8c3c-9cbc-4a76-9899-69714abf1e1e/people-02.xml> 
WHERE {  ?x dc:isPartOf <https://front.side/test/people> ; p:lastname ?last  } 
ORDER BY ?last 

returns 1 result when executed with unionDefaultGraph=true, but 0 results when unionDefaultGraph=false."
JENA-301,RecordRangeIterator: records not strictly increasing,"When I tried to execute the provided test case for JENA-256, I ran into a TDB Storage Exception. The scenario is like this

1) run the test application on a clean non-existing index. All should go well, i.e. not exceptions, tests finish fine
2) then run the test application again on the same index. You'll end up with the following stack trace at write operation 98:

xception in thread ""main"" java.lang.RuntimeException: com.hp.hpl.jena.tdb.base.StorageException: RecordRangeIterator: records not strictly increasing: 00000000000020ba000000000000002400000000000001490000000000000ad3 // 00000000000008bc000000000000002400000000000001490000000000000271
	at com.ibm.jena.test.PerformanceRegressionTest.main(PerformanceRegressionTest.java:101)
Caused by: com.hp.hpl.jena.tdb.base.StorageException: RecordRangeIterator: records not strictly increasing: 00000000000020ba000000000000002400000000000001490000000000000ad3 // 00000000000008bc000000000000002400000000000001490000000000000271
	at com.hp.hpl.jena.tdb.base.recordbuffer.RecordRangeIterator.hasNext(RecordRangeIterator.java:124)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:295)
	at com.hp.hpl.jena.tdb.sys.DatasetControlMRSW$IteratorCheckNotConcurrent.hasNext(DatasetControlMRSW.java:119)
	at com.hp.hpl.jena.tdb.graph.BulkUpdateHandlerTDB.removeWorker(BulkUpdateHandlerTDB.java:142)
	at com.hp.hpl.jena.tdb.graph.BulkUpdateHandlerTDB.removeAll(BulkUpdateHandlerTDB.java:102)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.removeAll(ModelCom.java:372)
	at com.ibm.jena.test.PerformanceRegressionTest.main(PerformanceRegressionTest.java:78)

The issue seems reproducible (I have seen it 3 times in a row when following the scenario as described). Although I think this is exactly the same test application as in JENA-256, I'll add it again for completeness",Bug,"RecordRangeIterator: records not strictly increasing When I tried to execute the provided test case for JENA-256, I ran into a TDB Storage Exception. The scenario is like this

1) run the test application on a clean non-existing index. All should go well, i.e. not exceptions, tests finish fine
2) then run the test application again on the same index. You'll end up with the following stack trace at write operation 98:

xception in thread ""main"" java.lang.RuntimeException: com.hp.hpl.jena.tdb.base.StorageException: RecordRangeIterator: records not strictly increasing: 00000000000020ba000000000000002400000000000001490000000000000ad3 // 00000000000008bc000000000000002400000000000001490000000000000271
	at com.ibm.jena.test.PerformanceRegressionTest.main(PerformanceRegressionTest.java:101)
Caused by: com.hp.hpl.jena.tdb.base.StorageException: RecordRangeIterator: records not strictly increasing: 00000000000020ba000000000000002400000000000001490000000000000ad3 // 00000000000008bc000000000000002400000000000001490000000000000271
	at com.hp.hpl.jena.tdb.base.recordbuffer.RecordRangeIterator.hasNext(RecordRangeIterator.java:124)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:295)
	at com.hp.hpl.jena.tdb.sys.DatasetControlMRSW$IteratorCheckNotConcurrent.hasNext(DatasetControlMRSW.java:119)
	at com.hp.hpl.jena.tdb.graph.BulkUpdateHandlerTDB.removeWorker(BulkUpdateHandlerTDB.java:142)
	at com.hp.hpl.jena.tdb.graph.BulkUpdateHandlerTDB.removeAll(BulkUpdateHandlerTDB.java:102)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.removeAll(ModelCom.java:372)
	at com.ibm.jena.test.PerformanceRegressionTest.main(PerformanceRegressionTest.java:78)

The issue seems reproducible (I have seen it 3 times in a row when following the scenario as described). Although I think this is exactly the same test application as in JENA-256, I'll add it again for completeness"
JENA-299,LeaveCriticalSection Error,"I have attached a standalone test case, which, when run with the latest snapshot produces the following exception:

Exception in thread ""main"" com.hp.hpl.jena.shared.JenaException: leaveCriticalSection: No lock held (main) Thread R/W: 0/0 :: Model R/W: 0/0 (thread: main)
	at com.hp.hpl.jena.shared.LockMRSW.leaveCriticalSection(LockMRSW.java:175)
	at com.hp.hpl.jena.tdb.transaction.TransactionManager$TSM_WriteBackEndTxn.readerFinishes(TransactionManager.java:210)
	at com.hp.hpl.jena.tdb.transaction.TransactionManager.readerFinishes(TransactionManager.java:723)
	at com.hp.hpl.jena.tdb.transaction.TransactionManager.noteTxnAbort(TransactionManager.java:587)
	at com.hp.hpl.jena.tdb.transaction.TransactionManager.notifyAbort(TransactionManager.java:445)
	at com.hp.hpl.jena.tdb.transaction.Transaction.abort(Transaction.java:162)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.abort(DatasetGraphTxn.java:45)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._abort(DatasetGraphTransaction.java:156)
	at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.abort(DatasetGraphTrackActive.java:68)
	at com.hp.hpl.jena.sparql.core.DatasetImpl.abort(DatasetImpl.java:149)
	at com.ibm.jena.test.LeaveCriticalSectionErrorTest.storeOperation(LeaveCriticalSectionErrorTest.java:57)
	at com.ibm.jena.test.LeaveCriticalSectionErrorTest.query1(LeaveCriticalSectionErrorTest.java:105)
	at com.ibm.jena.test.LeaveCriticalSectionErrorTest.main(LeaveCriticalSectionErrorTest.java:156)

The sequence in the test case is to run 2 queries, 1 write and then again 2 queries:

	test.query1();
		test.query1();
		test.write1();
		test.query1();
		test.query1();

Somehow, the following sequence did not produce the exception:

	test.query1();
		test.query1();
		test.write1();
		test.query1();

Note that the test case does not check the correctness of any results.",Bug,"LeaveCriticalSection Error I have attached a standalone test case, which, when run with the latest snapshot produces the following exception:

Exception in thread ""main"" com.hp.hpl.jena.shared.JenaException: leaveCriticalSection: No lock held (main) Thread R/W: 0/0 :: Model R/W: 0/0 (thread: main)
	at com.hp.hpl.jena.shared.LockMRSW.leaveCriticalSection(LockMRSW.java:175)
	at com.hp.hpl.jena.tdb.transaction.TransactionManager$TSM_WriteBackEndTxn.readerFinishes(TransactionManager.java:210)
	at com.hp.hpl.jena.tdb.transaction.TransactionManager.readerFinishes(TransactionManager.java:723)
	at com.hp.hpl.jena.tdb.transaction.TransactionManager.noteTxnAbort(TransactionManager.java:587)
	at com.hp.hpl.jena.tdb.transaction.TransactionManager.notifyAbort(TransactionManager.java:445)
	at com.hp.hpl.jena.tdb.transaction.Transaction.abort(Transaction.java:162)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.abort(DatasetGraphTxn.java:45)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._abort(DatasetGraphTransaction.java:156)
	at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.abort(DatasetGraphTrackActive.java:68)
	at com.hp.hpl.jena.sparql.core.DatasetImpl.abort(DatasetImpl.java:149)
	at com.ibm.jena.test.LeaveCriticalSectionErrorTest.storeOperation(LeaveCriticalSectionErrorTest.java:57)
	at com.ibm.jena.test.LeaveCriticalSectionErrorTest.query1(LeaveCriticalSectionErrorTest.java:105)
	at com.ibm.jena.test.LeaveCriticalSectionErrorTest.main(LeaveCriticalSectionErrorTest.java:156)

The sequence in the test case is to run 2 queries, 1 write and then again 2 queries:

	test.query1();
		test.query1();
		test.write1();
		test.query1();
		test.query1();

Somehow, the following sequence did not produce the exception:

	test.query1();
		test.query1();
		test.write1();
		test.query1();

Note that the test case does not check the correctness of any results."
JENA-297,N3 Parser and escaped ( %3A ) colon ,"Having the following n3 file, I get a tottaly different behaviour when calling getNameSpace() and getLocalName for the resources.

For resource:
<http://aNameSpace/TestWith%3AColon> 
I get:
namespace: http://aNameSpace/TestWith%3A
LocalName: Colon


For resource:
<http://aNameSpace/TestWith3AColon> 
I get:
namespace: http://aNameSpace/
LocalName: TestWith3AColon

First one is wrong, second is correct. ",Bug,"N3 Parser and escaped ( %3A ) colon  Having the following n3 file, I get a tottaly different behaviour when calling getNameSpace() and getLocalName for the resources.

For resource:
<http://aNameSpace/TestWith%3AColon> 
I get:
namespace: http://aNameSpace/TestWith%3A
LocalName: Colon


For resource:
<http://aNameSpace/TestWith3AColon> 
I get:
namespace: http://aNameSpace/
LocalName: TestWith3AColon

First one is wrong, second is correct. "
JENA-296,tdb.TS_TDBLoader3 test fails in Windows,"The tdb.TS_TDBLoader3 test fails in Windows.  See stacktrace [1].

Work-around: run maven with ""-DskipTests"" command line argument.


[1] Stacktrace from failing test:

Running tdb.TS_TDBLoader3
09:51:28 ERROR BPlusTreeRewriter         :: **** Not the root: 1024
com.hp.hpl.jena.tdb.index.bplustree.BPTreeException
        at com.hp.hpl.jena.tdb.index.bplustree.BPlusTreeRewriter.packIntoBPlusTree(BPlusTreeRewriter.java:89)
        at org.apache.jena.tdb.store.bulkloader3.NodeTableBuilder2.buildNodeTableBPTreeIndex(NodeTableBuilder2.java:296)
        at org.apache.jena.tdb.store.bulkloader3.NodeTableBuilder2.close(NodeTableBuilder2.java:172)
        at tdb.tdbloader3.exec(tdbloader3.java:216)
        at arq.cmdline.CmdMain.mainMethod(CmdMain.java:101)
        at arq.cmdline.CmdMain.mainRun(CmdMain.java:63)
        at arq.cmdline.CmdMain.mainRun(CmdMain.java:50)
        at tdb.tdbloader3.main(tdbloader3.java:108)
        at tdb.TestTDBLoader3.run(TestTDBLoader3.java:120)
        at tdb.TestTDBLoader3.test(TestTDBLoader3.java:88)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:69)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:48)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:292)
        at org.junit.runners.Suite.runChild(Suite.java:128)
        at org.junit.runners.Suite.runChild(Suite.java:24)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:292)
        at org.junit.runners.Suite.runChild(Suite.java:128)
        at org.junit.runners.Suite.runChild(Suite.java:24)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:292)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:236)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:134)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:113)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
        at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
        at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
",Bug,"tdb.TS_TDBLoader3 test fails in Windows The tdb.TS_TDBLoader3 test fails in Windows.  See stacktrace [1].

Work-around: run maven with ""-DskipTests"" command line argument.


[1] Stacktrace from failing test:

Running tdb.TS_TDBLoader3
09:51:28 ERROR BPlusTreeRewriter         :: **** Not the root: 1024
com.hp.hpl.jena.tdb.index.bplustree.BPTreeException
        at com.hp.hpl.jena.tdb.index.bplustree.BPlusTreeRewriter.packIntoBPlusTree(BPlusTreeRewriter.java:89)
        at org.apache.jena.tdb.store.bulkloader3.NodeTableBuilder2.buildNodeTableBPTreeIndex(NodeTableBuilder2.java:296)
        at org.apache.jena.tdb.store.bulkloader3.NodeTableBuilder2.close(NodeTableBuilder2.java:172)
        at tdb.tdbloader3.exec(tdbloader3.java:216)
        at arq.cmdline.CmdMain.mainMethod(CmdMain.java:101)
        at arq.cmdline.CmdMain.mainRun(CmdMain.java:63)
        at arq.cmdline.CmdMain.mainRun(CmdMain.java:50)
        at tdb.tdbloader3.main(tdbloader3.java:108)
        at tdb.TestTDBLoader3.run(TestTDBLoader3.java:120)
        at tdb.TestTDBLoader3.test(TestTDBLoader3.java:88)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:69)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:48)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:292)
        at org.junit.runners.Suite.runChild(Suite.java:128)
        at org.junit.runners.Suite.runChild(Suite.java:24)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:292)
        at org.junit.runners.Suite.runChild(Suite.java:128)
        at org.junit.runners.Suite.runChild(Suite.java:24)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:292)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:236)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:134)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:113)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
        at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
        at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
"
JENA-290,TDB txn creation touches stats unnecessarily.,Each transaction is recalculating the static stats ReorderTransformation.,Bug,TDB txn creation touches stats unnecessarily. Each transaction is recalculating the static stats ReorderTransformation.
JENA-288, QueryIterAssignVarValue: Null iterator,"Test case:

PREFIX : <http://example/>

SELECT *
{
   BIND ( :g AS ?G )
   GRAPH ?G { ?s ?p ?o }
}

and :g is not a graph in the data.
",Bug," QueryIterAssignVarValue: Null iterator Test case:

PREFIX : <http://example/>

SELECT *
{
   BIND ( :g AS ?G )
   GRAPH ?G { ?s ?p ?o }
}

and :g is not a graph in the data.
"
JENA-287,Timezones with non-zero minutes cause endcode/decode problems.,"Example:

public class DevMain
{
    public static void main(String[] args)
    {
        for ( int tz = 0 ; tz < 2 ; tz++ )
        {
            String x = String.format(""2012-07-29T12:01:23-%02d:30"", tz) ;
            System.out.println(x) ;
            Node n = Node.createLiteral(x, XSDDatatype.XSDdateTime) ;
            NodeId nid = NodeId.inline(n) ;
            if ( nid != null )
            {
                Node n1 = NodeId.extract(nid) ;
                if ( ! n.equals(n1) )
                    System.out.println(""Different: ""+n+"" -> ""+n1) ;
            }
            else
                System.out.println(""Miss"") ; 
        }
        System.out.println(""DONE"") ;
        System.exit(0) ;
    }
}
        ",Bug,"Timezones with non-zero minutes cause endcode/decode problems. Example:

public class DevMain
{
    public static void main(String[] args)
    {
        for ( int tz = 0 ; tz < 2 ; tz++ )
        {
            String x = String.format(""2012-07-29T12:01:23-%02d:30"", tz) ;
            System.out.println(x) ;
            Node n = Node.createLiteral(x, XSDDatatype.XSDdateTime) ;
            NodeId nid = NodeId.inline(n) ;
            if ( nid != null )
            {
                Node n1 = NodeId.extract(nid) ;
                if ( ! n.equals(n1) )
                    System.out.println(""Different: ""+n+"" -> ""+n1) ;
            }
            else
                System.out.println(""Miss"") ; 
        }
        System.out.println(""DONE"") ;
        System.exit(0) ;
    }
}
        "
JENA-285,rdfcat does not respect -n flag,-n flag (n-triples input syntax) is overridden by the file-extension guessing heuristics in the FileManager,Bug,rdfcat does not respect -n flag -n flag (n-triples input syntax) is overridden by the file-extension guessing heuristics in the FileManager
JENA-282,DatasetAccessorHTTP does not %-encode the URL.,"DatasetAccessorHTTP does not %-encode the URL.
",Bug,"DatasetAccessorHTTP does not %-encode the URL. DatasetAccessorHTTP does not %-encode the URL.
"
JENA-276,CORS not working properly for preflight requests,"I tried to access a Fuseki Server by using an ajax request. Unfortunately the browser just sends an OPTIONS request and stops.

Fuseki returns correct Access-Control-Allow-Origin headers for a POST request, but I think it also needs to return them on an OPTIONS request [1]. Otherwise the browser would not allow the request.

I tested this with Firefox 13.0.1.

[1] https://gist.github.com/a8af6897f2ce1f69c459",Bug,"CORS not working properly for preflight requests I tried to access a Fuseki Server by using an ajax request. Unfortunately the browser just sends an OPTIONS request and stops.

Fuseki returns correct Access-Control-Allow-Origin headers for a POST request, but I think it also needs to return them on an OPTIONS request [1]. Otherwise the browser would not allow the request.

I tested this with Firefox 13.0.1.

[1] https://gist.github.com/a8af6897f2ce1f69c459"
JENA-272,tdbloader2 shell script calls missing tdb_path,"    [~/dev/java/apache-jena-2.7.2] 
    ian@ian-desktop $ echo $JENA_HOME
    /home/ian/dev/java/apache-jena-2.7.2
    [~/dev/java/apache-jena-2.7.2] 
    ian@ian-desktop $ which tdbloader2
    /home/ian/dev/java/apache-jena-2.7.2/bin/tdbloader2
    [~/dev/java/apache-jena-2.7.2] 
    ian@ian-desktop $ tdbloader2
    /home/ian/dev/java/apache-jena-2.7.2/bin/tdbloader2: line 30: /home/ian/dev/java/apache-jena-2.7.2/bin/tdb_path: No such file or directory
",Bug,"tdbloader2 shell script calls missing tdb_path     [~/dev/java/apache-jena-2.7.2] 
    ian@ian-desktop $ echo $JENA_HOME
    /home/ian/dev/java/apache-jena-2.7.2
    [~/dev/java/apache-jena-2.7.2] 
    ian@ian-desktop $ which tdbloader2
    /home/ian/dev/java/apache-jena-2.7.2/bin/tdbloader2
    [~/dev/java/apache-jena-2.7.2] 
    ian@ian-desktop $ tdbloader2
    /home/ian/dev/java/apache-jena-2.7.2/bin/tdbloader2: line 30: /home/ian/dev/java/apache-jena-2.7.2/bin/tdb_path: No such file or directory
"
JENA-265,"BINDINGS being parsed as BIND, leading to ""unexpected …"" error","Error 400: Parse error: 
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>

SELECT ?notation ?thing WHERE {
  ?thing skos:notation ?notation .
  FILTER (isuri(?thing))
} BINDINGS ?notation {
  (""317""^^<http://data.ox.ac.uk/id/notation/estates>)
  (""DJ""^^<http://data.ox.ac.uk/id/notation/twoThree>)
  (""51219523""^^<http://data.ox.ac.uk/id/notation/oxpoints>)
  (""154""^^<http://data.ox.ac.uk/id/notation/estates>)
  (""59030245""^^<http://data.ox.ac.uk/id/notation/oxpoints>)
}

Encountered "" ""bind"" ""BIND """" at line 6, column 3.
Was expecting one of:
    <EOF> 
    ""limit"" ...
    ""offset"" ...
    ""order"" ...
    ""values"" ...
    ""group"" ...
    ""having"" ...
    
Fuseki - version 0.2.3-SNAPSHOT (Build date: 2012-06-18T16:39:15+0100)


Here's the version numbers:

[alex@box jena-fuseki-0.2.3-SNAPSHOT]$ ./fuseki-server --version
Jena:       VERSION: 2.7.2-SNAPSHOT
Jena:       BUILD_DATE: 2012-06-18T16:36:46+0100
ARQ:        VERSION: 2.9.2-SNAPSHOT
ARQ:        BUILD_DATE: 2012-06-18T16:25:58+0100
TDB:        VERSION: 0.9.2-SNAPSHOT
TDB:        BUILD_DATE: 2012-06-18T16:34:15+0100
Fuseki:     VERSION: 0.2.3-SNAPSHOT
Fuseki:     BUILD_DATE: 2012-06-18T16:39:15+0100
",Bug,"BINDINGS being parsed as BIND, leading to ""unexpected ..."" error Error 400: Parse error: 
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>

SELECT ?notation ?thing WHERE {
  ?thing skos:notation ?notation .
  FILTER (isuri(?thing))
} BINDINGS ?notation {
  (""317""^^<http://data.ox.ac.uk/id/notation/estates>)
  (""DJ""^^<http://data.ox.ac.uk/id/notation/twoThree>)
  (""51219523""^^<http://data.ox.ac.uk/id/notation/oxpoints>)
  (""154""^^<http://data.ox.ac.uk/id/notation/estates>)
  (""59030245""^^<http://data.ox.ac.uk/id/notation/oxpoints>)
}

Encountered "" ""bind"" ""BIND """" at line 6, column 3.
Was expecting one of:
    <EOF> 
    ""limit"" ...
    ""offset"" ...
    ""order"" ...
    ""values"" ...
    ""group"" ...
    ""having"" ...
    
Fuseki - version 0.2.3-SNAPSHOT (Build date: 2012-06-18T16:39:15+0100)


Here's the version numbers:

[alex@box jena-fuseki-0.2.3-SNAPSHOT]$ ./fuseki-server --version
Jena:       VERSION: 2.7.2-SNAPSHOT
Jena:       BUILD_DATE: 2012-06-18T16:36:46+0100
ARQ:        VERSION: 2.9.2-SNAPSHOT
ARQ:        BUILD_DATE: 2012-06-18T16:25:58+0100
TDB:        VERSION: 0.9.2-SNAPSHOT
TDB:        BUILD_DATE: 2012-06-18T16:34:15+0100
Fuseki:     VERSION: 0.2.3-SNAPSHOT
Fuseki:     BUILD_DATE: 2012-06-18T16:39:15+0100
"
JENA-264,Fuseki SPARQL endpoint doesn't understand Content-type: application/x-www-form-urlencoded; charset=utf-8,"POSTing a query with the header
 Content-type: application/x-www-form-urlencoded; charset=utf-8
gets a response of 413 Unsupported

but 
 Content-type: application/x-www-form-urlencoded
works.",Bug,"Fuseki SPARQL endpoint doesn't understand Content-type: application/x-www-form-urlencoded; charset=utf-8 POSTing a query with the header
 Content-type: application/x-www-form-urlencoded; charset=utf-8
gets a response of 413 Unsupported

but 
 Content-type: application/x-www-form-urlencoded
works."
JENA-263,Adding resource property inside TDB transaction causes message '******* UNEXPECTED',"I created the attached test case while trying to isolate a problem I was seeing in some other code. This code doesn't repro the exception I'm seeing, but I do get the output '**************** UNEXPECTED' on stderr. Test case attached.",Bug,"Adding resource property inside TDB transaction causes message '******* UNEXPECTED' I created the attached test case while trying to isolate a problem I was seeing in some other code. This code doesn't repro the exception I'm seeing, but I do get the output '**************** UNEXPECTED' on stderr. Test case attached."
JENA-262,CacheFactory incorrectly uses hard-coded load factor,"The createCache(float loadFactor, int maxSize) method of org.openjena.atlas.lib.CacheFactory incorrectly passes a hard-coded load factor of 0.75 to the underlying CacheLRU constructor instead of passing the explicitly provided load factor.",Bug,"CacheFactory incorrectly uses hard-coded load factor The createCache(float loadFactor, int maxSize) method of org.openjena.atlas.lib.CacheFactory incorrectly passes a hard-coded load factor of 0.75 to the underlying CacheLRU constructor instead of passing the explicitly provided load factor."
JENA-260,TDB Transactional error logged by Fuseki server for all update operations,"Running a Fuseki server backed by TDB with update enabled from the latest SVN version 1351419, any time I execute an update operation, I see the following error in the Fuseki console output:


13:59:59 WARN  SPARQL_Upload$HttpActionUpload :: Transaction still active in endWriter - no commit or abort seen (forced abort)
13:59:59 WARN  SPARQL_Upload$HttpActionUpload :: Exception in forced abort (trying to continue)
com.hp.hpl.jena.tdb.transaction.TDBTransactionException: Transaction has already committed or aborted
	at com.hp.hpl.jena.tdb.transaction.Transaction.abort(Transaction.java:146)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.abort(DatasetGraphTxn.java:45)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._abort(DatasetGraphTransaction.java:138)
	at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.abort(DatasetGraphTrackActive.java:68)
	at org.apache.jena.fuseki.servlets.HttpAction.endWrite(HttpAction.java:119)
	at org.apache.jena.fuseki.servlets.SPARQL_Upload.perform(SPARQL_Upload.java:187)
	at org.apache.jena.fuseki.servlets.SPARQL_ServletBase.doCommon(SPARQL_ServletBase.java:92)
	at org.apache.jena.fuseki.servlets.SPARQL_Upload.doPost(SPARQL_Upload.java:71)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
...

In spite of this error message, the update apparently succeeds and is persisted to the database.",Bug,"TDB Transactional error logged by Fuseki server for all update operations Running a Fuseki server backed by TDB with update enabled from the latest SVN version 1351419, any time I execute an update operation, I see the following error in the Fuseki console output:


13:59:59 WARN  SPARQL_Upload$HttpActionUpload :: Transaction still active in endWriter - no commit or abort seen (forced abort)
13:59:59 WARN  SPARQL_Upload$HttpActionUpload :: Exception in forced abort (trying to continue)
com.hp.hpl.jena.tdb.transaction.TDBTransactionException: Transaction has already committed or aborted
	at com.hp.hpl.jena.tdb.transaction.Transaction.abort(Transaction.java:146)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.abort(DatasetGraphTxn.java:45)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._abort(DatasetGraphTransaction.java:138)
	at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.abort(DatasetGraphTrackActive.java:68)
	at org.apache.jena.fuseki.servlets.HttpAction.endWrite(HttpAction.java:119)
	at org.apache.jena.fuseki.servlets.SPARQL_Upload.perform(SPARQL_Upload.java:187)
	at org.apache.jena.fuseki.servlets.SPARQL_ServletBase.doCommon(SPARQL_ServletBase.java:92)
	at org.apache.jena.fuseki.servlets.SPARQL_Upload.doPost(SPARQL_Upload.java:71)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
...

In spite of this error message, the update apparently succeeds and is persisted to the database."
JENA-256,Significant performance regression (TDB?) on 2.7.1 RC compared to May 15 build,"See also http://mail-archives.apache.org/mod_mbox/jena-dev/201206.mbox/%3C4FD9F19E.3080904%40bristol.ac.uk%3E

I was able to reproduce the performance regression with an isolated test scenario. So I recreated the components ARQ, CORE, IRI, and TDB with the SVN state of May 15 9 (so svn update -r {2012-05-15} and then svn clean install)

I then created a simple test program (attached as PerformanceRegressionTest.java) which I ran 4 times in a row for each version of Jena. Note that I deleted the TDB directory after the first 4 runs before using the other Jena version. Attached are the files with the output. The regression is obvious",Bug,"Significant performance regression (TDB?) on 2.7.1 RC compared to May 15 build See also http://mail-archives.apache.org/mod_mbox/jena-dev/201206.mbox/%3C4FD9F19E.3080904%40bristol.ac.uk%3E

I was able to reproduce the performance regression with an isolated test scenario. So I recreated the components ARQ, CORE, IRI, and TDB with the SVN state of May 15 9 (so svn update -r {2012-05-15} and then svn clean install)

I then created a simple test program (attached as PerformanceRegressionTest.java) which I ran 4 times in a row for each version of Jena. Note that I deleted the TDB directory after the first 4 runs before using the other Jena version. Attached are the files with the output. The regression is obvious"
JENA-254,rdfcat produces invalid decimals N3,"According to the N3 grammar, decimals must have at least one digit to the left of the decimal point.
Rdfcat ignores this when abbreviating datatyped xsd:decimal literals.
This causes reasoners like CWM and (older versions of) EYE to throw syntax errors.

http://www.w3.org/TeamSubmission/n3/
decimal ::=	[-+]?[0-9]+(\.[0-9]+)?

Test case:

rdfcat -ttl test.ttl -out N3 > result.n3

test.ttl:
@prefix xsd: <http://www.w3.org/2001/XMLSchema#>.
@prefix :	<#>.
:s :p "".3""^^xsd:decimal.

result.n3
@prefix :        <file:///home/axgze/tmp/decimal/test.ttl#> .
@prefix xsd:     <http://www.w3.org/2001/XMLSchema#> .

:s    :p      .3 .
",Bug,"rdfcat produces invalid decimals N3 According to the N3 grammar, decimals must have at least one digit to the left of the decimal point.
Rdfcat ignores this when abbreviating datatyped xsd:decimal literals.
This causes reasoners like CWM and (older versions of) EYE to throw syntax errors.

http://www.w3.org/TeamSubmission/n3/
decimal ::=	[-+]?[0-9]+(\.[0-9]+)?

Test case:

rdfcat -ttl test.ttl -out N3 > result.n3

test.ttl:
@prefix xsd: <http://www.w3.org/2001/XMLSchema#>.
@prefix :	<#>.
:s :p "".3""^^xsd:decimal.

result.n3
@prefix :        <file:///home/axgze/tmp/decimal/test.ttl#> .
@prefix xsd:     <http://www.w3.org/2001/XMLSchema#> .

:s    :p      .3 .
"
JENA-252,ConcurrentModificationException as a result of fixing JENA-250,"For details see: http://mail-archives.apache.org/mod_mbox/jena-dev/201206.mbox/%3COFD5CF949B.2912666B-ON85257A17.0065FAD4-85257A17.0067EB5F%40ca.ibm.com%3E

The difference sits in the method _begin in DatasetGraphTransaction:

 @Override
    protected void _begin(ReadWrite readWrite)
    {
        synchronized(lock)
        {
            if ( ! haveUsedInTransaction )
                getBaseDatasetGraph().sync() ;
            haveUsedInTransaction = true ;
            DatasetGraphTxn dsgTxn = sConn.begin(readWrite) ;
            txn.set(dsgTxn) ;
            inTransaction.set(true) ;
        }
    }

The old method was

 @Override
    protected void _begin(ReadWrite readWrite)
    {
        synchronized(lock)
        {
            haveUsedInTransaction = true ;
            DatasetGraphTxn dsgTxn = sConn.begin(readWrite) ;
            txn.set(dsgTxn) ;
            inTransaction.set(true) ;
        }
    }

However, the call to getBaseDatasetGraph().sync()  violates an invariant which make the DatasetControlMRSW think there is more than 1 writer",Bug,"ConcurrentModificationException as a result of fixing JENA-250 For details see: http://mail-archives.apache.org/mod_mbox/jena-dev/201206.mbox/%3COFD5CF949B.2912666B-ON85257A17.0065FAD4-85257A17.0067EB5F%40ca.ibm.com%3E

The difference sits in the method _begin in DatasetGraphTransaction:

 @Override
    protected void _begin(ReadWrite readWrite)
    {
        synchronized(lock)
        {
            if ( ! haveUsedInTransaction )
                getBaseDatasetGraph().sync() ;
            haveUsedInTransaction = true ;
            DatasetGraphTxn dsgTxn = sConn.begin(readWrite) ;
            txn.set(dsgTxn) ;
            inTransaction.set(true) ;
        }
    }

The old method was

 @Override
    protected void _begin(ReadWrite readWrite)
    {
        synchronized(lock)
        {
            haveUsedInTransaction = true ;
            DatasetGraphTxn dsgTxn = sConn.begin(readWrite) ;
            txn.set(dsgTxn) ;
            inTransaction.set(true) ;
        }
    }

However, the call to getBaseDatasetGraph().sync()  violates an invariant which make the DatasetControlMRSW think there is more than 1 writer"
JENA-251,IRI throws a NullPointerException when RiotLoader reads an RDF/XML file while using dependencies of jena-sb 1.3.4-SNAPSHOT,"A project I'm working on loads files at runtime and updates URIs that have place holders with the domain a web application is deployed, prior to being saved to a default or named graph with SDB. For example, mca://foo/bar/  becomes http://m.bristol.ac.uk/foo/bar/. After the jena-sdb version become 1.3.4-SNAPSHOT some of the RDF XML files were failing with the following exception:

java.lang.NullPointerException
	at java.util.regex.Matcher.getTextLength(Matcher.java:1140)
	at java.util.regex.Matcher.reset(Matcher.java:291)
	at java.util.regex.Matcher.<init>(Matcher.java:211)
	at java.util.regex.Pattern.matcher(Pattern.java:888)
	at org.apache.jena.iri.impl.Parser.<init>(Parser.java:89)
	at org.apache.jena.iri.impl.IRIImpl.<init>(IRIImpl.java:65)
	at org.apache.jena.iri.impl.AbsIRIImpl.create(AbsIRIImpl.java:692)
	at org.apache.jena.iri.IRI.resolve(IRI.java:432)
	at org.openjena.riot.system.IRIResolver$IRIResolverNormal.resolveSilent(IRIResolver.java:435)
	at org.openjena.riot.system.IRIResolver$IRIResolverNormal.resolve(IRIResolver.java:420)
	at org.openjena.riot.system.IRIResolver.resolveIRI(IRIResolver.java:199)
	at org.openjena.riot.system.IRIResolver.resolveString(IRIResolver.java:189)
	at org.openjena.riot.RiotReader.createParserTriples(RiotReader.java:144)
	at org.openjena.riot.RiotLoader.readTriples(RiotLoader.java:215)

I've created a reduced sample test case (using maven). If you use the dependencies linked to jena-sdb (1.3.4-SNAPSHOT) you will get the stack trace above with mvn test. If you replace the dependencies with jena-arq (2.9.0-incubating) and run mvn clean and mvn test you won't get an error but will see a list of URIs being printed to standard out.",Bug,"IRI throws a NullPointerException when RiotLoader reads an RDF/XML file while using dependencies of jena-sb 1.3.4-SNAPSHOT A project I'm working on loads files at runtime and updates URIs that have place holders with the domain a web application is deployed, prior to being saved to a default or named graph with SDB. For example, mca://foo/bar/  becomes http://m.bristol.ac.uk/foo/bar/. After the jena-sdb version become 1.3.4-SNAPSHOT some of the RDF XML files were failing with the following exception:

java.lang.NullPointerException
	at java.util.regex.Matcher.getTextLength(Matcher.java:1140)
	at java.util.regex.Matcher.reset(Matcher.java:291)
	at java.util.regex.Matcher.<init>(Matcher.java:211)
	at java.util.regex.Pattern.matcher(Pattern.java:888)
	at org.apache.jena.iri.impl.Parser.<init>(Parser.java:89)
	at org.apache.jena.iri.impl.IRIImpl.<init>(IRIImpl.java:65)
	at org.apache.jena.iri.impl.AbsIRIImpl.create(AbsIRIImpl.java:692)
	at org.apache.jena.iri.IRI.resolve(IRI.java:432)
	at org.openjena.riot.system.IRIResolver$IRIResolverNormal.resolveSilent(IRIResolver.java:435)
	at org.openjena.riot.system.IRIResolver$IRIResolverNormal.resolve(IRIResolver.java:420)
	at org.openjena.riot.system.IRIResolver.resolveIRI(IRIResolver.java:199)
	at org.openjena.riot.system.IRIResolver.resolveString(IRIResolver.java:189)
	at org.openjena.riot.RiotReader.createParserTriples(RiotReader.java:144)
	at org.openjena.riot.RiotLoader.readTriples(RiotLoader.java:215)

I've created a reduced sample test case (using maven). If you use the dependencies linked to jena-sdb (1.3.4-SNAPSHOT) you will get the stack trace above with mvn test. If you replace the dependencies with jena-arq (2.9.0-incubating) and run mvn clean and mvn test you won't get an error but will see a list of URIs being printed to standard out."
JENA-250,StoreConnection.release will empty repository if last action is not a query,"Whenever the last activity before releasing a store (with StoreConnection.release) is a write transaction, the entire database is empty the next time you create a dataset. I should note that this only happens when you start with a new index store. If you release the store after a write transaction on a store which was created the first time around where you did not end with a write transaction, the problem will not occur.

I attached a little test case which illustrates the problem. Just provide a new index location as a java argument (or hard code it)",Bug,"StoreConnection.release will empty repository if last action is not a query Whenever the last activity before releasing a store (with StoreConnection.release) is a write transaction, the entire database is empty the next time you create a dataset. I should note that this only happens when you start with a new index store. If you release the store after a write transaction on a store which was created the first time around where you did not end with a write transaction, the problem will not occur.

I attached a little test case which illustrates the problem. Just provide a new index location as a java argument (or hard code it)"
JENA-249,The snapshot POM file for SDB is referencing incubating dependencies,"In the pom file the following properties are set:

<ver.jena>2.7.0-incubating</ver.jena>
<ver.arq>2.9.0-incubating</ver.arq>

This means the SDB snapshot pulls in dependencies with the incubating suffix:

jena-core-2.7.0-incubating.jar
jena-iri-0.9.0-incubating.jar
and jena-arq-2.9.0-incubating.jar",Bug,"The snapshot POM file for SDB is referencing incubating dependencies In the pom file the following properties are set:

<ver.jena>2.7.0-incubating</ver.jena>
<ver.arq>2.9.0-incubating</ver.arq>

This means the SDB snapshot pulls in dependencies with the incubating suffix:

jena-core-2.7.0-incubating.jar
jena-iri-0.9.0-incubating.jar
and jena-arq-2.9.0-incubating.jar"
JENA-248,Fuseki server unresponsive  when running multiple construct queries using multi-threading.,"Hi Andy,

We are running concurrency tests for Fuseki 0.2.1 (downloaded from http://www.apache.org/dist/incubator/jena/jena-fuseki-0.2.1-incubating/).
We're running multiple construct queries (approximately 200 queries) using Task Parallel Library of .Net to talk to Fuseki and get response back. We've first tried through dotNetRdf and when about 25 queries have run, the fuseki server freezes and becomes unresponsive. To make it responsive again, we had to restart the fuseki service.
Now the construct query is a bit that stands out here because its querying two separate service endpoints. Following is the sample construct query that we're using:
CONSTRUCT
{ 
	<http://rahul.org/company/id/123456> ?predicate ?object . 
	?blankNode ?blankNodePredicate ?blankNodeObject .
	<http://rahul.org/company/id/123456> ?pred ?blankNode1 .
	?blankNode1 ?blankNodePredicate1 ?blankNodeObject1 .
}
WHERE
{
	SERVICE <http://localhost:3030/companies/sparql>
	{
		<http://rahul.org/company/id/123456> ?predicate ?object .
	}
	SERVICE <http://localhost:3030/rahul/sparql>
	{
		OPTIONAL 
		{
			<http://rahul.org/company/id/123456> ?pred ?blankNode1 .
			?blankNode1 ?blankNodePredicate1 ?blankNodeObject1 .
		}
	}
}

Then we ran the queries again to make sure its not because of dotNetRdf - so we've used a simple HttpWebRequest - something like this:
var request = HttpWebRequest.Create(""http://localhost:3030/query/sparql?query="" + GetUtf8(sparql)) as HttpWebRequest;
request.Method = ""GET"";
var response = request.GetResponse();

Could you please help with this problem of Fuseki server becoming unresponsive in the above mentioned case.

Thanks,
Rahul
",Bug,"Fuseki server unresponsive  when running multiple construct queries using multi-threading. Hi Andy,

We are running concurrency tests for Fuseki 0.2.1 (downloaded from http://www.apache.org/dist/incubator/jena/jena-fuseki-0.2.1-incubating/).
We're running multiple construct queries (approximately 200 queries) using Task Parallel Library of .Net to talk to Fuseki and get response back. We've first tried through dotNetRdf and when about 25 queries have run, the fuseki server freezes and becomes unresponsive. To make it responsive again, we had to restart the fuseki service.
Now the construct query is a bit that stands out here because its querying two separate service endpoints. Following is the sample construct query that we're using:
CONSTRUCT
{ 
	<http://rahul.org/company/id/123456> ?predicate ?object . 
	?blankNode ?blankNodePredicate ?blankNodeObject .
	<http://rahul.org/company/id/123456> ?pred ?blankNode1 .
	?blankNode1 ?blankNodePredicate1 ?blankNodeObject1 .
}
WHERE
{
	SERVICE <http://localhost:3030/companies/sparql>
	{
		<http://rahul.org/company/id/123456> ?predicate ?object .
	}
	SERVICE <http://localhost:3030/rahul/sparql>
	{
		OPTIONAL 
		{
			<http://rahul.org/company/id/123456> ?pred ?blankNode1 .
			?blankNode1 ?blankNodePredicate1 ?blankNodeObject1 .
		}
	}
}

Then we ran the queries again to make sure its not because of dotNetRdf - so we've used a simple HttpWebRequest - something like this:
var request = HttpWebRequest.Create(""http://localhost:3030/query/sparql?query="" + GetUtf8(sparql)) as HttpWebRequest;
request.Method = ""GET"";
var response = request.GetResponse();

Could you please help with this problem of Fuseki server becoming unresponsive in the above mentioned case.

Thanks,
Rahul
"
JENA-247,XSDDateTime issue,http://mail-archives.apache.org/mod_mbox/jena-users/201205.mbox/%3CF1777BD020462E478F34F38513189F580FC150E8%40NDHV3004.na.corp.mckesson.com%3E,Bug,XSDDateTime issue http://mail-archives.apache.org/mod_mbox/jena-users/201205.mbox/%3CF1777BD020462E478F34F38513189F580FC150E8%40NDHV3004.na.corp.mckesson.com%3E
JENA-239,Cannot insert a triple into JenaTDB through Fuseki's sparql update functionality.,"Created a TDB database using bulkloader (using Jena-TDB-0.8.10 libraries). Trying to insert a triple using fuseki's sparql update functionality and keeps getting error:

Different ids for http://xxxxxx.xxxx.xxx.xx/xx/company/99999999: allocated: ex
pected [000000000007E5ED], got [000000000007DEF4]
>>>>>>>>>>
label = nodes
txn = Transaction: 1 : Mode=WRITE : State=PREPARING : E:\Rahul\fuseki\Dataset\
offset = 517613
journalStartOffset = 1785
journal = nodes.dat-jrnl

12:49:05 WARN  SPARQL_Update$HttpActionUpdate :: Transaction still active in end
Writer - no commit or abort seen (forced abort)
12:49:05 WARN  SPARQL_Update$HttpActionUpdate :: Exception in forced abort (tryi
ng to continue)
com.hp.hpl.jena.tdb.transaction.TDBTransactionException: Transaction has already
 committed or aborted
        at com.hp.hpl.jena.tdb.transaction.Transaction.abort(Transaction.java:14
6)
        at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.abort(DatasetGraphTxn
.java:45)
        at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._abort(Datase
tGraphTransaction.java:113)
        at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.abort(DatasetGrap
hTrackActive.java:68)
        at org.apache.jena.fuseki.servlets.HttpAction.endWrite(HttpAction.java:1
20)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.execute(SPARQL_Update.j
ava:238)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.executeForm(SPARQL_Upda
te.java:225)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.perform(SPARQL_Update.j
ava:122)
        at org.apache.jena.fuseki.servlets.SPARQL_ServletBase.doCommon(SPARQL_Se
rvletBase.java:92)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.doPost(SPARQL_Update.ja
va:78)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:547
)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java
:480)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl
er.java:225)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl
er.java:941)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:
409)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle
r.java:186)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle
r.java:875)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:117)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper
.java:110)
        at org.eclipse.jetty.server.Server.handle(Server.java:349)
        at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.
java:441)
        at org.eclipse.jetty.server.HttpConnection$RequestHandler.content(HttpCo
nnection.java:936)
        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:801)
        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:224)

        at org.eclipse.jetty.server.BlockingHttpConnection.handle(BlockingHttpCo
nnection.java:50)
        at org.eclipse.jetty.server.nio.BlockingChannelConnector$BlockingChannel
EndPoint.run(BlockingChannelConnector.java:293)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo
l.java:598)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool
.java:533)
        at java.lang.Thread.run(Thread.java:722)
12:49:05 WARN  Fuseki               :: [1] RC = 500 : Different ids for http://x
xxxxx.xxxx.xxx.xx/xx/company/99999999: allocated: expected [000000000007E5ED],
 got [000000000007DEF4]
com.hp.hpl.jena.tdb.TDBException: Different ids for http://xxxxxx.xxxx.xxx.xx/
xx/company/99999999: allocated: expected [000000000007E5ED], got [000000000007DE
F4]
        at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.inconsistent(NodeTable
Trans.java:212)
        at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.append(NodeTableTrans.
java:200)
        at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.writeNodeJournal(NodeT
ableTrans.java:306)
        at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.commitPrepare(NodeTabl
eTrans.java:266)
        at com.hp.hpl.jena.tdb.transaction.Transaction.prepare(Transaction.java:
131)
        at com.hp.hpl.jena.tdb.transaction.Transaction.commit(Transaction.java:1
12)
        at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.commit(DatasetGraphTx
n.java:40)
        at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._commit(Datas
etGraphTransaction.java:107)
        at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.commit(DatasetGra
phTrackActive.java:60)
        at org.apache.jena.fuseki.servlets.HttpAction.commit(HttpAction.java:105
)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.execute(SPARQL_Update.j
ava:235)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.executeForm(SPARQL_Upda
te.java:225)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.perform(SPARQL_Update.j
ava:122)
        at org.apache.jena.fuseki.servlets.SPARQL_ServletBase.doCommon(SPARQL_Se
rvletBase.java:92)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.doPost(SPARQL_Update.ja
va:78)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:547
)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java
:480)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl
er.java:225)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl
er.java:941)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:
409)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle
r.java:186)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle
r.java:875)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:117)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper
.java:110)
        at org.eclipse.jetty.server.Server.handle(Server.java:349)
        at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.
java:441)
        at org.eclipse.jetty.server.HttpConnection$RequestHandler.content(HttpCo
nnection.java:936)
        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:801)
        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:224)

        at org.eclipse.jetty.server.BlockingHttpConnection.handle(BlockingHttpCo
nnection.java:50)
        at org.eclipse.jetty.server.nio.BlockingChannelConnector$BlockingChannel
EndPoint.run(BlockingChannelConnector.java:293)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo
l.java:598)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool
.java:533)
        at java.lang.Thread.run(Thread.java:722)
12:49:05 INFO  Fuseki               :: [1] 500 Different ids for http://xxxxxxxx
/xx/company/99999999: allocated: expected [000000000007E5ED], got [0
00000000007DEF4]
",Bug,"Cannot insert a triple into JenaTDB through Fuseki's sparql update functionality. Created a TDB database using bulkloader (using Jena-TDB-0.8.10 libraries). Trying to insert a triple using fuseki's sparql update functionality and keeps getting error:

Different ids for http://xxxxxx.xxxx.xxx.xx/xx/company/99999999: allocated: ex
pected [000000000007E5ED], got [000000000007DEF4]
>>>>>>>>>>
label = nodes
txn = Transaction: 1 : Mode=WRITE : State=PREPARING : E:\Rahul\fuseki\Dataset\
offset = 517613
journalStartOffset = 1785
journal = nodes.dat-jrnl

12:49:05 WARN  SPARQL_Update$HttpActionUpdate :: Transaction still active in end
Writer - no commit or abort seen (forced abort)
12:49:05 WARN  SPARQL_Update$HttpActionUpdate :: Exception in forced abort (tryi
ng to continue)
com.hp.hpl.jena.tdb.transaction.TDBTransactionException: Transaction has already
 committed or aborted
        at com.hp.hpl.jena.tdb.transaction.Transaction.abort(Transaction.java:14
6)
        at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.abort(DatasetGraphTxn
.java:45)
        at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._abort(Datase
tGraphTransaction.java:113)
        at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.abort(DatasetGrap
hTrackActive.java:68)
        at org.apache.jena.fuseki.servlets.HttpAction.endWrite(HttpAction.java:1
20)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.execute(SPARQL_Update.j
ava:238)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.executeForm(SPARQL_Upda
te.java:225)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.perform(SPARQL_Update.j
ava:122)
        at org.apache.jena.fuseki.servlets.SPARQL_ServletBase.doCommon(SPARQL_Se
rvletBase.java:92)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.doPost(SPARQL_Update.ja
va:78)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:547
)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java
:480)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl
er.java:225)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl
er.java:941)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:
409)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle
r.java:186)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle
r.java:875)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:117)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper
.java:110)
        at org.eclipse.jetty.server.Server.handle(Server.java:349)
        at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.
java:441)
        at org.eclipse.jetty.server.HttpConnection$RequestHandler.content(HttpCo
nnection.java:936)
        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:801)
        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:224)

        at org.eclipse.jetty.server.BlockingHttpConnection.handle(BlockingHttpCo
nnection.java:50)
        at org.eclipse.jetty.server.nio.BlockingChannelConnector$BlockingChannel
EndPoint.run(BlockingChannelConnector.java:293)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo
l.java:598)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool
.java:533)
        at java.lang.Thread.run(Thread.java:722)
12:49:05 WARN  Fuseki               :: [1] RC = 500 : Different ids for http://x
xxxxx.xxxx.xxx.xx/xx/company/99999999: allocated: expected [000000000007E5ED],
 got [000000000007DEF4]
com.hp.hpl.jena.tdb.TDBException: Different ids for http://xxxxxx.xxxx.xxx.xx/
xx/company/99999999: allocated: expected [000000000007E5ED], got [000000000007DE
F4]
        at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.inconsistent(NodeTable
Trans.java:212)
        at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.append(NodeTableTrans.
java:200)
        at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.writeNodeJournal(NodeT
ableTrans.java:306)
        at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.commitPrepare(NodeTabl
eTrans.java:266)
        at com.hp.hpl.jena.tdb.transaction.Transaction.prepare(Transaction.java:
131)
        at com.hp.hpl.jena.tdb.transaction.Transaction.commit(Transaction.java:1
12)
        at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.commit(DatasetGraphTx
n.java:40)
        at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._commit(Datas
etGraphTransaction.java:107)
        at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.commit(DatasetGra
phTrackActive.java:60)
        at org.apache.jena.fuseki.servlets.HttpAction.commit(HttpAction.java:105
)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.execute(SPARQL_Update.j
ava:235)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.executeForm(SPARQL_Upda
te.java:225)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.perform(SPARQL_Update.j
ava:122)
        at org.apache.jena.fuseki.servlets.SPARQL_ServletBase.doCommon(SPARQL_Se
rvletBase.java:92)
        at org.apache.jena.fuseki.servlets.SPARQL_Update.doPost(SPARQL_Update.ja
va:78)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:547
)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java
:480)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl
er.java:225)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl
er.java:941)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:
409)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle
r.java:186)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle
r.java:875)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:117)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper
.java:110)
        at org.eclipse.jetty.server.Server.handle(Server.java:349)
        at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.
java:441)
        at org.eclipse.jetty.server.HttpConnection$RequestHandler.content(HttpCo
nnection.java:936)
        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:801)
        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:224)

        at org.eclipse.jetty.server.BlockingHttpConnection.handle(BlockingHttpCo
nnection.java:50)
        at org.eclipse.jetty.server.nio.BlockingChannelConnector$BlockingChannel
EndPoint.run(BlockingChannelConnector.java:293)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo
l.java:598)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool
.java:533)
        at java.lang.Thread.run(Thread.java:722)
12:49:05 INFO  Fuseki               :: [1] 500 Different ids for http://xxxxxxxx
/xx/company/99999999: allocated: expected [000000000007E5ED], got [0
00000000007DEF4]
"
JENA-238,construct query where clause does not seem to work as advertised,"Here are two queries:
select ?o ?o1 ?o2 where {<http://sadl.org/AssetManagement/ALoco#LocoA> 
	<http://com.ge.research.sadl/locomotive#poweredBy> ?o  . 
	OPTIONAL {?o <http://com.ge.research.sadl/locomotive#operatingTemperature> ?o1} .
	OPTIONAL {?o <http://com.ge.research.sadl/locomotive#desiredOperatingTemperature> ?o2}}
	
construct where {<http://sadl.org/AssetManagement/ALoco#LocoA> 
	<http://com.ge.research.sadl/locomotive#poweredBy> ?o  . 
	OPTIONAL {?o <http://com.ge.research.sadl/locomotive#operatingTemperature> ?o1} .
	OPTIONAL {?o <http://com.ge.research.sadl/locomotive#desiredOperatingTemperature> ?o2}}

My understanding is that the where clause for construct should handle OPTIONAL. The first query works fine, the second query has a parse error. The same is true if I try to use a construct query with a UNION in it--it will not parse.",Bug,"construct query where clause does not seem to work as advertised Here are two queries:
select ?o ?o1 ?o2 where {<http://sadl.org/AssetManagement/ALoco#LocoA> 
	<http://com.ge.research.sadl/locomotive#poweredBy> ?o  . 
	OPTIONAL {?o <http://com.ge.research.sadl/locomotive#operatingTemperature> ?o1} .
	OPTIONAL {?o <http://com.ge.research.sadl/locomotive#desiredOperatingTemperature> ?o2}}
	
construct where {<http://sadl.org/AssetManagement/ALoco#LocoA> 
	<http://com.ge.research.sadl/locomotive#poweredBy> ?o  . 
	OPTIONAL {?o <http://com.ge.research.sadl/locomotive#operatingTemperature> ?o1} .
	OPTIONAL {?o <http://com.ge.research.sadl/locomotive#desiredOperatingTemperature> ?o2}}

My understanding is that the where clause for construct should handle OPTIONAL. The first query works fine, the second query has a parse error. The same is true if I try to use a construct query with a UNION in it--it will not parse."
JENA-234,"In TDB, namespace data out of sync when dataset not closed properly","When a TDB model is not closed properly.  the NodeToId table get's out of sync with the IdToNode table.  This is because writeBuffer in ObjectFileStorage doesn't get written, but the data in the NodeToId table does get written.  This causes the error mentioned in the following email thread: 
http://mail-archives.apache.org/mod_mbox/incubator-jena-dev/201201.mbox/%3C4F1EE540.5050307@apache.org%3E
Normally I'd say this isn't a bug because the user should close their models correctly.  But it seems like this should be fixed, because this mistake breaks TDB for all future uses, and possibly forces the user to recreate the whole db.  I'd be fine with just not writing the buffered data to both tables, as long as they're in sync.",Bug,"In TDB, namespace data out of sync when dataset not closed properly When a TDB model is not closed properly.  the NodeToId table get's out of sync with the IdToNode table.  This is because writeBuffer in ObjectFileStorage doesn't get written, but the data in the NodeToId table does get written.  This causes the error mentioned in the following email thread: 
http://mail-archives.apache.org/mod_mbox/incubator-jena-dev/201201.mbox/%3C4F1EE540.5050307@apache.org%3E
Normally I'd say this isn't a bug because the user should close their models correctly.  But it seems like this should be fixed, because this mistake breaks TDB for all future uses, and possibly forces the user to recreate the whole db.  I'd be fine with just not writing the buffered data to both tables, as long as they're in sync."
JENA-233,Wrong returned value for INF and -INF floats,"File: com/hp/hpl/jena/datatypes/xsd/impl/XSDFloat.java

Problem in the parsing of INF and -INF float value.
INF is transformed to NEGATIVE_INFINITY while -INF is transformed to POSITIVE_INFINITY. It should be the other way around.
 
current version:

 public Object parseValidated(String lex) {
        if (lex.equals(""INF"")) {
            return new Float(Float.NEGATIVE_INFINITY);
        } else if (lex.equals(""-INF"")) {
            return new Float(Float.POSITIVE_INFINITY);
        } else if (lex.equals(""NaN"")) {
            return new Float(Float.NaN);
        } else {
            return Float.valueOf(lex);
        }
    }
     ",Bug,"Wrong returned value for INF and -INF floats File: com/hp/hpl/jena/datatypes/xsd/impl/XSDFloat.java

Problem in the parsing of INF and -INF float value.
INF is transformed to NEGATIVE_INFINITY while -INF is transformed to POSITIVE_INFINITY. It should be the other way around.
 
current version:

 public Object parseValidated(String lex) {
        if (lex.equals(""INF"")) {
            return new Float(Float.NEGATIVE_INFINITY);
        } else if (lex.equals(""-INF"")) {
            return new Float(Float.POSITIVE_INFINITY);
        } else if (lex.equals(""NaN"")) {
            return new Float(Float.NaN);
        } else {
            return Float.valueOf(lex);
        }
    }
     "
JENA-231,"NumberFormatException when casting to xsd:int in ARQ, with possible infinite loop","I'm running the following query on an empty dataset using the sparql command line command:

    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
    SELECT (xsd:int("" 1"") AS ?x) {}

The result is an error:

    java.lang.NumberFormatException: For input string: "" 1""

I know that this is not a valid lexical form for xsd:int (note the extra space). But I expected this to produce an empty result set, like other non-int strings such as xsd:int(""NaN""), and not an exception.

The problem appears to be triggered by the presence of leading or trailing spaces around an otherwise correct number. The same problem is present when casting to other types such as xsd:decimal. The problem is *not* present for xsd:double.

Command and full stack trace follows.

(I have a user report of an infinite loop in ARQ code that I distilled down to this root issue. The report involved a cast to xsd:decimal in a FILTER expression. The dataset is a D2RQ dataset, and the values came from a CHAR column, hence the extra spaces. I have not succeeded in actually reproducing the infinite loop as I don't have access to the original database.)



cygris:~$ sparql --query rob.sparql --data empty.nt
Exception
java.lang.NumberFormatException: For input string: "" 1""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)
	at java.lang.Integer.parseInt(Integer.java:449)
	at java.math.BigInteger.<init>(BigInteger.java:316)
	at java.math.BigInteger.<init>(BigInteger.java:451)
	at com.hp.hpl.jena.sparql.expr.NodeValue._setByValue(NodeValue.java:957)
	at com.hp.hpl.jena.sparql.expr.NodeValue.nodeToNodeValue(NodeValue.java:915)
	at com.hp.hpl.jena.sparql.expr.NodeValue.makeNode(NodeValue.java:231)
	at com.hp.hpl.jena.sparql.expr.NodeValue.makeNode(NodeValue.java:238)
	at com.hp.hpl.jena.sparql.function.CastXSD$Instance.cast(CastXSD.java:96)
	at com.hp.hpl.jena.sparql.function.CastXSD_Numeric$Instance.cast(CastXSD_Numeric.java:61)
	at com.hp.hpl.jena.sparql.function.CastXSD$Instance.exec(CastXSD.java:86)
	at com.hp.hpl.jena.sparql.function.FunctionBase1.exec(FunctionBase1.java:53)
	at com.hp.hpl.jena.sparql.function.FunctionBase.exec(FunctionBase.java:68)
	at com.hp.hpl.jena.sparql.expr.E_Function.evalSpecial(E_Function.java:71)
	at com.hp.hpl.jena.sparql.expr.ExprFunctionN.eval(ExprFunctionN.java:102)
	at com.hp.hpl.jena.sparql.core.VarExprList.get(VarExprList.java:82)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterAssign.accept(QueryIterAssign.java:68)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:64)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:108)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterConvert.hasNextBinding(QueryIterConvert.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:108)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:40)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:108)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:40)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:108)
	at com.hp.hpl.jena.sparql.engine.ResultSetStream.hasNext(ResultSetStream.java:72)
	at com.hp.hpl.jena.sparql.resultset.ResultSetMem.<init>(ResultSetMem.java:95)
	at com.hp.hpl.jena.sparql.resultset.TextOutput.write(TextOutput.java:147)
	at com.hp.hpl.jena.sparql.resultset.TextOutput.write(TextOutput.java:130)
	at com.hp.hpl.jena.sparql.resultset.TextOutput.write(TextOutput.java:118)
	at com.hp.hpl.jena.sparql.resultset.TextOutput.format(TextOutput.java:65)
	at com.hp.hpl.jena.query.ResultSetFormatter.out(ResultSetFormatter.java:134)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.outputResultSet(QueryExecUtils.java:169)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.doSelectQuery(QueryExecUtils.java:211)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.executeQuery(QueryExecUtils.java:75)
	at arq.query.queryExec(query.java:186)
	at arq.query.exec(query.java:145)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:97)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:59)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:46)
	at arq.query.main(query.java:65)
	at arq.sparql.main(sparql.java:27)
",Bug,"NumberFormatException when casting to xsd:int in ARQ, with possible infinite loop I'm running the following query on an empty dataset using the sparql command line command:

    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
    SELECT (xsd:int("" 1"") AS ?x) {}

The result is an error:

    java.lang.NumberFormatException: For input string: "" 1""

I know that this is not a valid lexical form for xsd:int (note the extra space). But I expected this to produce an empty result set, like other non-int strings such as xsd:int(""NaN""), and not an exception.

The problem appears to be triggered by the presence of leading or trailing spaces around an otherwise correct number. The same problem is present when casting to other types such as xsd:decimal. The problem is *not* present for xsd:double.

Command and full stack trace follows.

(I have a user report of an infinite loop in ARQ code that I distilled down to this root issue. The report involved a cast to xsd:decimal in a FILTER expression. The dataset is a D2RQ dataset, and the values came from a CHAR column, hence the extra spaces. I have not succeeded in actually reproducing the infinite loop as I don't have access to the original database.)



cygris:~$ sparql --query rob.sparql --data empty.nt
Exception
java.lang.NumberFormatException: For input string: "" 1""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)
	at java.lang.Integer.parseInt(Integer.java:449)
	at java.math.BigInteger.<init>(BigInteger.java:316)
	at java.math.BigInteger.<init>(BigInteger.java:451)
	at com.hp.hpl.jena.sparql.expr.NodeValue._setByValue(NodeValue.java:957)
	at com.hp.hpl.jena.sparql.expr.NodeValue.nodeToNodeValue(NodeValue.java:915)
	at com.hp.hpl.jena.sparql.expr.NodeValue.makeNode(NodeValue.java:231)
	at com.hp.hpl.jena.sparql.expr.NodeValue.makeNode(NodeValue.java:238)
	at com.hp.hpl.jena.sparql.function.CastXSD$Instance.cast(CastXSD.java:96)
	at com.hp.hpl.jena.sparql.function.CastXSD_Numeric$Instance.cast(CastXSD_Numeric.java:61)
	at com.hp.hpl.jena.sparql.function.CastXSD$Instance.exec(CastXSD.java:86)
	at com.hp.hpl.jena.sparql.function.FunctionBase1.exec(FunctionBase1.java:53)
	at com.hp.hpl.jena.sparql.function.FunctionBase.exec(FunctionBase.java:68)
	at com.hp.hpl.jena.sparql.expr.E_Function.evalSpecial(E_Function.java:71)
	at com.hp.hpl.jena.sparql.expr.ExprFunctionN.eval(ExprFunctionN.java:102)
	at com.hp.hpl.jena.sparql.core.VarExprList.get(VarExprList.java:82)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterAssign.accept(QueryIterAssign.java:68)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:64)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:108)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterConvert.hasNextBinding(QueryIterConvert.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:108)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:40)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:108)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:40)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:108)
	at com.hp.hpl.jena.sparql.engine.ResultSetStream.hasNext(ResultSetStream.java:72)
	at com.hp.hpl.jena.sparql.resultset.ResultSetMem.<init>(ResultSetMem.java:95)
	at com.hp.hpl.jena.sparql.resultset.TextOutput.write(TextOutput.java:147)
	at com.hp.hpl.jena.sparql.resultset.TextOutput.write(TextOutput.java:130)
	at com.hp.hpl.jena.sparql.resultset.TextOutput.write(TextOutput.java:118)
	at com.hp.hpl.jena.sparql.resultset.TextOutput.format(TextOutput.java:65)
	at com.hp.hpl.jena.query.ResultSetFormatter.out(ResultSetFormatter.java:134)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.outputResultSet(QueryExecUtils.java:169)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.doSelectQuery(QueryExecUtils.java:211)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.executeQuery(QueryExecUtils.java:75)
	at arq.query.queryExec(query.java:186)
	at arq.query.exec(query.java:145)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:97)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:59)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:46)
	at arq.query.main(query.java:65)
	at arq.sparql.main(sparql.java:27)
"
JENA-230,Running queries during graph PUT leads to PUT failing,"1. create empty dir for TDB and start fuseki with that directory as the tdb:location

2. PUT a small file to the graph protocol endpoint
curl -v -H ""Content-Type: text/turtle"" --upload-file small.ttl http://localhost:3030/crashtest/data?graph=http://test1

3. Run a count of all triples (this step not necessary to reproduce, but just a baseline check to compare against later stages).
select (count(*) as ?c) where {?s ?p ?o} 
Answer in my case is 25 (as expected)

4. PUT a big file
curl -v -H ""Content-Type: text/turtle"" --upload-file big.ttl http://localhost:3030/crashtest/data?graph=http://test2
(big enough that it takes at least several seconds to load, so you have time to run some other stuff. My example was about 200,000 triples)

5. Before it finishes, run the count query another 2 or more times.
It comes back with 25 each time. So far so good.

6.  After the big file load is finished (check for 201 Created in log), run the count again.
This is where the problem is evident: the count still shows 25, when it should show 200,000 or so.

(Probably not significant, but my small test file has a few blank nodes in it.  The big file does not).

ls -l of the TDB dir shows lots of data still in nodes.dat-jrnl.  The log includes the line:
""WARN  TDB                  :: Transaction not active: 5""
(full copy of the log below)

Going through the same procedure without running the COUNTs mentioned in stage 5, then everything goes smoothly.  

I'd be interested to hear if anyone else can reproduce this - and of course to hear what you think might be wrong!

Many thanks

Bill

Details:



OS:  Macosx 10.6.8

fuseki-server --version
------------------------------
Jena:       VERSION: 2.7.0-incubating
Jena:       BUILD_DATE: 2011-12-14T14:54:09+0000
ARQ:        VERSION: 2.9.0-incubating
ARQ:        BUILD_DATE: 2011-12-14T15:04:27+0000
TDB:        VERSION: 0.9.0-incubating
TDB:        BUILD_DATE: 2012-02-29T19:39:52+0000
Fuseki:     VERSION: 0.2.2-incubating-SNAPSHOT
Fuseki:     BUILD_DATE: 20120330-0505

java -version
------------------
java version ""1.6.0_29""
Java(TM) SE Runtime Environment (build 1.6.0_29-b11-402-10M3527)
Java HotSpot(TM) 64-Bit Server VM (build 20.4-b02-402, mixed mode)


Config file:
---------------
@prefix tdb:     <http://jena.hpl.hp.com/2008/tdb#> .
@prefix rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs:    <http://www.w3.org/2000/01/rdf-schema#> .
@prefix ja:      <http://jena.hpl.hp.com/2005/11/Assembler#> .
@prefix fuseki:  <http://jena.apache.org/fuseki#> .

[] rdf:type fuseki:Server ;     
  # Services available.  Only explicitly listed services are configured.
  #  If there is a service description not linked from this list, it is ignored.
  fuseki:services (
    <#service1>
  ) .


[] ja:loadClass ""com.hp.hpl.jena.tdb.TDB"" .
tdb:DatasetTDB  rdfs:subClassOf  ja:RDFDataset .
tdb:GraphTDB    rdfs:subClassOf  ja:Model .

<#service1>  rdf:type fuseki:Service ;
   fuseki:name              ""crashtest"" ;       # http://host:port/blah
   fuseki:serviceQuery      ""query"" ;    # SPARQL query service
   fuseki:serviceUpdate     ""update"" ;   # SPARQL update service
   fuseki:serviceReadWriteGraphStore ""data"" ;     # SPARQL Graph store protocol (read and write)
   fuseki:dataset           <#dataset-blah> ;
   .


<#dataset-blah> rdf:type      tdb:DatasetTDB ;
    tdb:location ""/Users/bill/tdb/crashtest"" ;
    # Query timeout on this dataset (1s, 1000 milliseconds)
    ja:context [ ja:cxtName ""arq:queryTimeout"" ;  ja:cxtValue ""10000"" ] ;
    tdb:unionDefaultGraph true ;


fuseki log:
--------------

20:23:51 INFO  Config               :: Configuration file: test.ttl
20:23:51 INFO  Config               :: Service: <file:///Users/bill/code/fuseki-0.2.2/test.ttl#service1>
20:23:51 INFO  Config               ::   name = crashtest
20:23:51 INFO  Config               ::   query = /crashtest/query
20:23:51 INFO  Config               ::   update = /crashtest/update
20:23:51 INFO  Config               ::   graphStore(RW) = /crashtest/data
20:23:52 INFO  Server               :: Dataset path = /crashtest
20:23:52 INFO  Server               :: Fuseki 0.2.2-incubating-SNAPSHOT 20120330-0505
20:23:52 INFO  Server               :: Jetty 7.x.y-SNAPSHOT
20:23:52 INFO  Server               :: Started 2012/04/01 20:23:52 BST on port 3030
20:24:15 INFO  Fuseki               :: [1] PUT http://localhost:3030/crashtest/data?graph=http://test1
20:24:16 INFO  Fuseki               :: [1] 201 Created
20:24:43 INFO  Fuseki               :: [2] GET http://localhost:3030/crashtest/query?query=select+%28count%28*%29+as+%3Fc%29+where+%7B%3Fs+%3Fp+%3Fo%7D+&output=text&stylesheet=%2Fxml-to-html.xsl
20:24:43 INFO  Fuseki               :: [2] Query = select (count(*) as ?c) where {?s ?p ?o} 
20:24:43 INFO  Fuseki               :: [2] OK/select
20:24:43 INFO  Fuseki               :: [2] 200 OK
20:29:12 INFO  Fuseki               :: [3] PUT http://localhost:3030/crashtest/data?graph=http://test2
20:29:14 INFO  Fuseki               :: [4] GET http://localhost:3030/crashtest/query?query=select+%28count%28*%29+as+%3Fc%29+where+%7B%3Fs+%3Fp+%3Fo%7D+&output=text&stylesheet=%2Fxml-to-html.xsl
20:29:14 INFO  Fuseki               :: [4] Query = select (count(*) as ?c) where {?s ?p ?o} 
20:29:14 INFO  Fuseki               :: [4] OK/select
20:29:14 INFO  Fuseki               :: [4] 200 OK
20:29:18 INFO  Fuseki               :: [5] GET http://localhost:3030/crashtest/query?query=select+%28count%28*%29+as+%3Fc%29+where+%7B%3Fs+%3Fp+%3Fo%7D+&output=text&stylesheet=%2Fxml-to-html.xsl
20:29:18 INFO  Fuseki               :: [5] Query = select (count(*) as ?c) where {?s ?p ?o} 
20:29:18 INFO  Fuseki               :: [5] OK/select
20:29:18 INFO  Fuseki               :: [5] 200 OK
20:29:28 WARN  TDB                  :: Transaction not active: 5
20:29:28 INFO  Fuseki               :: [3] 201 Created
20:29:28 INFO  Fuseki               :: [6] GET http://localhost:3030/crashtest/query?query=select+%28count%28*%29+as+%3Fc%29+where+%7B%3Fs+%3Fp+%3Fo%7D+&output=text&stylesheet=%2Fxml-to-html.xsl
20:29:28 INFO  Fuseki               :: [6] Query = select (count(*) as ?c) where {?s ?p ?o} 
20:29:28 INFO  Fuseki               :: [6] OK/select
20:29:28 INFO  Fuseki               :: [6] 200 OK

ls -l crashtest
------------------
drwxr-xr-x  31 bill  bill      1054  1 Apr 20:24 ./
drwxr-xr-x  15 bill  bill       510  1 Apr 20:23 ../
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 GOSP.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 GOSP.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 GPOS.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 GPOS.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 GSPO.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 GSPO.idn
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 OSP.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 OSP.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 OSPG.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 OSPG.idn
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 POS.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 POS.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 POSG.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 POSG.idn
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 SPO.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 SPO.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 SPOG.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 SPOG.idn
-rw-r--r--   1 bill  bill         0  1 Apr 20:24 journal.jrnl
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:24 node2id.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:24 node2id.idn
-rw-r--r--   1 bill  bill      2485  1 Apr 20:24 nodes.dat
-rw-r--r--   1 bill  bill   5596812  1 Apr 20:29 nodes.dat-jrnl
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 prefix2id.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 prefix2id.idn
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 prefixIdx.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 prefixIdx.idn
-rw-r--r--   1 bill  bill         0  1 Apr 20:23 prefixes.dat
-rw-r--r--   1 bill  bill         0  1 Apr 20:24 prefixes.dat-jrnl
",Bug,"Running queries during graph PUT leads to PUT failing 1. create empty dir for TDB and start fuseki with that directory as the tdb:location

2. PUT a small file to the graph protocol endpoint
curl -v -H ""Content-Type: text/turtle"" --upload-file small.ttl http://localhost:3030/crashtest/data?graph=http://test1

3. Run a count of all triples (this step not necessary to reproduce, but just a baseline check to compare against later stages).
select (count(*) as ?c) where {?s ?p ?o} 
Answer in my case is 25 (as expected)

4. PUT a big file
curl -v -H ""Content-Type: text/turtle"" --upload-file big.ttl http://localhost:3030/crashtest/data?graph=http://test2
(big enough that it takes at least several seconds to load, so you have time to run some other stuff. My example was about 200,000 triples)

5. Before it finishes, run the count query another 2 or more times.
It comes back with 25 each time. So far so good.

6.  After the big file load is finished (check for 201 Created in log), run the count again.
This is where the problem is evident: the count still shows 25, when it should show 200,000 or so.

(Probably not significant, but my small test file has a few blank nodes in it.  The big file does not).

ls -l of the TDB dir shows lots of data still in nodes.dat-jrnl.  The log includes the line:
""WARN  TDB                  :: Transaction not active: 5""
(full copy of the log below)

Going through the same procedure without running the COUNTs mentioned in stage 5, then everything goes smoothly.  

I'd be interested to hear if anyone else can reproduce this - and of course to hear what you think might be wrong!

Many thanks

Bill

Details:



OS:  Macosx 10.6.8

fuseki-server --version
------------------------------
Jena:       VERSION: 2.7.0-incubating
Jena:       BUILD_DATE: 2011-12-14T14:54:09+0000
ARQ:        VERSION: 2.9.0-incubating
ARQ:        BUILD_DATE: 2011-12-14T15:04:27+0000
TDB:        VERSION: 0.9.0-incubating
TDB:        BUILD_DATE: 2012-02-29T19:39:52+0000
Fuseki:     VERSION: 0.2.2-incubating-SNAPSHOT
Fuseki:     BUILD_DATE: 20120330-0505

java -version
------------------
java version ""1.6.0_29""
Java(TM) SE Runtime Environment (build 1.6.0_29-b11-402-10M3527)
Java HotSpot(TM) 64-Bit Server VM (build 20.4-b02-402, mixed mode)


Config file:
---------------
@prefix tdb:     <http://jena.hpl.hp.com/2008/tdb#> .
@prefix rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs:    <http://www.w3.org/2000/01/rdf-schema#> .
@prefix ja:      <http://jena.hpl.hp.com/2005/11/Assembler#> .
@prefix fuseki:  <http://jena.apache.org/fuseki#> .

[] rdf:type fuseki:Server ;     
  # Services available.  Only explicitly listed services are configured.
  #  If there is a service description not linked from this list, it is ignored.
  fuseki:services (
    <#service1>
  ) .


[] ja:loadClass ""com.hp.hpl.jena.tdb.TDB"" .
tdb:DatasetTDB  rdfs:subClassOf  ja:RDFDataset .
tdb:GraphTDB    rdfs:subClassOf  ja:Model .

<#service1>  rdf:type fuseki:Service ;
   fuseki:name              ""crashtest"" ;       # http://host:port/blah
   fuseki:serviceQuery      ""query"" ;    # SPARQL query service
   fuseki:serviceUpdate     ""update"" ;   # SPARQL update service
   fuseki:serviceReadWriteGraphStore ""data"" ;     # SPARQL Graph store protocol (read and write)
   fuseki:dataset           <#dataset-blah> ;
   .


<#dataset-blah> rdf:type      tdb:DatasetTDB ;
    tdb:location ""/Users/bill/tdb/crashtest"" ;
    # Query timeout on this dataset (1s, 1000 milliseconds)
    ja:context [ ja:cxtName ""arq:queryTimeout"" ;  ja:cxtValue ""10000"" ] ;
    tdb:unionDefaultGraph true ;


fuseki log:
--------------

20:23:51 INFO  Config               :: Configuration file: test.ttl
20:23:51 INFO  Config               :: Service: <file:///Users/bill/code/fuseki-0.2.2/test.ttl#service1>
20:23:51 INFO  Config               ::   name = crashtest
20:23:51 INFO  Config               ::   query = /crashtest/query
20:23:51 INFO  Config               ::   update = /crashtest/update
20:23:51 INFO  Config               ::   graphStore(RW) = /crashtest/data
20:23:52 INFO  Server               :: Dataset path = /crashtest
20:23:52 INFO  Server               :: Fuseki 0.2.2-incubating-SNAPSHOT 20120330-0505
20:23:52 INFO  Server               :: Jetty 7.x.y-SNAPSHOT
20:23:52 INFO  Server               :: Started 2012/04/01 20:23:52 BST on port 3030
20:24:15 INFO  Fuseki               :: [1] PUT http://localhost:3030/crashtest/data?graph=http://test1
20:24:16 INFO  Fuseki               :: [1] 201 Created
20:24:43 INFO  Fuseki               :: [2] GET http://localhost:3030/crashtest/query?query=select+%28count%28*%29+as+%3Fc%29+where+%7B%3Fs+%3Fp+%3Fo%7D+&output=text&stylesheet=%2Fxml-to-html.xsl
20:24:43 INFO  Fuseki               :: [2] Query = select (count(*) as ?c) where {?s ?p ?o} 
20:24:43 INFO  Fuseki               :: [2] OK/select
20:24:43 INFO  Fuseki               :: [2] 200 OK
20:29:12 INFO  Fuseki               :: [3] PUT http://localhost:3030/crashtest/data?graph=http://test2
20:29:14 INFO  Fuseki               :: [4] GET http://localhost:3030/crashtest/query?query=select+%28count%28*%29+as+%3Fc%29+where+%7B%3Fs+%3Fp+%3Fo%7D+&output=text&stylesheet=%2Fxml-to-html.xsl
20:29:14 INFO  Fuseki               :: [4] Query = select (count(*) as ?c) where {?s ?p ?o} 
20:29:14 INFO  Fuseki               :: [4] OK/select
20:29:14 INFO  Fuseki               :: [4] 200 OK
20:29:18 INFO  Fuseki               :: [5] GET http://localhost:3030/crashtest/query?query=select+%28count%28*%29+as+%3Fc%29+where+%7B%3Fs+%3Fp+%3Fo%7D+&output=text&stylesheet=%2Fxml-to-html.xsl
20:29:18 INFO  Fuseki               :: [5] Query = select (count(*) as ?c) where {?s ?p ?o} 
20:29:18 INFO  Fuseki               :: [5] OK/select
20:29:18 INFO  Fuseki               :: [5] 200 OK
20:29:28 WARN  TDB                  :: Transaction not active: 5
20:29:28 INFO  Fuseki               :: [3] 201 Created
20:29:28 INFO  Fuseki               :: [6] GET http://localhost:3030/crashtest/query?query=select+%28count%28*%29+as+%3Fc%29+where+%7B%3Fs+%3Fp+%3Fo%7D+&output=text&stylesheet=%2Fxml-to-html.xsl
20:29:28 INFO  Fuseki               :: [6] Query = select (count(*) as ?c) where {?s ?p ?o} 
20:29:28 INFO  Fuseki               :: [6] OK/select
20:29:28 INFO  Fuseki               :: [6] 200 OK

ls -l crashtest
------------------
drwxr-xr-x  31 bill  bill      1054  1 Apr 20:24 ./
drwxr-xr-x  15 bill  bill       510  1 Apr 20:23 ../
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 GOSP.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 GOSP.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 GPOS.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 GPOS.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 GSPO.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 GSPO.idn
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 OSP.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 OSP.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 OSPG.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 OSPG.idn
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 POS.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 POS.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 POSG.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 POSG.idn
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 SPO.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 SPO.idn
-rw-r--r--   1 bill  bill  16777216  1 Apr 20:29 SPOG.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 SPOG.idn
-rw-r--r--   1 bill  bill         0  1 Apr 20:24 journal.jrnl
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:24 node2id.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:24 node2id.idn
-rw-r--r--   1 bill  bill      2485  1 Apr 20:24 nodes.dat
-rw-r--r--   1 bill  bill   5596812  1 Apr 20:29 nodes.dat-jrnl
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 prefix2id.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 prefix2id.idn
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 prefixIdx.dat
-rw-r--r--   1 bill  bill   8388608  1 Apr 20:23 prefixIdx.idn
-rw-r--r--   1 bill  bill         0  1 Apr 20:23 prefixes.dat
-rw-r--r--   1 bill  bill         0  1 Apr 20:24 prefixes.dat-jrnl
"
JENA-225,TDB datasets can be corrupted by performing certain operations within a transaction ,"In a web application, we read some triples in a HTTP POST, using a LangTurtle instance and a tokenizer obtained from from TokenizerFactory.makeTokenizerUTF8. 
We then write the parsed Triples back out (to temporary storage) using OutputLangUtils.write. At some later time, these Triples are then re-read, again using a Tokenizer from TokenizerFactory.makeTokenizerUTF8, before being inserted into a TDB dataset. 
We have found it possible for the the input data to contain character strings which pass through the various parsers/serializers but which cause TDB's transaction layer to error in such a way as to make recovery from journals ineffective. 

Eliminating transactions from the code path enables the database to be updated successfully.

The stacktrace from TDB looks like this: 
org.openjena.riot.RiotParseException: [line: 1, col: 2 ] Broken token: Hello 
	at org.openjena.riot.tokens.TokenizerText.exception(TokenizerText.java:1209)
	at org.openjena.riot.tokens.TokenizerText.readString(TokenizerText.java:620)
	at org.openjena.riot.tokens.TokenizerText.parseToken(TokenizerText.java:248)
	at org.openjena.riot.tokens.TokenizerText.hasNext(TokenizerText.java:112)
	at com.hp.hpl.jena.tdb.nodetable.NodecSSE.decode(NodecSSE.java:105)
	at com.hp.hpl.jena.tdb.lib.NodeLib.decode(NodeLib.java:93)
	at com.hp.hpl.jena.tdb.nodetable.NodeTableNative$2.convert(NodeTableNative.java:234)
	at com.hp.hpl.jena.tdb.nodetable.NodeTableNative$2.convert(NodeTableNative.java:228)
	at org.openjena.atlas.iterator.Iter$4.next(Iter.java:301)
	at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.append(NodeTableTrans.java:188)
	at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.writeNodeJournal(NodeTableTrans.java:306)
	at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.commitPrepare(NodeTableTrans.java:266)
	at com.hp.hpl.jena.tdb.transaction.Transaction.prepare(Transaction.java:131)
	at com.hp.hpl.jena.tdb.transaction.Transaction.commit(Transaction.java:112)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.commit(DatasetGraphTxn.java:40)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._commit(DatasetGraphTransaction.java:106)
	at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.commit(DatasetGraphTrackActive.java:60)
	at com.hp.hpl.jena.sparql.core.DatasetImpl.commit(DatasetImpl.java:143)

At least part of the issue seems to be stem from NodecSSE (I know this isn't actual unicode escaping, but its derived from the user input we've received). 

String s = ""Hello \uDAE0 World"";
Node literal = Node.createLiteral(s);
ByteBuffer bb = NodeLib.encode(literal);
NodeLib.decode(bb);
",Bug,"TDB datasets can be corrupted by performing certain operations within a transaction  In a web application, we read some triples in a HTTP POST, using a LangTurtle instance and a tokenizer obtained from from TokenizerFactory.makeTokenizerUTF8. 
We then write the parsed Triples back out (to temporary storage) using OutputLangUtils.write. At some later time, these Triples are then re-read, again using a Tokenizer from TokenizerFactory.makeTokenizerUTF8, before being inserted into a TDB dataset. 
We have found it possible for the the input data to contain character strings which pass through the various parsers/serializers but which cause TDB's transaction layer to error in such a way as to make recovery from journals ineffective. 

Eliminating transactions from the code path enables the database to be updated successfully.

The stacktrace from TDB looks like this: 
org.openjena.riot.RiotParseException: [line: 1, col: 2 ] Broken token: Hello 
	at org.openjena.riot.tokens.TokenizerText.exception(TokenizerText.java:1209)
	at org.openjena.riot.tokens.TokenizerText.readString(TokenizerText.java:620)
	at org.openjena.riot.tokens.TokenizerText.parseToken(TokenizerText.java:248)
	at org.openjena.riot.tokens.TokenizerText.hasNext(TokenizerText.java:112)
	at com.hp.hpl.jena.tdb.nodetable.NodecSSE.decode(NodecSSE.java:105)
	at com.hp.hpl.jena.tdb.lib.NodeLib.decode(NodeLib.java:93)
	at com.hp.hpl.jena.tdb.nodetable.NodeTableNative$2.convert(NodeTableNative.java:234)
	at com.hp.hpl.jena.tdb.nodetable.NodeTableNative$2.convert(NodeTableNative.java:228)
	at org.openjena.atlas.iterator.Iter$4.next(Iter.java:301)
	at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.append(NodeTableTrans.java:188)
	at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.writeNodeJournal(NodeTableTrans.java:306)
	at com.hp.hpl.jena.tdb.transaction.NodeTableTrans.commitPrepare(NodeTableTrans.java:266)
	at com.hp.hpl.jena.tdb.transaction.Transaction.prepare(Transaction.java:131)
	at com.hp.hpl.jena.tdb.transaction.Transaction.commit(Transaction.java:112)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTxn.commit(DatasetGraphTxn.java:40)
	at com.hp.hpl.jena.tdb.transaction.DatasetGraphTransaction._commit(DatasetGraphTransaction.java:106)
	at com.hp.hpl.jena.tdb.migrate.DatasetGraphTrackActive.commit(DatasetGraphTrackActive.java:60)
	at com.hp.hpl.jena.sparql.core.DatasetImpl.commit(DatasetImpl.java:143)

At least part of the issue seems to be stem from NodecSSE (I know this isn't actual unicode escaping, but its derived from the user input we've received). 

String s = ""Hello \uDAE0 World"";
Node literal = Node.createLiteral(s);
ByteBuffer bb = NodeLib.encode(literal);
NodeLib.decode(bb);
"
JENA-223,Default memory model will not remove (partially) reified statements,"From antiguru on IRC:

Model m = ModelFactory.createDefaultModel();
Resource r = m.createResource(""http://example.com/a"");
r.addProperty(RDF.object, ""test1""); // or predicate or subject
m.removeAll(r, null, null);
System.err.println(m.size()); // => 1

Works (returns 0) with:

ModelFactory.createMemModelMaker(ReificationStyle.Minimal).createDefaultModel();",Bug,"Default memory model will not remove (partially) reified statements From antiguru on IRC:

Model m = ModelFactory.createDefaultModel();
Resource r = m.createResource(""http://example.com/a"");
r.addProperty(RDF.object, ""test1""); // or predicate or subject
m.removeAll(r, null, null);
System.err.println(m.size()); // => 1

Works (returns 0) with:

ModelFactory.createMemModelMaker(ReificationStyle.Minimal).createDefaultModel();"
JENA-222,"Graph.size() reports '0' for TDB ""urn:x-arq:UnionGraph""","using

    Dataset dataset = TDBFactory.createDataset(dir);
    Model model dataset.getNamedModel(""urn:x-arq:UnionGraph"");
    Graph graph = model.getGraph();
    int size = graph.size();

size will always report zero regardless of the amount of triples stored in the different named models of the dataset.

I think this is because com.hp.hpl.jena.tdb.store.GraphNamedTDB#countThis() would need special treatment in case of  ""isQuadUnionGraph(graphNode) == true""
",Bug,"Graph.size() reports '0' for TDB ""urn:x-arq:UnionGraph"" using

    Dataset dataset = TDBFactory.createDataset(dir);
    Model model dataset.getNamedModel(""urn:x-arq:UnionGraph"");
    Graph graph = model.getGraph();
    int size = graph.size();

size will always report zero regardless of the amount of triples stored in the different named models of the dataset.

I think this is because com.hp.hpl.jena.tdb.store.GraphNamedTDB#countThis() would need special treatment in case of  ""isQuadUnionGraph(graphNode) == true""
"
JENA-221,sparql.tpl in Fuseki control panel makes requests against the wrong endpoints,Likely a copy-and-paste error. pages/sparql.tpl tries to perform all requests against the query endpoint. Patch shortly...,Bug,sparql.tpl in Fuseki control panel makes requests against the wrong endpoints Likely a copy-and-paste error. pages/sparql.tpl tries to perform all requests against the query endpoint. Patch shortly...
JENA-217,tdbloader : Unsafe memory access operation,"First of all, I'm not sure if this is necessarily a bug or whether my system encountered some other issue. Here it is:

I'm trying to import world-development-indicators.nt which is 68 GB into a TDB store.

I've performed the following operation:

java tdb.tdbloader --loc /usr/lib/fuseki/DB/DB.worldbank2 world-development-indicators --graph=http://worldbank.270a.info/graph/world-bank-indicators /data/worldbank.270a.info/indicators/en/indicator/world-bank-indicators.nt

..
360,393,432 triples loaded in 15,956.80 seconds [Rate: 22,585.57 per second]
..
** Index GSPO->GPOS: 360,202,756 slots indexed in 18,194.61 seconds [Rate: 19,797.23 per second]
..
** Index GSPO->GOSP: 360,202,756 slots indexed in 4,410.64 seconds [Rate: 81,666.85 per second]
..
** Index GSPO->POSG: 360,202,756 slots indexed in 4,354.58 seconds [Rate: 82,718.05 per second]
..
** Index GSPO->OSPG: 360,202,756 slots indexed in 4,084.50 seconds [Rate: 88,187.73 per second]
..
Index GSPO->SPOG: 113,900,000 slots (Batch: 213,675 slots/s / Avg: 113,695 slots/s)
Exception in thread ""main"" java.lang.InternalError: a fault occurred in a recent unsafe memory access operation in compiled Java code
        at com.hp.hpl.jena.tdb.lib.TupleLib.tuple(TupleLib.java:208)
        at com.hp.hpl.jena.tdb.index.TupleIndexRecord$1.convert(TupleIndexRecord.java:195)
        at com.hp.hpl.jena.tdb.index.TupleIndexRecord$1.convert(TupleIndexRecord.java:191)
        at org.openjena.atlas.iterator.Iter$4.next(Iter.java:293)
        at com.hp.hpl.jena.tdb.store.bulkloader.LoaderNodeTupleTable.copyIndex(LoaderNodeTupleTable.java:209)
        at com.hp.hpl.jena.tdb.store.bulkloader.BuilderSecondaryIndexesSequential.createSecondaryIndexes(BuilderSecondaryIndexesSequential.java:43)
        at com.hp.hpl.jena.tdb.store.bulkloader.LoaderNodeTupleTable.createSecondaryIndexes(LoaderNodeTupleTable.java:192)
        at com.hp.hpl.jena.tdb.store.bulkloader.LoaderNodeTupleTable.loadSecondaryIndexes(LoaderNodeTupleTable.java:91)
        at com.hp.hpl.jena.tdb.store.bulkloader.LoaderNodeTupleTable.loadIndexStart(LoaderNodeTupleTable.java:144)
        at com.hp.hpl.jena.tdb.store.bulkloader.BulkLoader$1.finish(BulkLoader.java:232)
        at com.hp.hpl.jena.tdb.store.bulkloader.BulkLoader.loadTriples$(BulkLoader.java:141)
        at com.hp.hpl.jena.tdb.store.bulkloader.BulkLoader.loadNamedGraph(BulkLoader.java:107)
        at com.hp.hpl.jena.tdb.TDBLoader.loadNamedGraph$(TDBLoader.java:271)
        at com.hp.hpl.jena.tdb.TDBLoader.loadGraph$(TDBLoader.java:246)
        at com.hp.hpl.jena.tdb.TDBLoader.loadGraph(TDBLoader.java:177)
        at com.hp.hpl.jena.tdb.TDBLoader.load(TDBLoader.java:112)
        at tdb.tdbloader.loadNamedGraph(tdbloader.java:157)
        at tdb.tdbloader.exec(tdbloader.java:142)
        at arq.cmdline.CmdMain.mainMethod(CmdMain.java:97)
        at arq.cmdline.CmdMain.mainRun(CmdMain.java:59)
        at arq.cmdline.CmdMain.mainRun(CmdMain.java:46)
        at tdb.tdbloader.main(tdbloader.java:53)
",Bug,"tdbloader : Unsafe memory access operation First of all, I'm not sure if this is necessarily a bug or whether my system encountered some other issue. Here it is:

I'm trying to import world-development-indicators.nt which is 68 GB into a TDB store.

I've performed the following operation:

java tdb.tdbloader --loc /usr/lib/fuseki/DB/DB.worldbank2 world-development-indicators --graph=http://worldbank.270a.info/graph/world-bank-indicators /data/worldbank.270a.info/indicators/en/indicator/world-bank-indicators.nt

..
360,393,432 triples loaded in 15,956.80 seconds [Rate: 22,585.57 per second]
..
** Index GSPO->GPOS: 360,202,756 slots indexed in 18,194.61 seconds [Rate: 19,797.23 per second]
..
** Index GSPO->GOSP: 360,202,756 slots indexed in 4,410.64 seconds [Rate: 81,666.85 per second]
..
** Index GSPO->POSG: 360,202,756 slots indexed in 4,354.58 seconds [Rate: 82,718.05 per second]
..
** Index GSPO->OSPG: 360,202,756 slots indexed in 4,084.50 seconds [Rate: 88,187.73 per second]
..
Index GSPO->SPOG: 113,900,000 slots (Batch: 213,675 slots/s / Avg: 113,695 slots/s)
Exception in thread ""main"" java.lang.InternalError: a fault occurred in a recent unsafe memory access operation in compiled Java code
        at com.hp.hpl.jena.tdb.lib.TupleLib.tuple(TupleLib.java:208)
        at com.hp.hpl.jena.tdb.index.TupleIndexRecord$1.convert(TupleIndexRecord.java:195)
        at com.hp.hpl.jena.tdb.index.TupleIndexRecord$1.convert(TupleIndexRecord.java:191)
        at org.openjena.atlas.iterator.Iter$4.next(Iter.java:293)
        at com.hp.hpl.jena.tdb.store.bulkloader.LoaderNodeTupleTable.copyIndex(LoaderNodeTupleTable.java:209)
        at com.hp.hpl.jena.tdb.store.bulkloader.BuilderSecondaryIndexesSequential.createSecondaryIndexes(BuilderSecondaryIndexesSequential.java:43)
        at com.hp.hpl.jena.tdb.store.bulkloader.LoaderNodeTupleTable.createSecondaryIndexes(LoaderNodeTupleTable.java:192)
        at com.hp.hpl.jena.tdb.store.bulkloader.LoaderNodeTupleTable.loadSecondaryIndexes(LoaderNodeTupleTable.java:91)
        at com.hp.hpl.jena.tdb.store.bulkloader.LoaderNodeTupleTable.loadIndexStart(LoaderNodeTupleTable.java:144)
        at com.hp.hpl.jena.tdb.store.bulkloader.BulkLoader$1.finish(BulkLoader.java:232)
        at com.hp.hpl.jena.tdb.store.bulkloader.BulkLoader.loadTriples$(BulkLoader.java:141)
        at com.hp.hpl.jena.tdb.store.bulkloader.BulkLoader.loadNamedGraph(BulkLoader.java:107)
        at com.hp.hpl.jena.tdb.TDBLoader.loadNamedGraph$(TDBLoader.java:271)
        at com.hp.hpl.jena.tdb.TDBLoader.loadGraph$(TDBLoader.java:246)
        at com.hp.hpl.jena.tdb.TDBLoader.loadGraph(TDBLoader.java:177)
        at com.hp.hpl.jena.tdb.TDBLoader.load(TDBLoader.java:112)
        at tdb.tdbloader.loadNamedGraph(tdbloader.java:157)
        at tdb.tdbloader.exec(tdbloader.java:142)
        at arq.cmdline.CmdMain.mainMethod(CmdMain.java:97)
        at arq.cmdline.CmdMain.mainRun(CmdMain.java:59)
        at arq.cmdline.CmdMain.mainRun(CmdMain.java:46)
        at tdb.tdbloader.main(tdbloader.java:53)
"
JENA-216,Official Turtle Test-18 does not parse,"I am having trouble Trying to parse http://www.w3.org/TR/turtle/tests/test-18.ttl which contains the following two lines

<http://example.org/foo#a> <http://example.org/foo#b> ""\nthis \ris a \U00015678long\t\nliteral\uABCD\n"" .
<http://example.org/foo#d> <http://example.org/foo#e> ""\tThis \uABCDis\r \U00015678another\n\none\n"" .

scala> import java.io._
import java.io._

scala> import com.hp.hpl.jena.rdf.model._
import com.hp.hpl.jena.rdf.model._

scala> val f = ""/Volumes/Dev/Programming/w3.org/git/pimp-my-rdf/n3-test-suite/target/scala-2.9.1/classes/www.w3.org/TR/turtle/tests/test-18.out""
f: java.lang.String = /Volumes/Dev/Programming/w3.org/git/pimp-my-rdf/n3-test-suite/target/scala-2.9.1/classes/www.w3.org/TR/turtle/tests/test-18.out

scala> val in = new InputStreamReader(new BufferedInputStream(new FileInputStream(f)),""UTF-8"")
in: java.io.InputStreamReader = java.io.InputStreamReader@1e392427

scala> val model = ModelFactory.createDefaultModel()
model: com.hp.hpl.jena.rdf.model.Model = <ModelCom   {} | >

scala> model.read(in,""file:/""+f,""TTL"")
com.hp.hpl.jena.n3.turtle.TurtleParseException: Lexical error at line 1, column 71.  Encountered: ""U"" (85), after : ""\""\\nthis \\ris a \\""
	at com.hp.hpl.jena.n3.turtle.ParserTurtle.parse(ParserTurtle.java:56)
	at com.hp.hpl.jena.n3.turtle.TurtleReader.readWorker(TurtleReader.java:33)
	at com.hp.hpl.jena.n3.JenaReaderBase.readImpl(JenaReaderBase.java:119)
	at com.hp.hpl.jena.n3.JenaReaderBase.read(JenaReaderBase.java:49)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:261)

or more directly

 scala> model.read(""http://www.w3.org/TR/turtle/tests/test-18.ttl"",""TTL"")
com.hp.hpl.jena.n3.turtle.TurtleParseException: Lexical error at line 3, column 25.  Encountered: ""U"" (85), after : ""\""\\nthis \\ris a \\""
	at com.hp.hpl.jena.n3.turtle.ParserTurtle.parse(ParserTurtle.java:56)
	at com.hp.hpl.jena.n3.turtle.TurtleReader.readWorker(TurtleReader.java:33)
	at com.hp.hpl.jena.n3.JenaReaderBase.readImpl(JenaReaderBase.java:119)
	at com.hp.hpl.jena.n3.JenaReaderBase.read(JenaReaderBase.java:49)
	at com.hp.hpl.jena.n3.JenaReaderBase.read(JenaReaderBase.java:60)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:241)

This is with the 2.9 release of Jena for December which I imported into my project with 

    ""org.apache.jena"" % ""jena-arq"" % ""2.9.0-incubating""

",Bug,"Official Turtle Test-18 does not parse I am having trouble Trying to parse http://www.w3.org/TR/turtle/tests/test-18.ttl which contains the following two lines

<http://example.org/foo#a> <http://example.org/foo#b> ""\nthis \ris a \U00015678long\t\nliteral\uABCD\n"" .
<http://example.org/foo#d> <http://example.org/foo#e> ""\tThis \uABCDis\r \U00015678another\n\none\n"" .

scala> import java.io._
import java.io._

scala> import com.hp.hpl.jena.rdf.model._
import com.hp.hpl.jena.rdf.model._

scala> val f = ""/Volumes/Dev/Programming/w3.org/git/pimp-my-rdf/n3-test-suite/target/scala-2.9.1/classes/www.w3.org/TR/turtle/tests/test-18.out""
f: java.lang.String = /Volumes/Dev/Programming/w3.org/git/pimp-my-rdf/n3-test-suite/target/scala-2.9.1/classes/www.w3.org/TR/turtle/tests/test-18.out

scala> val in = new InputStreamReader(new BufferedInputStream(new FileInputStream(f)),""UTF-8"")
in: java.io.InputStreamReader = java.io.InputStreamReader@1e392427

scala> val model = ModelFactory.createDefaultModel()
model: com.hp.hpl.jena.rdf.model.Model = <ModelCom   {} | >

scala> model.read(in,""file:/""+f,""TTL"")
com.hp.hpl.jena.n3.turtle.TurtleParseException: Lexical error at line 1, column 71.  Encountered: ""U"" (85), after : ""\""\\nthis \\ris a \\""
	at com.hp.hpl.jena.n3.turtle.ParserTurtle.parse(ParserTurtle.java:56)
	at com.hp.hpl.jena.n3.turtle.TurtleReader.readWorker(TurtleReader.java:33)
	at com.hp.hpl.jena.n3.JenaReaderBase.readImpl(JenaReaderBase.java:119)
	at com.hp.hpl.jena.n3.JenaReaderBase.read(JenaReaderBase.java:49)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:261)

or more directly

 scala> model.read(""http://www.w3.org/TR/turtle/tests/test-18.ttl"",""TTL"")
com.hp.hpl.jena.n3.turtle.TurtleParseException: Lexical error at line 3, column 25.  Encountered: ""U"" (85), after : ""\""\\nthis \\ris a \\""
	at com.hp.hpl.jena.n3.turtle.ParserTurtle.parse(ParserTurtle.java:56)
	at com.hp.hpl.jena.n3.turtle.TurtleReader.readWorker(TurtleReader.java:33)
	at com.hp.hpl.jena.n3.JenaReaderBase.readImpl(JenaReaderBase.java:119)
	at com.hp.hpl.jena.n3.JenaReaderBase.read(JenaReaderBase.java:49)
	at com.hp.hpl.jena.n3.JenaReaderBase.read(JenaReaderBase.java:60)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:241)

This is with the 2.9 release of Jena for December which I imported into my project with 

    ""org.apache.jena"" % ""jena-arq"" % ""2.9.0-incubating""

"
JENA-212,schemagen script is missing from Jena 2.7.0 release,"The bin directory in the Jena release doesn't contain the schemagen script, even though this is in svn and, afaict, was there at the time of the release. Suggests a possible problem with the build script?",Bug,"schemagen script is missing from Jena 2.7.0 release The bin directory in the Jena release doesn't contain the schemagen script, even though this is in svn and, afaict, was there at the time of the release. Suggests a possible problem with the build script?"
JENA-211,DISTINCT isn't distinct in the presence of anon variables.,The DISTINCT (and REDUCED) iterators don't mask hidden variables (bnodes and rewrite-introducded hdden variables),Bug,DISTINCT isn't distinct in the presence of anon variables. The DISTINCT (and REDUCED) iterators don't mask hidden variables (bnodes and rewrite-introducded hdden variables)
JENA-208,The command line applications need to set up log4j.,"Without a log4j setup, the command line tools will issue some warning messages.

The commands should not do this - there needs to be a way to run command lien applications without other set up assumptions.

See also JENA-36.
",Bug,"The command line applications need to set up log4j. Without a log4j setup, the command line tools will issue some warning messages.

The commands should not do this - there needs to be a way to run command lien applications without other set up assumptions.

See also JENA-36.
"
JENA-207,FmtUtils.stringForNode() does not escape tab characters,"FmtUtils.stringForNode() delegates literal formatting to FmtUtils.stringForLiteral() which delegates string escaping to stringEsc()

The issue is that the whitespace escaping section has code to deal with escaping tab characters but has a logical flaw which means tab characters won't hit that code path, the if statement surrounding the white space escapes section checks for the other kinds of whitespace characters but not for tab",Bug,"FmtUtils.stringForNode() does not escape tab characters FmtUtils.stringForNode() delegates literal formatting to FmtUtils.stringForLiteral() which delegates string escaping to stringEsc()

The issue is that the whitespace escaping section has code to deal with escaping tab characters but has a logical flaw which means tab characters won't hit that code path, the if statement surrounding the white space escapes section checks for the other kinds of whitespace characters but not for tab"
JENA-200,TSVInput does not check for malformed header row,As a side effect of discovering JENA-199 I noticed that TSVInput does not check for a malformed header row (null/empty),Bug,TSVInput does not check for malformed header row As a side effect of discovering JENA-199 I noticed that TSVInput does not check for a malformed header row (null/empty)
JENA-198,TSV Output may be invalid but TSV Input reads it fine,"I noticed today that TSVOutput may produce output that contains prefixed names which is invalid per my reading of the relevant specification - http://www.w3.org/TR/sparql11-results-csv-tsv/

This is due to the fact that TSVOutput called FmtUtils.stringForNode() with only a Node resulting in it using the ARQ default prefix mapping for output.

Attached is a simple patch which fixes the issue, it should also speed up TSVOutput marginally as the existing code requires a SerializationContext to be created for every term serialized and incurs the cost of trying to turn URIs into prefixed names.  Essentially the patch creates a null SerializationContext variable and just passes that to every call to FmtUtils.stringForNode() so that the ARQ default prefix mapping never gets used.

The second part of the issue is that this malformed TSV input may be accepted because TSVInputIterator uses NodeFactory.parseNode() to parse terms which calls SSE.parseNode() without any prefix mapping and thus internally ends up using the default SSE prefix mapping which means some prefixed names get permitted as valid when they should be rejected.

The second patch attached fixes this part of the issue by keeping an empty static prefix map and calling SSE.parseNode() directly and passing in this map.",Bug,"TSV Output may be invalid but TSV Input reads it fine I noticed today that TSVOutput may produce output that contains prefixed names which is invalid per my reading of the relevant specification - http://www.w3.org/TR/sparql11-results-csv-tsv/

This is due to the fact that TSVOutput called FmtUtils.stringForNode() with only a Node resulting in it using the ARQ default prefix mapping for output.

Attached is a simple patch which fixes the issue, it should also speed up TSVOutput marginally as the existing code requires a SerializationContext to be created for every term serialized and incurs the cost of trying to turn URIs into prefixed names.  Essentially the patch creates a null SerializationContext variable and just passes that to every call to FmtUtils.stringForNode() so that the ARQ default prefix mapping never gets used.

The second part of the issue is that this malformed TSV input may be accepted because TSVInputIterator uses NodeFactory.parseNode() to parse terms which calls SSE.parseNode() without any prefix mapping and thus internally ends up using the default SSE prefix mapping which means some prefixed names get permitted as valid when they should be rejected.

The second patch attached fixes this part of the issue by keeping an empty static prefix map and calling SSE.parseNode() directly and passing in this map."
JENA-187,TSVInput parses all at once rather than streaming,"TSVInput parses TSV result sets all at once into memory and then wraps them in a query iterator which is very naive and results in OutOfMemoryException once you have a large number of results

I will submit a patch that address this later today once I've written the code to fix this",Bug,"TSVInput parses all at once rather than streaming TSVInput parses TSV result sets all at once into memory and then wraps them in a query iterator which is very naive and results in OutOfMemoryException once you have a large number of results

I will submit a patch that address this later today once I've written the code to fix this"
JENA-181,Fuseki starts producing 500 errors if rapidly sent a sequence of queries,"It is fairly trivial to cause Fuseki to start generating a 500 : Direct buffer memory error code in response to queries simply by sending a sequence of queries to it with no delays between them, even with a short delay e.g. 0.5 seconds Fuseki will typically get into this state at a similar point.

Attached is a simple test case which fires SELECT * WHERE { } queries at a local Fuseki instance, for me this reliably fails on the 25th iteration, turning on --debug and --verbose for Fuseki and modifying the log4j.properties file to set DEBUG level for everything didn't show anything particularly useful on the command line so I have no idea what the cause of this may be beyond something related to java.nio.HeapByteBuffer",Bug,"Fuseki starts producing 500 errors if rapidly sent a sequence of queries It is fairly trivial to cause Fuseki to start generating a 500 : Direct buffer memory error code in response to queries simply by sending a sequence of queries to it with no delays between them, even with a short delay e.g. 0.5 seconds Fuseki will typically get into this state at a similar point.

Attached is a simple test case which fires SELECT * WHERE { } queries at a local Fuseki instance, for me this reliably fails on the 25th iteration, turning on --debug and --verbose for Fuseki and modifying the log4j.properties file to set DEBUG level for everything didn't show anything particularly useful on the command line so I have no idea what the cause of this may be beyond something related to java.nio.HeapByteBuffer"
JENA-179,On Linux Fuseki will create user owned temporary files that block other users from using the full Fuseki Web UI,"Fuseki seems to create temporary files under Linux which are owned by the running user and blocks any other users from running Fuseki properly because servlets will not function correctly.

Going to the control panel will produce the following trace:

Error 500: /tmp/org/apache/jsp/control_002dpanel_jsp.java (Permission denied)

java.io.FileNotFoundException: /tmp/org/apache/jsp/control_002dpanel_jsp.java (Permission denied)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:179)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:70)
	at org.apache.jasper.compiler.JDTJavaCompiler.getJavaWriter(JDTJavaCompiler.java:149)
	at org.apache.jasper.compiler.Compiler.generateJava(Compiler.java:188)
	at org.apache.jasper.compiler.Compiler.compile(Compiler.java:435)
	at org.apache.jasper.JspCompilationContext.compile(JspCompilationContext.java:608)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:360)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:486)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:380)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:534)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:475)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:224)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:921)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:403)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:184)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:856)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:114)
	at org.eclipse.jetty.server.Server.handle(Server.java:348)
	at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.java:596)
	at org.eclipse.jetty.server.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:1052)
	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:590)
	at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:212)
	at org.eclipse.jetty.server.HttpConnection.handle(HttpConnection.java:426)
	at org.eclipse.jetty.server.nio.BlockingChannelConnector$BlockingChannelEndPoint.run(BlockingChannelConnector.java:292)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:450)
	at java.lang.Thread.run(Thread.java:619)



Fuseki - version 0.2.0 (Date: 2011-12-15T15:19:16-0800)

It looks like these temporary files are being generated by one of the components Fuseki relies upon rather than Fuseki itself but this is an issue for us because if one user has run Fuseki another user may be completely blocked from using the web based UI fully.

Interestingly servlets will still function correctly, e.g. I can still issue queries directly to /dataset/query and get a response but the lack of a control panel is inconvenient.

This may not be fixable due to it actually being caused by a component that Fuseki depends upon but I have no expertise in Jetty/JSP/Servlets so I don't know against what project this bug should actually be filed.",Bug,"On Linux Fuseki will create user owned temporary files that block other users from using the full Fuseki Web UI Fuseki seems to create temporary files under Linux which are owned by the running user and blocks any other users from running Fuseki properly because servlets will not function correctly.

Going to the control panel will produce the following trace:

Error 500: /tmp/org/apache/jsp/control_002dpanel_jsp.java (Permission denied)

java.io.FileNotFoundException: /tmp/org/apache/jsp/control_002dpanel_jsp.java (Permission denied)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:179)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:70)
	at org.apache.jasper.compiler.JDTJavaCompiler.getJavaWriter(JDTJavaCompiler.java:149)
	at org.apache.jasper.compiler.Compiler.generateJava(Compiler.java:188)
	at org.apache.jasper.compiler.Compiler.compile(Compiler.java:435)
	at org.apache.jasper.JspCompilationContext.compile(JspCompilationContext.java:608)
	at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:360)
	at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:486)
	at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:380)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:534)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:475)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:224)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:921)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:403)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:184)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:856)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:114)
	at org.eclipse.jetty.server.Server.handle(Server.java:348)
	at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.java:596)
	at org.eclipse.jetty.server.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:1052)
	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:590)
	at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:212)
	at org.eclipse.jetty.server.HttpConnection.handle(HttpConnection.java:426)
	at org.eclipse.jetty.server.nio.BlockingChannelConnector$BlockingChannelEndPoint.run(BlockingChannelConnector.java:292)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:450)
	at java.lang.Thread.run(Thread.java:619)



Fuseki - version 0.2.0 (Date: 2011-12-15T15:19:16-0800)

It looks like these temporary files are being generated by one of the components Fuseki relies upon rather than Fuseki itself but this is an issue for us because if one user has run Fuseki another user may be completely blocked from using the web based UI fully.

Interestingly servlets will still function correctly, e.g. I can still issue queries directly to /dataset/query and get a response but the lack of a control panel is inconvenient.

This may not be fixable due to it actually being caused by a component that Fuseki depends upon but I have no expertise in Jetty/JSP/Servlets so I don't know against what project this bug should actually be filed."
JENA-170,hexBinary whitespace issue,"As I understand, initial and final white spaces in xsd:hexBinary in xml should be ignored

   http://www.w3.org/TR/2001/REC-xmlschema-2-20010502/#hexBinary
 
because of the whitespace facet.

With Jena 2.6.4 this is not the case, as shown by the test below. 
I found that in Clerezza when using the graph api, so this is a problem even when one does not use SPARQL.
Removing the white space solves the proble. 

xsd:hexBinary is already a very fragile encoding. Making it this fragile is bound to lead to issues in communication.
The same is true with the N3 encoding.


-----------------------------------------------------------------
hjs@bblfish[0]$ cat q1.sparql 
PREFIX : <http://me.example/p#> 
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> 

SELECT ?S WHERE {
  ?S :related ""AAAA""^^xsd:hexBinary .
}


hjs@bblfish[0]$ cat c1.rdf 

<rdf:RDF xmlns=""http://me.example/p#""
    xmlns:rdf=""http://www.w3.org/1999/02/22-rdf-syntax-ns#"">

    <rdf:Description rdf:about=""http://me.example/p#me"">
        <related rdf:datatype=""http://www.w3.org/2001/XMLSchema#hexBinary"">
AAAA
</related>
    </rdf:Description>
</rdf:RDF>

hjs@bblfish[0]$ arq --query=q1.sparql --data=c1.rdf
-----
| S |
=====
-----
",Bug,"hexBinary whitespace issue As I understand, initial and final white spaces in xsd:hexBinary in xml should be ignored

   http://www.w3.org/TR/2001/REC-xmlschema-2-20010502/#hexBinary
 
because of the whitespace facet.

With Jena 2.6.4 this is not the case, as shown by the test below. 
I found that in Clerezza when using the graph api, so this is a problem even when one does not use SPARQL.
Removing the white space solves the proble. 

xsd:hexBinary is already a very fragile encoding. Making it this fragile is bound to lead to issues in communication.
The same is true with the N3 encoding.


-----------------------------------------------------------------
hjs@bblfish[0]$ cat q1.sparql 
PREFIX : <http://me.example/p#> 
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> 

SELECT ?S WHERE {
  ?S :related ""AAAA""^^xsd:hexBinary .
}


hjs@bblfish[0]$ cat c1.rdf 

<rdf:RDF xmlns=""http://me.example/p#""
    xmlns:rdf=""http://www.w3.org/1999/02/22-rdf-syntax-ns#"">

    <rdf:Description rdf:about=""http://me.example/p#me"">
        <related rdf:datatype=""http://www.w3.org/2001/XMLSchema#hexBinary"">
AAAA
</related>
    </rdf:Description>
</rdf:RDF>

hjs@bblfish[0]$ arq --query=q1.sparql --data=c1.rdf
-----
| S |
=====
-----
"
JENA-161,TDB Transaction deadlock,"While running some tests I ran into a deadlock. Unfortunately, on my 64 bit windows 7, I was unable to trigger the complete stack trace. (there is no equivalent of kill -3 and all known utilities to achieve this on windows don't work with a 64 bit process). I was able to see two of the threads which were hanging (because of a UI view in our admin console), but it is not showing the other threads (which I'd need to see why the 2 threads I do have are hanging). I will show the 2 threads which are hanging here in the hope it rings a bell. I hope I will be able to get a full set of stack traces at some point

as for an analysis: Not sure if we are dealing with a double-crossed locking issue here. It seems that thread 2 is waiting for thread 1 who clearly has the lock on the transaction manager, but it is not clear why it is waiting on the Transaction object. It seems that some other thread still has it and the question is whether thread 2 could be the one (so there is a crossing of the locks)? It would surprise me because thread 1 is doing a READ transaction and thread 2 is doing a separate WRITE transaction. 

thread 1:
------------
com.hp.hpl.jena.tdb.transaction.Transaction.signalEnacted(Transaction.java:178)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.enactTransaction(TransactionManager.java:384)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.processDelayedReplayQueue(TransactionManager.java:419)
   com.hp.hpl.jena.tdb.transaction.TransactionManager$TSM_WriteBackEndTxn.readerFinishes(TransactionManager.java:189)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.readerFinishes(TransactionManager.java:609)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.noteTxnCommit(TransactionManager.java:472)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.notifyCommit(TransactionManager.java:349)
   com.hp.hpl.jena.tdb.transaction.Transaction.commit(Transaction.java:100)
   com.hp.hpl.jena.tdb.transaction.Transaction.close(Transaction.java:151)
   com.hp.hpl.jena.tdb.DatasetGraphTxn.close(DatasetGraphTxn.java:55)
   com.ibm.team.jfs.rdf.internal.jena.tdb.JenaTdbTxProvider.storeOperation(JenaTdbTxProvider.java:179)
<snip>

thread 2
------------
com.hp.hpl.jena.tdb.transaction.TransactionManager.notifyClose(TransactionManager.java:445)
   com.hp.hpl.jena.tdb.transaction.Transaction.close(Transaction.java:162)
   com.hp.hpl.jena.tdb.DatasetGraphTxn.close(DatasetGraphTxn.java:55)
   com.ibm.team.jfs.rdf.internal.jena.tdb.JenaTdbTxProvider.storeOperation(JenaTdbTxProvider.java:285)
   com.ibm.team.jfs.rdf.internal.jena.tdb.JenaTdbTxProvider.unprotectedDelete(JenaTdbTxProvider.java:1902)
   com.ibm.team.jfs.rdf.internal.jena.tdb.JenaTdbTxProvider.delete(JenaTdbTxProvider.java:664)
<snip>
",Bug,"TDB Transaction deadlock While running some tests I ran into a deadlock. Unfortunately, on my 64 bit windows 7, I was unable to trigger the complete stack trace. (there is no equivalent of kill -3 and all known utilities to achieve this on windows don't work with a 64 bit process). I was able to see two of the threads which were hanging (because of a UI view in our admin console), but it is not showing the other threads (which I'd need to see why the 2 threads I do have are hanging). I will show the 2 threads which are hanging here in the hope it rings a bell. I hope I will be able to get a full set of stack traces at some point

as for an analysis: Not sure if we are dealing with a double-crossed locking issue here. It seems that thread 2 is waiting for thread 1 who clearly has the lock on the transaction manager, but it is not clear why it is waiting on the Transaction object. It seems that some other thread still has it and the question is whether thread 2 could be the one (so there is a crossing of the locks)? It would surprise me because thread 1 is doing a READ transaction and thread 2 is doing a separate WRITE transaction. 

thread 1:
------------
com.hp.hpl.jena.tdb.transaction.Transaction.signalEnacted(Transaction.java:178)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.enactTransaction(TransactionManager.java:384)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.processDelayedReplayQueue(TransactionManager.java:419)
   com.hp.hpl.jena.tdb.transaction.TransactionManager$TSM_WriteBackEndTxn.readerFinishes(TransactionManager.java:189)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.readerFinishes(TransactionManager.java:609)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.noteTxnCommit(TransactionManager.java:472)
   com.hp.hpl.jena.tdb.transaction.TransactionManager.notifyCommit(TransactionManager.java:349)
   com.hp.hpl.jena.tdb.transaction.Transaction.commit(Transaction.java:100)
   com.hp.hpl.jena.tdb.transaction.Transaction.close(Transaction.java:151)
   com.hp.hpl.jena.tdb.DatasetGraphTxn.close(DatasetGraphTxn.java:55)
   com.ibm.team.jfs.rdf.internal.jena.tdb.JenaTdbTxProvider.storeOperation(JenaTdbTxProvider.java:179)
<snip>

thread 2
------------
com.hp.hpl.jena.tdb.transaction.TransactionManager.notifyClose(TransactionManager.java:445)
   com.hp.hpl.jena.tdb.transaction.Transaction.close(Transaction.java:162)
   com.hp.hpl.jena.tdb.DatasetGraphTxn.close(DatasetGraphTxn.java:55)
   com.ibm.team.jfs.rdf.internal.jena.tdb.JenaTdbTxProvider.storeOperation(JenaTdbTxProvider.java:285)
   com.ibm.team.jfs.rdf.internal.jena.tdb.JenaTdbTxProvider.unprotectedDelete(JenaTdbTxProvider.java:1902)
   com.ibm.team.jfs.rdf.internal.jena.tdb.JenaTdbTxProvider.delete(JenaTdbTxProvider.java:664)
<snip>
"
JENA-153,xsd:integers larger than java.long.MAX_VALUE silently overflow in ARQ,"ARQ handles small xsd:integers fine, and it handles large xsd:integers fine, but there seems to be some weirdness going on with integers of ~20 digits:

ASK {FILTER (200000/2=100000)} => true
ASK {FILTER (20000000/2=10000000)} => true
ASK {FILTER (2000000000/2=1000000000)} => true
ASK {FILTER (200000000000/2=100000000000)} => true
ASK {FILTER (20000000000000/2=10000000000000)} => true
ASK {FILTER (2000000000000000/2=1000000000000000)} => true
ASK {FILTER (200000000000000000/2=100000000000000000)} => true
ASK {FILTER (20000000000000000000/2=10000000000000000000)} => ***false***
ASK {FILTER (2000000000000000000000/2=1000000000000000000000)} => true
ASK {FILTER (200000000000000000000000/2=100000000000000000000000)} => true
ASK {FILTER (20000000000000000000000000/2=10000000000000000000000000)} => true

These were all tested in http://sparql.org/sparql.html with an arbitrary target graph URI.

It works fine again if dividend and quotient are changed to xsd:decimal:

ASK {FILTER (20000000000000000000.0/2=10000000000000000000.0)} => true

I guess this may have something to do with Java's native long being used for xsd:integers of some size, and BigInteger for others?",Bug,"xsd:integers larger than java.long.MAX_VALUE silently overflow in ARQ ARQ handles small xsd:integers fine, and it handles large xsd:integers fine, but there seems to be some weirdness going on with integers of ~20 digits:

ASK {FILTER (200000/2=100000)} => true
ASK {FILTER (20000000/2=10000000)} => true
ASK {FILTER (2000000000/2=1000000000)} => true
ASK {FILTER (200000000000/2=100000000000)} => true
ASK {FILTER (20000000000000/2=10000000000000)} => true
ASK {FILTER (2000000000000000/2=1000000000000000)} => true
ASK {FILTER (200000000000000000/2=100000000000000000)} => true
ASK {FILTER (20000000000000000000/2=10000000000000000000)} => ***false***
ASK {FILTER (2000000000000000000000/2=1000000000000000000000)} => true
ASK {FILTER (200000000000000000000000/2=100000000000000000000000)} => true
ASK {FILTER (20000000000000000000000000/2=10000000000000000000000000)} => true

These were all tested in http://sparql.org/sparql.html with an arbitrary target graph URI.

It works fine again if dividend and quotient are changed to xsd:decimal:

ASK {FILTER (20000000000000000000.0/2=10000000000000000000.0)} => true

I guess this may have something to do with Java's native long being used for xsd:integers of some size, and BigInteger for others?"
JENA-151,Resolve Maven warnings due to use of deprecated feature,Maven outputs some warnings due to usage of deprecated <tasks> inside ant task specification. Should be <target>.,Bug,Resolve Maven warnings due to use of deprecated feature Maven outputs some warnings due to usage of deprecated <tasks> inside ant task specification. Should be <target>.
JENA-150,Junit test org.openjena.riot.TS_Riot fails,The test mentioned in the title of this issue fails on my machine. Seems to be a locale-specific issue.,Bug,Junit test org.openjena.riot.TS_Riot fails The test mentioned in the title of this issue fails on my machine. Seems to be a locale-specific issue.
JENA-148,xsd:anyURI is sameValueAs an xsd:string or simple literal,"In the memory model xsd:anyURI matches in Graph.find an xsd;string with the same lexical form.

""http://example/""^^xsd:anyURI matches ""http://example/""^^xsd:string and ""http://example/""

This is because the value returned by Xerces is a Java string and isEqual in XSDDatatype is based on equality of Xerces value regerdless of datatype to account for derived types.

The proposed solution in the patch is to have a new XSD datatype that uses the BaseDatatype isEquals machinery which makes equity ""same datatype, same value"".

Also applies to xsd:QName, xsd:IDREF, xsd:NOTATION
",Bug,"xsd:anyURI is sameValueAs an xsd:string or simple literal In the memory model xsd:anyURI matches in Graph.find an xsd;string with the same lexical form.

""http://example/""^^xsd:anyURI matches ""http://example/""^^xsd:string and ""http://example/""

This is because the value returned by Xerces is a Java string and isEqual in XSDDatatype is based on equality of Xerces value regerdless of datatype to account for derived types.

The proposed solution in the patch is to have a new XSD datatype that uses the BaseDatatype isEquals machinery which makes equity ""same datatype, same value"".

Also applies to xsd:QName, xsd:IDREF, xsd:NOTATION
"
JENA-147,SAX2Model errorhandler does not work correctly if you have a Turkish locale,"There is a small language bug in the JenaReader class when you run Jena on Turkish machine. In line 440, there is a call to toUpperCase() which incorrectly maps ""strict"" to ""STRYCT"" when executed on a Turkish machine. This leads to obviously problems which we observed when using SAX2Model. 

The fix is to use toUpperCase(Locale.ENGLISH) in this case because you know the keywords are English",Bug,"SAX2Model errorhandler does not work correctly if you have a Turkish locale There is a small language bug in the JenaReader class when you run Jena on Turkish machine. In line 440, there is a call to toUpperCase() which incorrectly maps ""strict"" to ""STRYCT"" when executed on a Turkish machine. This leads to obviously problems which we observed when using SAX2Model. 

The fix is to use toUpperCase(Locale.ENGLISH) in this case because you know the keywords are English"
JENA-143,QueryExecution.abort seems to corrupt TDB when interrupting transactional queries,"The interaction between queryExecution.abort() and TDB transactions seems to suffer from a problem. When I use it, it seems that the store corrupts again. Note that when the QueryCancellationException is thrown, I actively abort the DatasetGraphTxn object, but I am seeing 

14:59:20,580 [477961341@qtp-1709008349-8]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterFilterExpr/37159

and then shortly after:

15:00:34,691 [jazz.jfs.indexer.jfs_tests_default_consumer_name.triple] ERROR com.ibm.team.jfs                                    - Originating Exception:
com.hp.hpl.jena.tdb.base.file.FileException: ObjectFile.read(8072)[12980][12980]: Impossibly large object : 1936010863 bytes
	at com.hp.hpl.jena.tdb.base.objectfile.ObjectFileStorage.read(ObjectFileStorage.java:294)
	at com.hp.hpl.jena.tdb.base.objectfile.ObjectFileStorage$ObjectIterator.next(ObjectFileStorage.java:409)

This is the used coding pattern. The main thread just sets up the transaction, so, something like this:

	DatasetGraphTxn dsGraph = null;
		try {
			dsGraph = StoreConnection.make(this.location).begin(ReadWrite.READ);
			Dataset ds = dsGraph.toDataset();
			
			...

			QueryExecution qe = null;
			...
			try {
			results = qe.execSelect();
			...
			} finally {
				if (qe != null) {
					qe.close();
				}
			}

		} catch (QueryCancelledException e) {
			if (dsGraph != null) {
				dsGraph.abort();
			}
		}  finally {
			if (dsGraph != null) {
			 	dsGraph.close();
			}
		}


A parallel thread may decide that the given query needs to be cancelled, so it has access to the QueryExecution and may decide to call

this.queryExecution.abort(); 

",Bug,"QueryExecution.abort seems to corrupt TDB when interrupting transactional queries The interaction between queryExecution.abort() and TDB transactions seems to suffer from a problem. When I use it, it seems that the store corrupts again. Note that when the QueryCancellationException is thrown, I actively abort the DatasetGraphTxn object, but I am seeing 

14:59:20,580 [477961341@qtp-1709008349-8]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterFilterExpr/37159

and then shortly after:

15:00:34,691 [jazz.jfs.indexer.jfs_tests_default_consumer_name.triple] ERROR com.ibm.team.jfs                                    - Originating Exception:
com.hp.hpl.jena.tdb.base.file.FileException: ObjectFile.read(8072)[12980][12980]: Impossibly large object : 1936010863 bytes
	at com.hp.hpl.jena.tdb.base.objectfile.ObjectFileStorage.read(ObjectFileStorage.java:294)
	at com.hp.hpl.jena.tdb.base.objectfile.ObjectFileStorage$ObjectIterator.next(ObjectFileStorage.java:409)

This is the used coding pattern. The main thread just sets up the transaction, so, something like this:

	DatasetGraphTxn dsGraph = null;
		try {
			dsGraph = StoreConnection.make(this.location).begin(ReadWrite.READ);
			Dataset ds = dsGraph.toDataset();
			
			...

			QueryExecution qe = null;
			...
			try {
			results = qe.execSelect();
			...
			} finally {
				if (qe != null) {
					qe.close();
				}
			}

		} catch (QueryCancelledException e) {
			if (dsGraph != null) {
				dsGraph.abort();
			}
		}  finally {
			if (dsGraph != null) {
			 	dsGraph.close();
			}
		}


A parallel thread may decide that the given query needs to be cancelled, so it has access to the QueryExecution and may decide to call

this.queryExecution.abort(); 

"
JENA-142,Scope tracking of variables does not work for UNION.,"test case:

SELECT * {
    { ?s ?p ?o} 
    UNION 
   { BIND('default' AS ?s) }
}

related group forms also need checking:

{ { ?s ?p ?o} BIND('default' AS ?s) }
{ { ?s ?p ?o} { BIND('default' AS ?s) } }
",Bug,"Scope tracking of variables does not work for UNION. test case:

SELECT * {
    { ?s ?p ?o} 
    UNION 
   { BIND('default' AS ?s) }
}

related group forms also need checking:

{ { ?s ?p ?o} BIND('default' AS ?s) }
{ { ?s ?p ?o} { BIND('default' AS ?s) } }
"
JENA-131,TxTDB problem during concurrent execution,"In a massive concurrent test with many reads and writes, I am running into the problems shown below. I suspect the problem only occurs if a read and write are trying to operate on the same data at the same time, i.e. the transactions don't isolate enough. My test case is inside the framework. I currently have no test case for you to try, but I am hoping you can see something by inspecting the stack trace

ModelWriteActivity: 1579ms
17:46:27,183 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterConcat/55657
17:46:27,254 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterSingleton/55658
17:46:27,257 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterPeek/55659
17:46:27,261 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterTDB/55660
17:46:27,264 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterOptionalIndex/55661
17:46:27,335 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterOptionalIndex/55662
17:46:27,338 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterDefaulting/55803
17:46:27,395 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterDefaulting/55807
17:46:27,399 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterPeek/55808
17:46:27,403 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterTDB/55809
17:46:27,406 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterAssign/55810
17:46:27,410 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterSingleton/55811
17:46:27,490 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterPeek/55812
17:46:27,493 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterTDB/55813
17:46:27,497 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterOptionalIndex/55814
17:46:27,502 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterOptionalIndex/55815
17:46:27,507 [1948218399@qtp-533667791-14] ERROR com.ibm.team.jfs                                    - Originating Exception:
java.lang.IndexOutOfBoundsException: Index: 20, Size: 18
	at java.util.ArrayList.remove(ArrayList.java:552)
	at java.util.ArrayList.remove(ArrayList.java:572)
	at com.hp.hpl.jena.tdb.transaction.Transaction.removeIterator(Transaction.java:188)
	at com.hp.hpl.jena.tdb.transaction.BlockMgrJournal.endIterator(BlockMgrJournal.java:312)
	at com.hp.hpl.jena.tdb.transaction.BlockMgrJournal.endIterator(BlockMgrJournal.java:313)
	at com.hp.hpl.jena.tdb.base.block.BlockMgrWrapper.endIterator(BlockMgrWrapper.java:134)
	at com.hp.hpl.jena.tdb.base.recordbuffer.RecordRangeIterator.close(RecordRangeIterator.java:155)
	at com.hp.hpl.jena.tdb.base.recordbuffer.RecordRangeIterator.hasNext(RecordRangeIterator.java:112)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:274)
	at com.hp.hpl.jena.tdb.sys.DatasetControlMRSW$IteratorCheckNotConcurrent.hasNext(DatasetControlMRSW.java:119)
	at org.openjena.atlas.iterator.Iter$3.hasNext(Iter.java:164)
	at org.openjena.atlas.iterator.Iter$6.hasNext(Iter.java:359)
	at org.openjena.atlas.iterator.Iter$3.hasNext(Iter.java:164)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:274)
	at org.openjena.atlas.iterator.Iter$3.hasNext(Iter.java:164)
	at org.openjena.atlas.iterator.Iter.hasNext(Iter.java:742)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:58)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:274)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterPlainWrapper.hasNextBinding(QueryIterPlainWrapper.java:54)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.makeNextStage(QueryIterRepeatApply.java:106)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.makeNextStage(QueryIterRepeatApply.java:106)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.tdb.solver.OpExecutorTDB.optimizeExecuteQuads(OpExecutorTDB.java:215)
	at com.hp.hpl.jena.tdb.solver.OpExecutorTDB.execute(OpExecutorTDB.java:152)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.visit(ExecutionDispatch.java:63)
	at com.hp.hpl.jena.sparql.algebra.op.OpQuadPattern.visit(OpQuadPattern.java:97)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.exec(ExecutionDispatch.java:43)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.executeOp(OpExecutor.java:119)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.execute(OpExecutor.java:208)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.visit(ExecutionDispatch.java:105)
	at com.hp.hpl.jena.sparql.algebra.op.OpSequence.visit(OpSequence.java:73)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.exec(ExecutionDispatch.java:45)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.executeOp(OpExecutor.java:119)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.execute(OpExecutor.java:464)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.visit(ExecutionDispatch.java:246)
	at com.hp.hpl.jena.sparql.algebra.op.OpAssign.visit(OpAssign.java:116)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.exec(ExecutionDispatch.java:45)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.executeOp(OpExecutor.java:119)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.execute(OpExecutor.java:92)
	at com.hp.hpl.jena.sparql.engine.main.QC.execute(QC.java:52)
	at com.hp.hpl.jena.sparql.engine.main.iterator.QueryIterUnion.nextStage(QueryIterUnion.java:55)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.makeNextStage(QueryIterRepeatApply.java:113)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterConvert.hasNextBinding(QueryIterConvert.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterSlice.hasNextBinding(QueryIterSlice.java:76)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:40)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:40)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.ResultSetStream.hasNext(ResultSetStream.java:70)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execDescribe(QueryExecutionBase.java:278)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execDescribe(QueryExecutionBase.java:256)
        <snip>
DataSetReadActivity: 1249ms",Bug,"TxTDB problem during concurrent execution In a massive concurrent test with many reads and writes, I am running into the problems shown below. I suspect the problem only occurs if a read and write are trying to operate on the same data at the same time, i.e. the transactions don't isolate enough. My test case is inside the framework. I currently have no test case for you to try, but I am hoping you can see something by inspecting the stack trace

ModelWriteActivity: 1579ms
17:46:27,183 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterConcat/55657
17:46:27,254 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterSingleton/55658
17:46:27,257 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterPeek/55659
17:46:27,261 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterTDB/55660
17:46:27,264 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterOptionalIndex/55661
17:46:27,335 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterOptionalIndex/55662
17:46:27,338 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterDefaulting/55803
17:46:27,395 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterDefaulting/55807
17:46:27,399 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterPeek/55808
17:46:27,403 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterTDB/55809
17:46:27,406 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterAssign/55810
17:46:27,410 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterSingleton/55811
17:46:27,490 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterPeek/55812
17:46:27,493 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterTDB/55813
17:46:27,497 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterOptionalIndex/55814
17:46:27,502 [1948218399@qtp-533667791-14]  WARN hpl.jena.sparql.engine.iterator.QueryIteratorCheck  - Open iterator: QueryIterOptionalIndex/55815
17:46:27,507 [1948218399@qtp-533667791-14] ERROR com.ibm.team.jfs                                    - Originating Exception:
java.lang.IndexOutOfBoundsException: Index: 20, Size: 18
	at java.util.ArrayList.remove(ArrayList.java:552)
	at java.util.ArrayList.remove(ArrayList.java:572)
	at com.hp.hpl.jena.tdb.transaction.Transaction.removeIterator(Transaction.java:188)
	at com.hp.hpl.jena.tdb.transaction.BlockMgrJournal.endIterator(BlockMgrJournal.java:312)
	at com.hp.hpl.jena.tdb.transaction.BlockMgrJournal.endIterator(BlockMgrJournal.java:313)
	at com.hp.hpl.jena.tdb.base.block.BlockMgrWrapper.endIterator(BlockMgrWrapper.java:134)
	at com.hp.hpl.jena.tdb.base.recordbuffer.RecordRangeIterator.close(RecordRangeIterator.java:155)
	at com.hp.hpl.jena.tdb.base.recordbuffer.RecordRangeIterator.hasNext(RecordRangeIterator.java:112)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:274)
	at com.hp.hpl.jena.tdb.sys.DatasetControlMRSW$IteratorCheckNotConcurrent.hasNext(DatasetControlMRSW.java:119)
	at org.openjena.atlas.iterator.Iter$3.hasNext(Iter.java:164)
	at org.openjena.atlas.iterator.Iter$6.hasNext(Iter.java:359)
	at org.openjena.atlas.iterator.Iter$3.hasNext(Iter.java:164)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:274)
	at org.openjena.atlas.iterator.Iter$3.hasNext(Iter.java:164)
	at org.openjena.atlas.iterator.Iter.hasNext(Iter.java:742)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:58)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:274)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterPlainWrapper.hasNextBinding(QueryIterPlainWrapper.java:54)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.makeNextStage(QueryIterRepeatApply.java:106)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.makeNextStage(QueryIterRepeatApply.java:106)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.tdb.solver.OpExecutorTDB.optimizeExecuteQuads(OpExecutorTDB.java:215)
	at com.hp.hpl.jena.tdb.solver.OpExecutorTDB.execute(OpExecutorTDB.java:152)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.visit(ExecutionDispatch.java:63)
	at com.hp.hpl.jena.sparql.algebra.op.OpQuadPattern.visit(OpQuadPattern.java:97)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.exec(ExecutionDispatch.java:43)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.executeOp(OpExecutor.java:119)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.execute(OpExecutor.java:208)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.visit(ExecutionDispatch.java:105)
	at com.hp.hpl.jena.sparql.algebra.op.OpSequence.visit(OpSequence.java:73)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.exec(ExecutionDispatch.java:45)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.executeOp(OpExecutor.java:119)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.execute(OpExecutor.java:464)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.visit(ExecutionDispatch.java:246)
	at com.hp.hpl.jena.sparql.algebra.op.OpAssign.visit(OpAssign.java:116)
	at com.hp.hpl.jena.sparql.engine.main.ExecutionDispatch.exec(ExecutionDispatch.java:45)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.executeOp(OpExecutor.java:119)
	at com.hp.hpl.jena.sparql.engine.main.OpExecutor.execute(OpExecutor.java:92)
	at com.hp.hpl.jena.sparql.engine.main.QC.execute(QC.java:52)
	at com.hp.hpl.jena.sparql.engine.main.iterator.QueryIterUnion.nextStage(QueryIterUnion.java:55)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.makeNextStage(QueryIterRepeatApply.java:113)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterConvert.hasNextBinding(QueryIterConvert.java:65)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterSlice.hasNextBinding(QueryIterSlice.java:76)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:40)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:40)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:107)
	at com.hp.hpl.jena.sparql.engine.ResultSetStream.hasNext(ResultSetStream.java:70)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execDescribe(QueryExecutionBase.java:278)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execDescribe(QueryExecutionBase.java:256)
        <snip>
DataSetReadActivity: 1249ms"
JENA-129,RIOT not parsing UTF combining characters correctly,"Background on the issue can be found at the list archive:
http://mail-archives.apache.org/mod_mbox/incubator-jena-users/201110.mbox/%3C4E88320C.8040300@apache.org%3E

RIOT failed to parse the SPARQL 1.0 DAWG test: ""i18n/normalization-01.ttl"".

In offline email Andy also noted:

I see one oddity:

[[
==== DAWG-Final/i18n/normalization-02.ttl
WARN  [line: 7, col: 8 ] Bad IRI: <eXAMPLE://a/b/%63/%7bfoo%7d#xyz>
Code: 8/NON_INITIAL_DOT_SEGMENT in PATH: The path contains a segment
/../ not at the beginning of a relative reference, or it contains a /./
These should be removed.
]]

because the test is on the input, not the resultant form used for toString.",Bug,"RIOT not parsing UTF combining characters correctly Background on the issue can be found at the list archive:
http://mail-archives.apache.org/mod_mbox/incubator-jena-users/201110.mbox/%3C4E88320C.8040300@apache.org%3E

RIOT failed to parse the SPARQL 1.0 DAWG test: ""i18n/normalization-01.ttl"".

In offline email Andy also noted:

I see one oddity:

[[
==== DAWG-Final/i18n/normalization-02.ttl
WARN  [line: 7, col: 8 ] Bad IRI: <eXAMPLE://a/b/%63/%7bfoo%7d#xyz>
Code: 8/NON_INITIAL_DOT_SEGMENT in PATH: The path contains a segment
/../ not at the beginning of a relative reference, or it contains a /./
These should be removed.
]]

because the test is on the input, not the resultant form used for toString."
JENA-124,NodeFormatterNT is not escaping characters,"Original message from the mailing-list:

http://mail-archives.apache.org/mod_mbox/incubator-jena-dev/201109.mbox/%3CCAJWYrb2ZAtDSsswF5jsKG6dhvNeYH2TrrUQRGCt27XoQLyNBhw@mail.gmail.com%3E

Copied answer given by Andy:

> Looks like there is a bug in BindingOutputStream - it's not escaping the
> "" in the item being output.

So the operation is called ""writeEscaped"" in NodeFormatterNT ... except 
it doesn't do any escaping.  Doh!  This is a regression due to the 
better (in theory) node formatters.",Bug,"NodeFormatterNT is not escaping characters Original message from the mailing-list:

http://mail-archives.apache.org/mod_mbox/incubator-jena-dev/201109.mbox/%3CCAJWYrb2ZAtDSsswF5jsKG6dhvNeYH2TrrUQRGCt27XoQLyNBhw@mail.gmail.com%3E

Copied answer given by Andy:

> Looks like there is a bug in BindingOutputStream - it's not escaping the
> "" in the item being output.

So the operation is called ""writeEscaped"" in NodeFormatterNT ... except 
it doesn't do any escaping.  Doh!  This is a regression due to the 
better (in theory) node formatters."
JENA-120,Query objects with aggregators cannot be reused,"Query objects that contain aggregators (Group By) cannot be reused by different threads because the internal state is mutable.  Even reusing a query object in the same thread has problems, because it creates a new Aggregator object each time you execute the query.  Users may want to reuse Query objects to save having to reparse the query string.

I believe the solution is to copy the aggregators when compiling the query.  I've attached a patch that does that in the AlgebraGenerator.compileModifiers() method.

See the thread at [1] for more discussion.

[1] http://mail-archives.apache.org/mod_mbox/incubator-jena-users/201109.mbox/%3CB60ACA3A-DB31-4FEC-A72E-D81A5C2AB41A@knublauch.com%3E

",Bug,"Query objects with aggregators cannot be reused Query objects that contain aggregators (Group By) cannot be reused by different threads because the internal state is mutable.  Even reusing a query object in the same thread has problems, because it creates a new Aggregator object each time you execute the query.  Users may want to reuse Query objects to save having to reparse the query string.

I believe the solution is to copy the aggregators when compiling the query.  I've attached a patch that does that in the AlgebraGenerator.compileModifiers() method.

See the thread at [1] for more discussion.

[1] http://mail-archives.apache.org/mod_mbox/incubator-jena-users/201109.mbox/%3CB60ACA3A-DB31-4FEC-A72E-D81A5C2AB41A@knublauch.com%3E

"
JENA-116,DatasetGraphMap.getGraph() should call addGraph() instead of adding directly to graph collection,"The DatasetGraphMap class is useful for implementing a quad store as a collection of triplestores, but when you attempt to retrieve a graph that does not exist, a new one is created but bypasses the addGraph() method.

Parliament needs to register all new graphs in an internal table (so that it knows which directory and files on disk correspond to each graph).  It does this by overriding the addGraph() method.

I've attached a patch that fixes this issue and also removes the ""final"" modifier on the getGraph() method (not strictly necessary for our use case, but it seemed out of place since no other methods are final, and I can imagine implementations that may want to override that method).",Bug,"DatasetGraphMap.getGraph() should call addGraph() instead of adding directly to graph collection The DatasetGraphMap class is useful for implementing a quad store as a collection of triplestores, but when you attempt to retrieve a graph that does not exist, a new one is created but bypasses the addGraph() method.

Parliament needs to register all new graphs in an internal table (so that it knows which directory and files on disk correspond to each graph).  It does this by overriding the addGraph() method.

I've attached a patch that fixes this issue and also removes the ""final"" modifier on the getGraph() method (not strictly necessary for our use case, but it seemed out of place since no other methods are final, and I can imagine implementations that may want to override that method)."
JENA-115,TxTDB tests fail on Windows,"As reported by Simon here: http://markmail.org/message/o7eakyks55b3ylzr and by Dave here: http://markmail.org/message/oj3zbozlygkifs3i we have tests failing in the current TxTDB test suite.
Running the TxTDB test suite on Jenkins using Windows shows the problem as well: https://builds.apache.org/view/G-L/view/Jena/job/Jena_TxTDB/197/
",Bug,"TxTDB tests fail on Windows As reported by Simon here: http://markmail.org/message/o7eakyks55b3ylzr and by Dave here: http://markmail.org/message/oj3zbozlygkifs3i we have tests failing in the current TxTDB test suite.
Running the TxTDB test suite on Jenkins using Windows shows the problem as well: https://builds.apache.org/view/G-L/view/Jena/job/Jena_TxTDB/197/
"
JENA-113,Choice and content of web pages needs to reflect the Fuseki configuration file.,"I am using Fuseki with multiple datasets configured via config file.

One of these datasets define a service as:

<#service1>  rdf:type fuseki:Service ;
    fuseki:name              ""ds1"" ;
    fuseki:serviceQuery      ""sparql"" ;
    fuseki:dataset           <#dataset> ;
    .

However, the sparql.jsp page always redirects to ds1/query.
Quick workaround is: add fuseki:serviceQuery ""sparql""  to <#service1>.",Bug,"Choice and content of web pages needs to reflect the Fuseki configuration file. I am using Fuseki with multiple datasets configured via config file.

One of these datasets define a service as:

<#service1>  rdf:type fuseki:Service ;
    fuseki:name              ""ds1"" ;
    fuseki:serviceQuery      ""sparql"" ;
    fuseki:dataset           <#dataset> ;
    .

However, the sparql.jsp page always redirects to ds1/query.
Quick workaround is: add fuseki:serviceQuery ""sparql""  to <#service1>."
JENA-104,ReverseComparator fails on Integer.MIN_VALUE,"There is a subtle bug in ReverseComparator. If the forward comparator returned Integer.MIN_VALUE, so would the reverse comparator.  Using signed integer types, there are more negative numbers available than positive ones (range is -2^31 to 2^31-1 inclusive) and negating the minimum value is effectively a no-op.  We can avoid the problem by reversing the order of the arguments instead.

I've included a patch and tests.
",Bug,"ReverseComparator fails on Integer.MIN_VALUE There is a subtle bug in ReverseComparator. If the forward comparator returned Integer.MIN_VALUE, so would the reverse comparator.  Using signed integer types, there are more negative numbers available than positive ones (range is -2^31 to 2^31-1 inclusive) and negating the minimum value is effectively a no-op.  We can avoid the problem by reversing the order of the arguments instead.

I've included a patch and tests.
"
JENA-103,FmtUtils does not expand xsd prefix,"A call to FmtUtils#stringForNode(literalNode) with literalNode equals to Node.createLiteral(""9"", null, XSDDatatype.XSDint) returns ""9""^^xsd:int whereas ""9""^^http://www.w3.org/2001/XMLSchema#int is expected.

I have set the issue as minor because it is currently possible to solve the issue by using the new OutputLangUtils class which returns the right value. However this imply to write several lines to get the output as a String:

    StringWriter sw = new StringWriter();
    OutputLangUtils.output(sw, object, null);
    new String(sw.getBuffer());

Maybe, a solution would be to rewrite FmtUtils by using OutputLangUtils? Thus, FmtUtils will be useful to format Nodes as String and only OutputLangUtils has to be maintained.
",Bug,"FmtUtils does not expand xsd prefix A call to FmtUtils#stringForNode(literalNode) with literalNode equals to Node.createLiteral(""9"", null, XSDDatatype.XSDint) returns ""9""^^xsd:int whereas ""9""^^http://www.w3.org/2001/XMLSchema#int is expected.

I have set the issue as minor because it is currently possible to solve the issue by using the new OutputLangUtils class which returns the right value. However this imply to write several lines to get the output as a String:

    StringWriter sw = new StringWriter();
    OutputLangUtils.output(sw, object, null);
    new String(sw.getBuffer());

Maybe, a solution would be to rewrite FmtUtils by using OutputLangUtils? Thus, FmtUtils will be useful to format Nodes as String and only OutputLangUtils has to be maintained.
"
JENA-102,tdbloader creates stats.opt file in existing DB,running tdbloader to add new triples to an existing TDB database creates a new stats.opt file if one does not already exist (whether or not none.opt already exists in the DB directory).,Bug,tdbloader creates stats.opt file in existing DB running tdbloader to add new triples to an existing TDB database creates a new stats.opt file if one does not already exist (whether or not none.opt already exists in the DB directory).
JENA-100,QueryIteratorBase concurrency issues,"QueryIteratorBase appears to have some concurrency bugs relating to cancelling a query:

1) The cancel() and cancelAllowContinue() methods did not have large enough synchronized blocks (they also used ""this"" as the lock, which is not recommended)
2) The order of setting the cancellation flags and the notifying subclasses via the requestCancel() method was incorrect
3) The visibility and happens-before relationships were incorrect for the requestingCancel and abortIterator variables

The cancelAllowContinue() feature adds a lot of complexity in terms of visibility and ordering.  Unfortunately it is hard to write test cases for these types of concurrency issues, so the existing tests did not uncover the issues.",Bug,"QueryIteratorBase concurrency issues QueryIteratorBase appears to have some concurrency bugs relating to cancelling a query:

1) The cancel() and cancelAllowContinue() methods did not have large enough synchronized blocks (they also used ""this"" as the lock, which is not recommended)
2) The order of setting the cancellation flags and the notifying subclasses via the requestCancel() method was incorrect
3) The visibility and happens-before relationships were incorrect for the requestingCancel and abortIterator variables

The cancelAllowContinue() feature adds a lot of complexity in terms of visibility and ordering.  Unfortunately it is hard to write test cases for these types of concurrency issues, so the existing tests did not uncover the issues."
JENA-97,TDB 0.9.0 snapshot sometimes returns a SELECT binding twice,"Very sometimes (rare), it seems that a result set will repeat the first SELECT binding. E.g. 

SELECT ?a ?b ...

will bind ?a twice in the result set. It only happens quite rarely, but the same queries behave correctly in TDB 0.8.7.",Bug,"TDB 0.9.0 snapshot sometimes returns a SELECT binding twice Very sometimes (rare), it seems that a result set will repeat the first SELECT binding. E.g. 

SELECT ?a ?b ...

will bind ?a twice in the result set. It only happens quite rarely, but the same queries behave correctly in TDB 0.8.7."
JENA-96,transactional behavior not sound,"TDB-TX tx-tdb-0.9.0-20110809.130753-7 has transactionality issues. I am seeing the following stack trace:

com.hp.hpl.jena.tdb.transaction.TDBTransactionException: Transaction has already committed or aborted
	at com.hp.hpl.jena.tdb.transaction.Transaction.abort(Transaction.java:107)
	at com.hp.hpl.jena.tdb.DatasetGraphTxn.abort(DatasetGraphTxn.java:31)
	at com.ibm.team.jfs.rdf.internal.jenatdbtx.JenaTdbProvider.storeOperation(JenaTdbProvider.java:208)
	at com.ibm.team.jfs.rdf.internal.jenatdbtx.JenaTdbProvider.replace(JenaTdbProvider.java:2411)
	at com.ibm.team.jfs.rdf.internal.jenatdbtx.JenaRdfService.replace(JenaRdfService.java:265)
	... 14 more

 I use the following bit of code to execute writes:

	DatasetGraphTxn dsGraph = null;
		try {
			dsGraph = this.store.begin(ReadWrite.WRITE);
			Dataset ds = dsGraph.toDataset();
			Model m = ds.getNamedModel(graphName);
			E e = modelWriteActivity.run(m);
			dsGraph.commit();
			return e;
		} catch (Exception e) {
			if (dsGraph != null) {
				dsGraph.abort();
			}
			// TODO handle better
			throw new RuntimeException(e);
		} finally {
			if (dsGraph != null) {
				dsGraph.close();
			}
			//System.out.println(""ModelWriteActivity: "" + (System.currentTimeMillis() - t) + ""ms""); //$NON-NLS-1$ //$NON-NLS-2$
		}

The only thing I do in the ModelWriteActivity is 

	model.removeAll();
	model.add(graph);

As you can see, there is nothing in here which could have made it possible that the transaction has committed before. Moreover I only see this happening when I am executing massive concurrent reads/writes. Sequential operations do not expose this problem.
",Bug,"transactional behavior not sound TDB-TX tx-tdb-0.9.0-20110809.130753-7 has transactionality issues. I am seeing the following stack trace:

com.hp.hpl.jena.tdb.transaction.TDBTransactionException: Transaction has already committed or aborted
	at com.hp.hpl.jena.tdb.transaction.Transaction.abort(Transaction.java:107)
	at com.hp.hpl.jena.tdb.DatasetGraphTxn.abort(DatasetGraphTxn.java:31)
	at com.ibm.team.jfs.rdf.internal.jenatdbtx.JenaTdbProvider.storeOperation(JenaTdbProvider.java:208)
	at com.ibm.team.jfs.rdf.internal.jenatdbtx.JenaTdbProvider.replace(JenaTdbProvider.java:2411)
	at com.ibm.team.jfs.rdf.internal.jenatdbtx.JenaRdfService.replace(JenaRdfService.java:265)
	... 14 more

 I use the following bit of code to execute writes:

	DatasetGraphTxn dsGraph = null;
		try {
			dsGraph = this.store.begin(ReadWrite.WRITE);
			Dataset ds = dsGraph.toDataset();
			Model m = ds.getNamedModel(graphName);
			E e = modelWriteActivity.run(m);
			dsGraph.commit();
			return e;
		} catch (Exception e) {
			if (dsGraph != null) {
				dsGraph.abort();
			}
			// TODO handle better
			throw new RuntimeException(e);
		} finally {
			if (dsGraph != null) {
				dsGraph.close();
			}
			//System.out.println(""ModelWriteActivity: "" + (System.currentTimeMillis() - t) + ""ms""); //$NON-NLS-1$ //$NON-NLS-2$
		}

The only thing I do in the ModelWriteActivity is 

	model.removeAll();
	model.add(graph);

As you can see, there is nothing in here which could have made it possible that the transaction has committed before. Moreover I only see this happening when I am executing massive concurrent reads/writes. Sequential operations do not expose this problem.
"
JENA-95,journal.jrl is not released when expelling a alocation,"whenever I call StoreConnection.expel(location) it seems that something is holding on to journal.jrl in location

Caused by: 
java.io.IOException: Could not delete D:\jfsDev\working_dir\indices\4cb718ffab6047639c383cf9582633dc\jfs-rdfindex\journal.jrnl
	at java.lang.Throwable.<init>(Throwable.java:67)",Bug,"journal.jrl is not released when expelling a alocation whenever I call StoreConnection.expel(location) it seems that something is holding on to journal.jrl in location

Caused by: 
java.io.IOException: Could not delete D:\jfsDev\working_dir\indices\4cb718ffab6047639c383cf9582633dc\jfs-rdfindex\journal.jrnl
	at java.lang.Throwable.<init>(Throwable.java:67)"
JENA-92,BufferingWriter.close() does not flush buffer before closing,The BufferingWriter.close() function does not flush the byte buffer before closing the underlying stream.  This will cause any data left in the buffer to be lost.,Bug,BufferingWriter.close() does not flush buffer before closing The BufferingWriter.close() function does not flush the byte buffer before closing the underlying stream.  This will cause any data left in the buffer to be lost.
JENA-91,extremely large buffer is being created in ObjectFileStorage,"I tried to debug the OME and check why a bytebuffer is causing my native memory to explode in almost no time. It all seems to happen in this bit of code in com.hp.hpl.jena.tdb.base.objectfile.ObjectFileStorage (lines 243 onwards)

  // No - it's in the underlying file storage.
        lengthBuffer.clear() ;
        int x = file.read(lengthBuffer, loc) ;
        if ( x != 4 )
            throw new FileException(""ObjectFile.read(""+loc+"")[""+filesize+""][""+file.size()+""]: Failed to read the length : got ""+x+"" bytes"") ;
        int len = lengthBuffer.getInt(0) ;
        ByteBuffer bb = ByteBuffer.allocate(len) ;

My debugger shows that x==4. It also shows the lengthBuffer has the following content: [111, 110, 61, 95]. This amounts to the value of len=1869495647, which is rather a lot :-) Obviously, the next statement (ByteBuffer.allocate) causes the OME.
",Bug,"extremely large buffer is being created in ObjectFileStorage I tried to debug the OME and check why a bytebuffer is causing my native memory to explode in almost no time. It all seems to happen in this bit of code in com.hp.hpl.jena.tdb.base.objectfile.ObjectFileStorage (lines 243 onwards)

  // No - it's in the underlying file storage.
        lengthBuffer.clear() ;
        int x = file.read(lengthBuffer, loc) ;
        if ( x != 4 )
            throw new FileException(""ObjectFile.read(""+loc+"")[""+filesize+""][""+file.size()+""]: Failed to read the length : got ""+x+"" bytes"") ;
        int len = lengthBuffer.getInt(0) ;
        ByteBuffer bb = ByteBuffer.allocate(len) ;

My debugger shows that x==4. It also shows the lengthBuffer has the following content: [111, 110, 61, 95]. This amounts to the value of len=1869495647, which is rather a lot :-) Obviously, the next statement (ByteBuffer.allocate) causes the OME.
"
JENA-88,TSVInput does not cope with adjacent tabs,"TSVInput has special code to cope with one trailing tab but there can be several.

It does not cope with adjacent tabs internall in the input.

Solution is to use String.split( ,-1) which splits into multiple files for each match of the regex.",Bug,"TSVInput does not cope with adjacent tabs TSVInput has special code to cope with one trailing tab but there can be several.

It does not cope with adjacent tabs internall in the input.

Solution is to use String.split( ,-1) which splits into multiple files for each match of the regex."
JENA-87,SVN directories are included in Eclipse .classpath,"The .classpath files for ARQ, Jena, TDB, Fuseki (and probably the other Jena projects) do not exclude the .svn directories from the build classpath.  This causes a lot of the following warnings to be displayed:

    ""The resource is a duplicate of src/.svn/all-wcprops and was not copied to the output folder""

The fix is to replace this line [1] in the .classpath with [2] for each of the ""src"" classpath entries.  This issue might be masked if you are using an Eclipse SVN plugin.

[1] <classpathentry kind=""src"" path=""src""/>
[2] <classpathentry excluding=""**/.svn/"" kind=""src"" path=""src""/>

",Bug,"SVN directories are included in Eclipse .classpath The .classpath files for ARQ, Jena, TDB, Fuseki (and probably the other Jena projects) do not exclude the .svn directories from the build classpath.  This causes a lot of the following warnings to be displayed:

    ""The resource is a duplicate of src/.svn/all-wcprops and was not copied to the output folder""

The fix is to replace this line [1] in the .classpath with [2] for each of the ""src"" classpath entries.  This issue might be masked if you are using an Eclipse SVN plugin.

[1] <classpathentry kind=""src"" path=""src""/>
[2] <classpathentry excluding=""**/.svn/"" kind=""src"" path=""src""/>

"
JENA-86,NPE in BlockMgrCache in direct mode,"There seems to be a problem with the implementation of getWrite in BlockMgrCache. Whenever there is a write and read cache miss, the code does not actually delegate to the wrapped BlockMgr. In direct mode, this would have to be the file system. The resulting exception is 

java.lang.NullPointerException
	at com.hp.hpl.jena.tdb.base.page.PageBlockMgr.getWrite(PageBlockMgr.java:50)
	at com.hp.hpl.jena.tdb.index.bplustree.BPTreeNode.getMgrWrite(BPTreeNode.java:162)
	at com.hp.hpl.jena.tdb.index.bplustree.BPTreeNode.get(BPTreeNode.java:145)
	at com.hp.hpl.jena.tdb.index.bplustree.BPTreeNode.delete(BPTreeNode.java:227)
	at com.hp.hpl.jena.tdb.index.bplustree.BPlusTree.deleteAndReturnOld(BPlusTree.java:324)
	at com.hp.hpl.jena.tdb.index.bplustree.BPlusTree.delete(BPlusTree.java:318)
	at com.hp.hpl.jena.tdb.index.TupleIndexRecord.performDelete(TupleIndexRecord.java:55)
	at com.hp.hpl.jena.tdb.index.TupleIndexBase.delete(TupleIndexBase.java:61)
	at com.hp.hpl.jena.tdb.index.TupleTable.delete(TupleTable.java:108)
	at com.hp.hpl.jena.tdb.graph.BulkUpdateHandlerTDB.removeWorker(BulkUpdateHandlerTDB.java:136)
	at com.hp.hpl.jena.tdb.graph.BulkUpdateHandlerTDB.removeAll(BulkUpdateHandlerTDB.java:90)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.removeAll(ModelCom.java:315)

I think the fix is to change the following code in the getWrite method of BlockMgrCache (starting at line 158):

     // Did not find.
        cacheMisses++ ;
        log(""Miss/w: %d"", id) ;
        if ( writeCache != null )
            writeCache.put(id, blk) ;
        return blk ;

into 

     // Did not find.
        cacheMisses++ ;
        log(""Miss/w: %d"", id) ;
        blk = super.getWrite(id);
        if ( writeCache != null )
            writeCache.put(id, blk) ;
        return blk ;",Bug,"NPE in BlockMgrCache in direct mode There seems to be a problem with the implementation of getWrite in BlockMgrCache. Whenever there is a write and read cache miss, the code does not actually delegate to the wrapped BlockMgr. In direct mode, this would have to be the file system. The resulting exception is 

java.lang.NullPointerException
	at com.hp.hpl.jena.tdb.base.page.PageBlockMgr.getWrite(PageBlockMgr.java:50)
	at com.hp.hpl.jena.tdb.index.bplustree.BPTreeNode.getMgrWrite(BPTreeNode.java:162)
	at com.hp.hpl.jena.tdb.index.bplustree.BPTreeNode.get(BPTreeNode.java:145)
	at com.hp.hpl.jena.tdb.index.bplustree.BPTreeNode.delete(BPTreeNode.java:227)
	at com.hp.hpl.jena.tdb.index.bplustree.BPlusTree.deleteAndReturnOld(BPlusTree.java:324)
	at com.hp.hpl.jena.tdb.index.bplustree.BPlusTree.delete(BPlusTree.java:318)
	at com.hp.hpl.jena.tdb.index.TupleIndexRecord.performDelete(TupleIndexRecord.java:55)
	at com.hp.hpl.jena.tdb.index.TupleIndexBase.delete(TupleIndexBase.java:61)
	at com.hp.hpl.jena.tdb.index.TupleTable.delete(TupleTable.java:108)
	at com.hp.hpl.jena.tdb.graph.BulkUpdateHandlerTDB.removeWorker(BulkUpdateHandlerTDB.java:136)
	at com.hp.hpl.jena.tdb.graph.BulkUpdateHandlerTDB.removeAll(BulkUpdateHandlerTDB.java:90)
	at com.hp.hpl.jena.rdf.model.impl.ModelCom.removeAll(ModelCom.java:315)

I think the fix is to change the following code in the getWrite method of BlockMgrCache (starting at line 158):

     // Did not find.
        cacheMisses++ ;
        log(""Miss/w: %d"", id) ;
        if ( writeCache != null )
            writeCache.put(id, blk) ;
        return blk ;

into 

     // Did not find.
        cacheMisses++ ;
        log(""Miss/w: %d"", id) ;
        blk = super.getWrite(id);
        if ( writeCache != null )
            writeCache.put(id, blk) ;
        return blk ;"
JENA-82,Deleting reifications for one statement in TDB also deletes them for others with the same subject,"See git://github.com/bimargulies/jena-tdb-reification-delete-tc.git for a test case that is reasonably lean, though it could be a bit leaner.

It creates and reifies two statements, then tries to delete the reification for one (as prep for deleting the statement), but both disappear.

 * urn:jug:1a2b3c#rr1=>[urn:jug:global#per1,http://jug.basistech.com/2011/01/rex-entity#coOccurInSentence,urn:jug:global#per2]
 * urn:jug:2b3c4f#rr1=>[urn:jug:global#per2,http://jug.basistech.com/2011/01/rex-entity#hasSibling,urn:jug:global#per2]

 * then call removeReification on [urn:jug:global#per2,http://jug.basistech.com/2011/01/rex-entity#hasSibling,urn:jug:global#per2],
 *  and BOTH reifications are deleted.
 ",Bug,"Deleting reifications for one statement in TDB also deletes them for others with the same subject See git://github.com/bimargulies/jena-tdb-reification-delete-tc.git for a test case that is reasonably lean, though it could be a bit leaner.

It creates and reifies two statements, then tries to delete the reification for one (as prep for deleting the statement), but both disappear.

 * urn:jug:1a2b3c#rr1=>[urn:jug:global#per1,http://jug.basistech.com/2011/01/rex-entity#coOccurInSentence,urn:jug:global#per2]
 * urn:jug:2b3c4f#rr1=>[urn:jug:global#per2,http://jug.basistech.com/2011/01/rex-entity#hasSibling,urn:jug:global#per2]

 * then call removeReification on [urn:jug:global#per2,http://jug.basistech.com/2011/01/rex-entity#hasSibling,urn:jug:global#per2],
 *  and BOTH reifications are deleted.
 "
JENA-81,Partial failure to see prefixes in persistent storage,"PrefixMappingImpl only looks in its local data structures to service findMapping. findMapping is private.

But calls to get() are used to cache prefixes from persistent store so a findmMappign call before touching a prefix wil casuse findMapping not to find it.",Bug,"Partial failure to see prefixes in persistent storage PrefixMappingImpl only looks in its local data structures to service findMapping. findMapping is private.

But calls to get() are used to cache prefixes from persistent store so a findmMappign call before touching a prefix wil casuse findMapping not to find it."
JENA-79,Wrong query result when FILTERing an unbound variable,"Consider the graph:

{code}
@prefix ex: <http://example.com/ns#>.

ex:subject a ex:Class.
{code}

and the query

{code}
PREFIX ex: <http://example.com/ns#>
SELECT ?x WHERE {
  ?s a ?c
  OPTIONAL { ?s ex:property ?x }
  FILTER (?x = ex:v)
}
{code}

Executing the query on the graph should return no solutions (?x is unbound, so the filter evaluates to 'error'). But I get the result:

{code}
-----------------------------
| x                         |
=============================
| <http://example.com/ns#v> |
-----------------------------
{code}

When changing the query to filter on a literal (?x = ""string"") or (?x = 1), the query returns no results. ",Bug,"Wrong query result when FILTERing an unbound variable Consider the graph:

{code}
@prefix ex: <http://example.com/ns#>.

ex:subject a ex:Class.
{code}

and the query

{code}
PREFIX ex: <http://example.com/ns#>
SELECT ?x WHERE {
  ?s a ?c
  OPTIONAL { ?s ex:property ?x }
  FILTER (?x = ex:v)
}
{code}

Executing the query on the graph should return no solutions (?x is unbound, so the filter evaluates to 'error'). But I get the result:

{code}
-----------------------------
| x                         |
=============================
| <http://example.com/ns#v> |
-----------------------------
{code}

When changing the query to filter on a literal (?x = ""string"") or (?x = 1), the query returns no results. "
JENA-77,rdfs:member property function in ARQ does not look for concrete rdfs:member triples.,rdfs:member property function in ARQ does not look in the data for concrete rdfs:member triples.,Bug,rdfs:member property function in ARQ does not look for concrete rdfs:member triples. rdfs:member property function in ARQ does not look in the data for concrete rdfs:member triples.
JENA-73,Turtle and N3 writer ignores properties set after the write is created,"Example:

 RDFWriter w = model.getWriter(""TTL"");
 w.setProperty(""usePropertySymbols"", ""false"");
 w.write(model, fos, null);

still writes ""a"" 

useWellKnownPropertySymbols is set when writer created.",Bug,"Turtle and N3 writer ignores properties set after the write is created Example:

 RDFWriter w = model.getWriter(""TTL"");
 w.setProperty(""usePropertySymbols"", ""false"");
 w.write(model, fos, null);

still writes ""a"" 

useWellKnownPropertySymbols is set when writer created."
JENA-59,Couple bugs in Delta,"Transferred from http://sourceforge.net/tracker/?func=detail&aid=3284907&group_id=40417&atid=537167

re: com.hp.hpl.jena.graph.compose.Delta
- Delta remove() should not modify base graph.
- Delta.performAdd(t) and performDelete(t) should not fill up L and R with redundant statements because graphBaseSize() will return the wrong answer.

Here are fixed versions of these methods (sorry I don't have a patch file; I don't know which directory to checkout and checking out everything takes too long and I'm still waiting for Ctrl-C to finish)

@Override public void performAdd(Triple t) {
if (!base.contains(t))
L.add(t);
R.delete(t);
}
@Override public void performDelete(Triple t) {
L.delete(t);
if (base.contains(t))
R.add(t);
}

public class RemoveAppendsToDeletionsIterator extends TrackingTripleIterator {
public RemoveAppendsToDeletionsIterator(Iterator<Triple> it) { super(it); }
@Override
public void remove() {
if (null == current)
throw new IllegalStateException();
getDeletions().add(current);
current = null;
}
}
@Override
public ExtendedIterator<Triple> graphBaseFind(TripleMatch tm) {
return new RemoveAppendsToDeletionsIterator(base.find(tm)).filterDrop(ifIn(GraphUtil.findAll(R))).andThen(L.find(tm));
}",Bug,"Couple bugs in Delta Transferred from http://sourceforge.net/tracker/?func=detail&aid=3284907&group_id=40417&atid=537167

re: com.hp.hpl.jena.graph.compose.Delta
- Delta remove() should not modify base graph.
- Delta.performAdd(t) and performDelete(t) should not fill up L and R with redundant statements because graphBaseSize() will return the wrong answer.

Here are fixed versions of these methods (sorry I don't have a patch file; I don't know which directory to checkout and checking out everything takes too long and I'm still waiting for Ctrl-C to finish)

@Override public void performAdd(Triple t) {
if (!base.contains(t))
L.add(t);
R.delete(t);
}
@Override public void performDelete(Triple t) {
L.delete(t);
if (base.contains(t))
R.add(t);
}

public class RemoveAppendsToDeletionsIterator extends TrackingTripleIterator {
public RemoveAppendsToDeletionsIterator(Iterator<Triple> it) { super(it); }
@Override
public void remove() {
if (null == current)
throw new IllegalStateException();
getDeletions().add(current);
current = null;
}
}
@Override
public ExtendedIterator<Triple> graphBaseFind(TripleMatch tm) {
return new RemoveAppendsToDeletionsIterator(base.find(tm)).filterDrop(ifIn(GraphUtil.findAll(R))).andThen(L.find(tm));
}"
JENA-55,"Turtle writer / lists where a list element is a URI, not a blank node.","The Turtle writer seems to process lists where the cons-cell node has a URI the same way as if it is a blank node.
",Bug,"Turtle writer / lists where a list element is a URI, not a blank node. The Turtle writer seems to process lists where the cons-cell node has a URI the same way as if it is a blank node.
"
JENA-54,TDB dynamic datasets causes property paths not to work.,"TDB dynamic datasets causes property paths not to work.  They do work with union default graph.

Appears to be that the combination of quad rewrite, dynamic datasets and property paths menas the evaluation is not across the dynamic default graph.
",Bug,"TDB dynamic datasets causes property paths not to work. TDB dynamic datasets causes property paths not to work.  They do work with union default graph.

Appears to be that the combination of quad rewrite, dynamic datasets and property paths menas the evaluation is not across the dynamic default graph.
"
JENA-53,"Turtle writer can write data using the N3 "":-"" syntax","
--------
@prefix : <http://example/> .
@prefix rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#>  .

:x1 :p _:b .
:x2 :p _:b .

_:b rdf:first 1 ;
    rdf:rest rdf:nil .
",Bug,"Turtle writer can write data using the N3 "":-"" syntax 
--------
@prefix : <http://example/> .
@prefix rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#>  .

:x1 :p _:b .
:x2 :p _:b .

_:b rdf:first 1 ;
    rdf:rest rdf:nil .
"
JENA-52,GROUP_CONCAT DISTINCT on unbound variable causes NPE,"Data:

{code}
@prefix ex: <http://example.com/ns#> .
ex:a ex:p1 ""1"" .
ex:b ex:p1 ""2"" ; ex:p2 ""3"" .
{code}

Query:

{code}
prefix ex: <http://example.com/ns#>
select ?s (group_concat(distinct ?p2) as ?concat) 
{ ?s ex:p1 ?p1 optional { ?s ex:p2 ?p2 } }
group by ?s
{code}

Result:

{noformat}
java.lang.NullPointerException
	at com.hp.hpl.jena.sparql.expr.aggregate.AggGroupConcatDistinct$AccGroupConcatDistinct.getValue(AggGroupConcatDistinct.java:124)
	at com.hp.hpl.jena.sparql.expr.aggregate.AggregatorBase.getValue(AggregatorBase.java:62)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterGroup$1.initializeIterator(QueryIterGroup.java:147)
	at org.openjena.atlas.iterator.IteratorDelayedInitialization.init(IteratorDelayedInitialization.java:25)
{noformat}
",Bug,"GROUP_CONCAT DISTINCT on unbound variable causes NPE Data:

{code}
@prefix ex: <http://example.com/ns#> .
ex:a ex:p1 ""1"" .
ex:b ex:p1 ""2"" ; ex:p2 ""3"" .
{code}

Query:

{code}
prefix ex: <http://example.com/ns#>
select ?s (group_concat(distinct ?p2) as ?concat) 
{ ?s ex:p1 ?p1 optional { ?s ex:p2 ?p2 } }
group by ?s
{code}

Result:

{noformat}
java.lang.NullPointerException
	at com.hp.hpl.jena.sparql.expr.aggregate.AggGroupConcatDistinct$AccGroupConcatDistinct.getValue(AggGroupConcatDistinct.java:124)
	at com.hp.hpl.jena.sparql.expr.aggregate.AggregatorBase.getValue(AggregatorBase.java:62)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterGroup$1.initializeIterator(QueryIterGroup.java:147)
	at org.openjena.atlas.iterator.IteratorDelayedInitialization.init(IteratorDelayedInitialization.java:25)
{noformat}
"
JENA-51,Turtle parser misses prefix declarations,"Jena's Turtle parser doesn't capture @prefix declarations in the prefix mapping. Any triples are parsed correctly, but model.getNsPrefixMap() and friends show an empty prefix mapping.

The N3 parser handles this correctly.

====== example code below =======

import com.hp.hpl.jena.rdf.model.*;

public class Test {
	public static void main(String[] args) {
		String s =
			""@prefix ex1: <http://example.com/1#>.\n"" +
			""@prefix ex2: <http://example.com/2#>.\n"" +
			""ex1:A a ex1:B ."";
		
		Model n3 = ModelFactory.createDefaultModel();
		System.out.println(""Parsing with N3 parser and printing prefixes:"");
		n3.read(new java.io.ByteArrayInputStream(s.getBytes()), null, ""N3"");
		System.out.println(n3.getNsPrefixMap());

		Model turtle = ModelFactory.createDefaultModel();
		System.out.println(""Parsing with Turtle parser and printing prefixes:"");
		turtle.read(new java.io.ByteArrayInputStream(s.getBytes()), null, ""TURTLE"");
		System.out.println(turtle.getNsPrefixMap());
	}
}


===== output ======

Parsing with N3 parser:
{ex2=http://example.com/2#, ex1=http://example.com/1#}
Parsing with Turtle parser:
{}
",Bug,"Turtle parser misses prefix declarations Jena's Turtle parser doesn't capture @prefix declarations in the prefix mapping. Any triples are parsed correctly, but model.getNsPrefixMap() and friends show an empty prefix mapping.

The N3 parser handles this correctly.

====== example code below =======

import com.hp.hpl.jena.rdf.model.*;

public class Test {
	public static void main(String[] args) {
		String s =
			""@prefix ex1: <http://example.com/1#>.\n"" +
			""@prefix ex2: <http://example.com/2#>.\n"" +
			""ex1:A a ex1:B ."";
		
		Model n3 = ModelFactory.createDefaultModel();
		System.out.println(""Parsing with N3 parser and printing prefixes:"");
		n3.read(new java.io.ByteArrayInputStream(s.getBytes()), null, ""N3"");
		System.out.println(n3.getNsPrefixMap());

		Model turtle = ModelFactory.createDefaultModel();
		System.out.println(""Parsing with Turtle parser and printing prefixes:"");
		turtle.read(new java.io.ByteArrayInputStream(s.getBytes()), null, ""TURTLE"");
		System.out.println(turtle.getNsPrefixMap());
	}
}


===== output ======

Parsing with N3 parser:
{ex2=http://example.com/2#, ex1=http://example.com/1#}
Parsing with Turtle parser:
{}
"
JENA-42,System.err output when calling IRIResolver.createNoResolve(),"I believe the changes associated with the JENA-37 fix (svn revision 8485) have introduced a bug in IRIResolver.createNoResolve().

I now get the following System.err output when I run the org.openjena.riot.TestLangNQuads unit test.  The test completes successfully.  I'm guessing it has something to do with the double ""file://"".

Here is the output of ""mvn -Dtest=TestLangNQuads test"":

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.openjena.riot.lang.TestLangNQuads
Unexpected IRIException in initializer: <file://file:///D:/develop/Jena/ARQ/trunk/> Code: 12/PORT_SHOULD_NOT_BE_EMPTY in PORT: The colon introducing an empty port component should be omitted entirely, or a port number should be specified.
com.hp.hpl.jena.iri.impl.IRIImplException: <file://file:///D:/develop/Jena/ARQ/trunk/> Code: 12/PORT_SHOULD_NOT_BE_EMPTY in PORT: The colon introducing an empty port component should be omitted entirely, or a port number should be specified.
        at com.hp.hpl.jena.iri.impl.AbsIRIFactoryImpl.throwAnyErrors(AbsIRIFactoryImpl.java:49)
        at com.hp.hpl.jena.iri.impl.AbsIRIFactoryImpl.construct(AbsIRIFactoryImpl.java:33)
        at org.openjena.riot.system.IRIResolver.<clinit>(IRIResolver.java:107)
        at org.openjena.riot.system.RiotLib.profile(RiotLib.java:75)
        at org.openjena.riot.system.RiotLib.profile(RiotLib.java:65)
        at org.openjena.riot.system.RiotLib.<clinit>(RiotLib.java:23)
        at org.openjena.riot.RiotReader.createParserNQuads(RiotReader.java:251)
        at org.openjena.riot.lang.TestLangNQuads.parse(TestLangNQuads.java:87)
        at org.openjena.riot.lang.TestLangNQuads.parseCount(TestLangNQuads.java:71)
        at org.openjena.riot.lang.TestLangNQuads.quad_1(TestLangNQuads.java:34)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:73)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:46)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:180)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:41)
        at org.junit.runners.ParentRunner$1.evaluate(ParentRunner.java:173)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
        at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:35)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:146)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:97)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.maven.surefire.booter.ProviderFactory$ClassLoaderProxy.invoke(ProviderFactory.java:103)
        at $Proxy0.invoke(Unknown Source)
        at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:145)
        at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcess(SurefireStarter.java:87)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:69)
",Bug,"System.err output when calling IRIResolver.createNoResolve() I believe the changes associated with the JENA-37 fix (svn revision 8485) have introduced a bug in IRIResolver.createNoResolve().

I now get the following System.err output when I run the org.openjena.riot.TestLangNQuads unit test.  The test completes successfully.  I'm guessing it has something to do with the double ""file://"".

Here is the output of ""mvn -Dtest=TestLangNQuads test"":

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.openjena.riot.lang.TestLangNQuads
Unexpected IRIException in initializer: <file://file:///D:/develop/Jena/ARQ/trunk/> Code: 12/PORT_SHOULD_NOT_BE_EMPTY in PORT: The colon introducing an empty port component should be omitted entirely, or a port number should be specified.
com.hp.hpl.jena.iri.impl.IRIImplException: <file://file:///D:/develop/Jena/ARQ/trunk/> Code: 12/PORT_SHOULD_NOT_BE_EMPTY in PORT: The colon introducing an empty port component should be omitted entirely, or a port number should be specified.
        at com.hp.hpl.jena.iri.impl.AbsIRIFactoryImpl.throwAnyErrors(AbsIRIFactoryImpl.java:49)
        at com.hp.hpl.jena.iri.impl.AbsIRIFactoryImpl.construct(AbsIRIFactoryImpl.java:33)
        at org.openjena.riot.system.IRIResolver.<clinit>(IRIResolver.java:107)
        at org.openjena.riot.system.RiotLib.profile(RiotLib.java:75)
        at org.openjena.riot.system.RiotLib.profile(RiotLib.java:65)
        at org.openjena.riot.system.RiotLib.<clinit>(RiotLib.java:23)
        at org.openjena.riot.RiotReader.createParserNQuads(RiotReader.java:251)
        at org.openjena.riot.lang.TestLangNQuads.parse(TestLangNQuads.java:87)
        at org.openjena.riot.lang.TestLangNQuads.parseCount(TestLangNQuads.java:71)
        at org.openjena.riot.lang.TestLangNQuads.quad_1(TestLangNQuads.java:34)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:73)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:46)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:180)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:41)
        at org.junit.runners.ParentRunner$1.evaluate(ParentRunner.java:173)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
        at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:35)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:146)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:97)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.maven.surefire.booter.ProviderFactory$ClassLoaderProxy.invoke(ProviderFactory.java:103)
        at $Proxy0.invoke(Unknown Source)
        at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:145)
        at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcess(SurefireStarter.java:87)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:69)
"
JENA-40,Query that runs more or less forever,"Using the data set you have from me, the following query, which looks very much like a series of other queries that run quite rapidly, shows no sign of finishing.
",Bug,"Query that runs more or less forever Using the data set you have from me, the following query, which looks very much like a series of other queries that run quite rapidly, shows no sign of finishing.
"
JENA-39,Current modification exception with current TDB snapshot,"I am running with a snapshot current as of 2 Feb 2011.

Caused by: java.util.ConcurrentModificationException: Iterator: started at 266529, now 266530
	at com.hp.hpl.jena.tdb.sys.ConcurrencyPolicyMRSW.policyError(ConcurrencyPolicyMRSW.java:127)
	at com.hp.hpl.jena.tdb.sys.ConcurrencyPolicyMRSW.access$000(ConcurrencyPolicyMRSW.java:18)
	at com.hp.hpl.jena.tdb.sys.ConcurrencyPolicyMRSW$IteratorCheckNotConcurrent.checkCourrentModification(ConcurrencyPolicyMRSW.java:90)
	at com.hp.hpl.jena.tdb.sys.ConcurrencyPolicyMRSW$IteratorCheckNotConcurrent.hasNext(ConcurrencyPolicyMRSW.java:97)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:262)
	at org.openjena.atlas.iterator.Iter$3.hasNext(Iter.java:152)
	at org.openjena.atlas.iterator.Iter.hasNext(Iter.java:596)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:262)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterPlainWrapper.hasNextBinding(QueryIterPlainWrapper.java:42)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:48)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterConcat.hasNextBinding(QueryIterConcat.java:70)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:57)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:48)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterDefaulting.hasNextBinding(QueryIterDefaulting.java:43)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:57)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:28)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:28)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execConstruct(QueryExecutionBase.java:117)
	at com.basistech.jug.rdfdb.jena.JenaStore.executeConstructQuery(JenaStore.java:127)
	at com.basistech.jug.rdfdb.jena.QueryManager.runConstructQuery(QueryManager.java:59)
	at com.basistech.jug.rdfdb.service.query.QueryService.constructQuery(QueryService.java:166)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.cxf.service.invoker.AbstractInvoker.performInvocation(AbstractInvoker.java:173)
	at org.apache.cxf.service.invoker.AbstractInvoker.invoke(AbstractInvoker.java:89)
	... 29 more

",Bug,"Current modification exception with current TDB snapshot I am running with a snapshot current as of 2 Feb 2011.

Caused by: java.util.ConcurrentModificationException: Iterator: started at 266529, now 266530
	at com.hp.hpl.jena.tdb.sys.ConcurrencyPolicyMRSW.policyError(ConcurrencyPolicyMRSW.java:127)
	at com.hp.hpl.jena.tdb.sys.ConcurrencyPolicyMRSW.access$000(ConcurrencyPolicyMRSW.java:18)
	at com.hp.hpl.jena.tdb.sys.ConcurrencyPolicyMRSW$IteratorCheckNotConcurrent.checkCourrentModification(ConcurrencyPolicyMRSW.java:90)
	at com.hp.hpl.jena.tdb.sys.ConcurrencyPolicyMRSW$IteratorCheckNotConcurrent.hasNext(ConcurrencyPolicyMRSW.java:97)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:262)
	at org.openjena.atlas.iterator.Iter$3.hasNext(Iter.java:152)
	at org.openjena.atlas.iterator.Iter.hasNext(Iter.java:596)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:46)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:262)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterPlainWrapper.hasNextBinding(QueryIterPlainWrapper.java:42)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:48)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterConcat.hasNextBinding(QueryIterConcat.java:70)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:57)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:48)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterDefaulting.hasNextBinding(QueryIterDefaulting.java:43)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:57)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:28)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:28)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execConstruct(QueryExecutionBase.java:117)
	at com.basistech.jug.rdfdb.jena.JenaStore.executeConstructQuery(JenaStore.java:127)
	at com.basistech.jug.rdfdb.jena.QueryManager.runConstructQuery(QueryManager.java:59)
	at com.basistech.jug.rdfdb.service.query.QueryService.constructQuery(QueryService.java:166)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.cxf.service.invoker.AbstractInvoker.performInvocation(AbstractInvoker.java:173)
	at org.apache.cxf.service.invoker.AbstractInvoker.invoke(AbstractInvoker.java:89)
	... 29 more

"
JENA-35,NPE on a particular SPARQL query,"nquads to demo this can be found on people.apache.org:~bimargulies, 1k_news.nq.gz

tdbquery --loc=1k_news.tdb --query=aq0.ru


First, the backtrace:

{noformat}

/Users/benson/data tdbquery --loc=1k_news.tdb --query=aq0.ru
Exception
java.lang.NullPointerException
	at com.hp.hpl.jena.sparql.serializer.FmtExpr$FmtExprARQVisitor.visit(FmtExpr.java:126)
	at com.hp.hpl.jena.sparql.expr.ExprFunctionN.visit(ExprFunctionN.java:109)
	at com.hp.hpl.jena.sparql.serializer.FmtExpr.format(FmtExpr.java:37)
	at com.hp.hpl.jena.sparql.util.ExprUtils.fmtSPARQL(ExprUtils.java:141)
	at com.hp.hpl.jena.sparql.util.ExprUtils.fmtSPARQL(ExprUtils.java:146)
	at com.hp.hpl.jena.sparql.util.ExprUtils.fmtSPARQL(ExprUtils.java:152)
	at com.hp.hpl.jena.sparql.expr.ExprNode.toString(ExprNode.java:94)
	at java.lang.String.valueOf(String.java:2826)
	at java.lang.StringBuilder.append(StringBuilder.java:115)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterFilterExpr.accept(QueryIterFilterExpr.java:47)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:52)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:260)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:260)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterPlainWrapper.hasNextBinding(QueryIterPlainWrapper.java:42)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:48)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:260)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:260)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterPlainWrapper.hasNextBinding(QueryIterPlainWrapper.java:42)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterDefaulting.hasNextBinding(QueryIterDefaulting.java:43)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:57)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.makeNextStage(QueryIterRepeatApply.java:84)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:52)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:28)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:28)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execConstruct(QueryExecutionBase.java:117)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execConstruct(QueryExecutionBase.java:100)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.doConstructQuery(QueryExecUtils.java:186)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.executeQuery(QueryExecUtils.java:58)
	at arq.query.queryExec(query.java:124)
	at arq.query.exec(query.java:91)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:85)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:47)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:34)
	at tdb.tdbquery.main(tdbquery.java:22)
{noformat}
",Bug,"NPE on a particular SPARQL query nquads to demo this can be found on people.apache.org:~bimargulies, 1k_news.nq.gz

tdbquery --loc=1k_news.tdb --query=aq0.ru


First, the backtrace:

{noformat}

/Users/benson/data tdbquery --loc=1k_news.tdb --query=aq0.ru
Exception
java.lang.NullPointerException
	at com.hp.hpl.jena.sparql.serializer.FmtExpr$FmtExprARQVisitor.visit(FmtExpr.java:126)
	at com.hp.hpl.jena.sparql.expr.ExprFunctionN.visit(ExprFunctionN.java:109)
	at com.hp.hpl.jena.sparql.serializer.FmtExpr.format(FmtExpr.java:37)
	at com.hp.hpl.jena.sparql.util.ExprUtils.fmtSPARQL(ExprUtils.java:141)
	at com.hp.hpl.jena.sparql.util.ExprUtils.fmtSPARQL(ExprUtils.java:146)
	at com.hp.hpl.jena.sparql.util.ExprUtils.fmtSPARQL(ExprUtils.java:152)
	at com.hp.hpl.jena.sparql.expr.ExprNode.toString(ExprNode.java:94)
	at java.lang.String.valueOf(String.java:2826)
	at java.lang.StringBuilder.append(StringBuilder.java:115)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterFilterExpr.accept(QueryIterFilterExpr.java:47)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:52)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:260)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:260)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterPlainWrapper.hasNextBinding(QueryIterPlainWrapper.java:42)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterProcessBinding.hasNextBinding(QueryIterProcessBinding.java:48)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:260)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.RepeatApplyIterator.hasNext(RepeatApplyIterator.java:34)
	at org.openjena.atlas.iterator.Iter$4.hasNext(Iter.java:260)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterPlainWrapper.hasNextBinding(QueryIterPlainWrapper.java:42)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterDefaulting.hasNextBinding(QueryIterDefaulting.java:43)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:57)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.makeNextStage(QueryIterRepeatApply.java:84)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIterRepeatApply.hasNextBinding(QueryIterRepeatApply.java:52)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:28)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorWrapper.hasNextBinding(QueryIteratorWrapper.java:28)
	at com.hp.hpl.jena.sparql.engine.iterator.QueryIteratorBase.hasNext(QueryIteratorBase.java:66)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execConstruct(QueryExecutionBase.java:117)
	at com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execConstruct(QueryExecutionBase.java:100)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.doConstructQuery(QueryExecUtils.java:186)
	at com.hp.hpl.jena.sparql.util.QueryExecUtils.executeQuery(QueryExecUtils.java:58)
	at arq.query.queryExec(query.java:124)
	at arq.query.exec(query.java:91)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:85)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:47)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:34)
	at tdb.tdbquery.main(tdbquery.java:22)
{noformat}
"
JENA-34,missing prefix in example doc for assembly,"http://openjena.org/wiki/TDB/Assembler

The first example is missing the 'rdfs' prefix.
",Bug,"missing prefix in example doc for assembly http://openjena.org/wiki/TDB/Assembler

The first example is missing the 'rdfs' prefix.
"
JENA-32,"DatasetGraphBase.deleteAny(null, ,,) cause NPE","See http://mail-archives.apache.org/mod_mbox/incubator-jena-users/201101.mbox/%3C4D3AEA32.9010406@mysema.com%3E

Node.ANY is also broken.

DatasetGraph is a DatasetGraphCollection

dataSource.asDatasetGraph().add(new Quad(Quad.defaultGraphIRI, subject, predicate, object));
dataSource.asDatasetGraph().deleteAny(Node.ANY, subject, null, null);

DatasetGraphBase.deleteAny ==> 
   find(g, s, p, o) ;
   => g = null for the default graph (aside ?? should be Quad.defaultGraphIRI)
   =>delete attempts to get graph null.

1/ delete(quad) in DatasetGraphCollection => fetchGraph with a null
2/ Think about the find/4 => null vs URI for dft graph.

",Bug,"DatasetGraphBase.deleteAny(null, ,,) cause NPE See http://mail-archives.apache.org/mod_mbox/incubator-jena-users/201101.mbox/%3C4D3AEA32.9010406@mysema.com%3E

Node.ANY is also broken.

DatasetGraph is a DatasetGraphCollection

dataSource.asDatasetGraph().add(new Quad(Quad.defaultGraphIRI, subject, predicate, object));
dataSource.asDatasetGraph().deleteAny(Node.ANY, subject, null, null);

DatasetGraphBase.deleteAny ==> 
   find(g, s, p, o) ;
   => g = null for the default graph (aside ?? should be Quad.defaultGraphIRI)
   =>delete attempts to get graph null.

1/ delete(quad) in DatasetGraphCollection => fetchGraph with a null
2/ Think about the find/4 => null vs URI for dft graph.

"
JENA-27,NullPointerException at com.hp.hpl.jena.sdb.compiler.SDB_QC.exec (PATCH),"Unable to execute SPARQL queries with SDB. OpSQL's bridge is null in at least some cases. Patch works, but seems odd as the code seems to indicate that a op3 (3rd pass?) shouldn't need a bridge any more? 

java.lang.NullPointerException
        at com.hp.hpl.jena.sdb.compiler.SDB_QC.exec(SDB_QC.java:65)
        at com.hp.hpl.jena.sdb.compiler.OpSQL.exec(OpSQL.java:53)
        at com.hp.hpl.jena.sdb.engine.QueryEngineSDB.eval(QueryEngineSDB.java:117)
        at 
com.hp.hpl.jena.sparql.engine.QueryEngineBase.evaluate(QueryEngineBase.java:138)
        at 
com.hp.hpl.jena.sparql.engine.QueryEngineBase.createPlan(QueryEngineBase.java:109)
        at 
com.hp.hpl.jena.sparql.engine.QueryEngineBase.getPlan(QueryEngineBase.java:97)
        at 
com.hp.hpl.jena.sdb.engine.QueryEngineSDB$QueryEngineFactorySDB.create(QueryEngineSDB.java:142)
        at 
com.hp.hpl.jena.sparql.engine.QueryExecutionBase.getPlan(QueryExecutionBase.java:266)
        at 
com.hp.hpl.jena.sparql.engine.QueryExecutionBase.startQueryIterator(QueryExecutionBase.java:243)
        at 
com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execResultSet(QueryExecutionBase.java:248)
        at 
com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execSelect(QueryExecutionBase.java:94)
        at com.oreilly.rdf.tenuki.SDBBugTest.testForSDBBug(SDBBugTest.java:47)

Test Case:
https://github.com/norcalrdf/Tenuki/blob/0.4-bugfixes/src/test/java/com/oreilly/rdf/tenuki/SDBBugTest.java

Patch:
https://gist.github.com/675719",Bug,"NullPointerException at com.hp.hpl.jena.sdb.compiler.SDB_QC.exec (PATCH) Unable to execute SPARQL queries with SDB. OpSQL's bridge is null in at least some cases. Patch works, but seems odd as the code seems to indicate that a op3 (3rd pass?) shouldn't need a bridge any more? 

java.lang.NullPointerException
        at com.hp.hpl.jena.sdb.compiler.SDB_QC.exec(SDB_QC.java:65)
        at com.hp.hpl.jena.sdb.compiler.OpSQL.exec(OpSQL.java:53)
        at com.hp.hpl.jena.sdb.engine.QueryEngineSDB.eval(QueryEngineSDB.java:117)
        at 
com.hp.hpl.jena.sparql.engine.QueryEngineBase.evaluate(QueryEngineBase.java:138)
        at 
com.hp.hpl.jena.sparql.engine.QueryEngineBase.createPlan(QueryEngineBase.java:109)
        at 
com.hp.hpl.jena.sparql.engine.QueryEngineBase.getPlan(QueryEngineBase.java:97)
        at 
com.hp.hpl.jena.sdb.engine.QueryEngineSDB$QueryEngineFactorySDB.create(QueryEngineSDB.java:142)
        at 
com.hp.hpl.jena.sparql.engine.QueryExecutionBase.getPlan(QueryExecutionBase.java:266)
        at 
com.hp.hpl.jena.sparql.engine.QueryExecutionBase.startQueryIterator(QueryExecutionBase.java:243)
        at 
com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execResultSet(QueryExecutionBase.java:248)
        at 
com.hp.hpl.jena.sparql.engine.QueryExecutionBase.execSelect(QueryExecutionBase.java:94)
        at com.oreilly.rdf.tenuki.SDBBugTest.testForSDBBug(SDBBugTest.java:47)

Test Case:
https://github.com/norcalrdf/Tenuki/blob/0.4-bugfixes/src/test/java/com/oreilly/rdf/tenuki/SDBBugTest.java

Patch:
https://gist.github.com/675719"
JENA-26,Make Iter class documentation more prominent,"The Iter class has useful things in it but is currently obscure. Improve the javadoc and link to it from Model.
",Bug,"Make Iter class documentation more prominent The Iter class has useful things in it but is currently obscure. Improve the javadoc and link to it from Model.
"
JENA-23,tdbloader2 dies on unrecognized file suffix,"Exception in thread ""main"" java.lang.NullPointerException
	at com.hp.hpl.jena.tdb.store.bulkloader2.CmdNodeTableBuilder.exec(CmdNodeTableBuilder.java:147)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:85)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:47)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:34)
	at com.hp.hpl.jena.tdb.store.bulkloader2.CmdNodeTableBuilder.main(CmdNodeTableBuilder.java:70)
",Bug,"tdbloader2 dies on unrecognized file suffix Exception in thread ""main"" java.lang.NullPointerException
	at com.hp.hpl.jena.tdb.store.bulkloader2.CmdNodeTableBuilder.exec(CmdNodeTableBuilder.java:147)
	at arq.cmdline.CmdMain.mainMethod(CmdMain.java:85)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:47)
	at arq.cmdline.CmdMain.mainRun(CmdMain.java:34)
	at com.hp.hpl.jena.tdb.store.bulkloader2.CmdNodeTableBuilder.main(CmdNodeTableBuilder.java:70)
"
JENA-22,OpAsQuery doesn't support OpGroup,"OpAsQuery can't create some fairly straightforward queries, for example select (count(*) as ?cs) { ?s ?p ?o }.",Bug,"OpAsQuery doesn't support OpGroup OpAsQuery can't create some fairly straightforward queries, for example select (count(*) as ?cs) { ?s ?p ?o }."
JENA-19,Clean up N3,"1/ IO/howto.html (documentation)
2/ N3 writer to write strict Turtle
3/ N3-<variation> ==> Turtle-<variation>

",Bug,"Clean up N3 1/ IO/howto.html (documentation)
2/ N3 writer to write strict Turtle
3/ N3-<variation> ==> Turtle-<variation>

"
JENA-18,Round trip problem with N3 and owl:SameAs,"Using Jena 2.6.3, since I'm using tdb ...

If I write with language=N3, I get constructs that are rejected by the turtle parser. This is because 'strictTurtle' is always turned on. Perhaps the intent was to have a distinct N3 reader that subclasses the turtle parser or just made a call to turn off this flag?

",Bug,"Round trip problem with N3 and owl:SameAs Using Jena 2.6.3, since I'm using tdb ...

If I write with language=N3, I get constructs that are rejected by the turtle parser. This is because 'strictTurtle' is always turned on. Perhaps the intent was to have a distinct N3 reader that subclasses the turtle parser or just made a call to turn off this flag?

"
JENA-12,Turtle Files with a UTF-8 BOM fail to parse,"If a Turtle file has a BOM at the start then Jena will refuse to parse it giving the following error:

Exception in thread ""main"" com.hp.hpl.jena.n3.turtle.TurtleParseException: Lexical error at line 1, column 2.  Encountered: ""@"" (64), after : ""\ufeff""
    at com.hp.hpl.jena.n3.turtle.ParserTurtle.parse(ParserTurtle.java:44)
    at com.hp.hpl.jena.n3.turtle.TurtleReader.readWorker(TurtleReader.java:21)
    at com.hp.hpl.jena.n3.JenaReaderBase.readImpl(JenaReaderBase.java:101)
    at com.hp.hpl.jena.n3.JenaReaderBase.read(JenaReaderBase.java:68)
    at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:226)
    at TurtleWithBOM.main(TurtleWithBOM.java:31)

The code I used to produce this error was as follows:

import com.hp.hpl.jena.rdf.model.*;
import com.hp.hpl.jena.util.FileManager;

import java.io.*;

public class TurtleWithBOM
{

    public static void main(String[] args)
    {

        // create an empty model
        Model model = ModelFactory.createDefaultModel();

        InputStream in = FileManager.get().open( ""ttl-with-bom.ttl"" );
        if (in == null)
            {
            throw new IllegalArgumentException( ""File: ttl-with-bom.ttl not found"");
        }

        // read the Turtle file
        model.read(in, """", ""TTL"");

        // write it to standard out
        model.write(System.out);
    }
}

A sample Turtle file used with the above code is attached to this issue.

The data files are coming from my software which is all written in .Net and when outputting in UTF-8 the default behaviour of .Net is to include the BOM at the start of the file. The BOM is not required for UTF-8 but it is not forbidden so I think this should be fixed (if possible) for future releases. I will be modifying my software so that output of the BOM can be disabled by my users if desired 

Looking at the error message given I expect that the same problem would also affect N3 files since they are using the same reader afaict from the error trace. 
",Bug,"Turtle Files with a UTF-8 BOM fail to parse If a Turtle file has a BOM at the start then Jena will refuse to parse it giving the following error:

Exception in thread ""main"" com.hp.hpl.jena.n3.turtle.TurtleParseException: Lexical error at line 1, column 2.  Encountered: ""@"" (64), after : ""\ufeff""
    at com.hp.hpl.jena.n3.turtle.ParserTurtle.parse(ParserTurtle.java:44)
    at com.hp.hpl.jena.n3.turtle.TurtleReader.readWorker(TurtleReader.java:21)
    at com.hp.hpl.jena.n3.JenaReaderBase.readImpl(JenaReaderBase.java:101)
    at com.hp.hpl.jena.n3.JenaReaderBase.read(JenaReaderBase.java:68)
    at com.hp.hpl.jena.rdf.model.impl.ModelCom.read(ModelCom.java:226)
    at TurtleWithBOM.main(TurtleWithBOM.java:31)

The code I used to produce this error was as follows:

import com.hp.hpl.jena.rdf.model.*;
import com.hp.hpl.jena.util.FileManager;

import java.io.*;

public class TurtleWithBOM
{

    public static void main(String[] args)
    {

        // create an empty model
        Model model = ModelFactory.createDefaultModel();

        InputStream in = FileManager.get().open( ""ttl-with-bom.ttl"" );
        if (in == null)
            {
            throw new IllegalArgumentException( ""File: ttl-with-bom.ttl not found"");
        }

        // read the Turtle file
        model.read(in, """", ""TTL"");

        // write it to standard out
        model.write(System.out);
    }
}

A sample Turtle file used with the above code is attached to this issue.

The data files are coming from my software which is all written in .Net and when outputting in UTF-8 the default behaviour of .Net is to include the BOM at the start of the file. The BOM is not required for UTF-8 but it is not forbidden so I think this should be fixed (if possible) for future releases. I will be modifying my software so that output of the BOM can be disabled by my users if desired 

Looking at the error message given I expect that the same problem would also affect N3 files since they are using the same reader afaict from the error trace. 
"
JENA-6,Need a consistent policy on closing streams for Jena readers,"See also https://sourceforge.net/tracker/?func=detail&aid=3067790&group_id=40417&atid=430288

Jena readers do not provide any gaurantees as to the state of the stream in terms of byte position after parsing.  RIOT, and some original readers, also close the stream, on the principle the stream is no longer usable.

But Java zip streams signal end of stream but can continue to be read by moving to the next zip file entry.  Closing the stream after parsing is wrong in this case.

The original report noted a wrapper can be used that does not pass through the .close.
",Bug,"Need a consistent policy on closing streams for Jena readers See also https://sourceforge.net/tracker/?func=detail&aid=3067790&group_id=40417&atid=430288

Jena readers do not provide any gaurantees as to the state of the stream in terms of byte position after parsing.  RIOT, and some original readers, also close the stream, on the principle the stream is no longer usable.

But Java zip streams signal end of stream but can continue to be read by moving to the next zip file entry.  Closing the stream after parsing is wrong in this case.

The original report noted a wrapper can be used that does not pass through the .close.
"
JENA-5,IndexLARQ is not thread safe,"Copying a previously sent email:

I ran into a concurrency problem in LARQ.  When I try to run concurrent queries the Lucene query parser barfs.

After a bit of digging, I think I understand what is going on.  I was creating  an IndexLARQ and setting that as the global index, then running my queries.  The IndexLARQ constructor constructs a Lucene QueryParser object which it uses for all queries.  Lucene QueryParser objects are not thread safe, so multiple concurrent queries cause the parser the barf.

I have had a go at patching the HEAD from SVN.  Basically I make the QueryParser object in IndexLARQ ThreadLocal.

The problem with this is that there is a constructor to IndexLARQ which takes an externally provided QueryParser object and QueryParser is not clonable.  I could replicate the query parser for each thread provided I know its a QueryParser and not a subclass of QueryParser.  If someone passed in a subclass of QueryParser I'd go creating the wrong class of objects as a replica.

Whilst this scenario is not very likely, since I think the constructor should be deprecated anyway, what I've done is esentially left that constructor alone.  Creating an IndexLARQ with that contructor will continue to construct one that is not thread safe.  The other constructors will construct threadsafe instances.

Attached are:

a modified IndexLARQ.java that fixes the problem as I've described.
TestLARQConcurrent.java - a test case
larqConcurrentPatch - a patch file that applies the changes

Oops - Just noticed the license notice on the test case file - you will want to change that if you use this. 

hmmm - there doesn't seem to be a button here for attaching files.",Bug,"IndexLARQ is not thread safe Copying a previously sent email:

I ran into a concurrency problem in LARQ.  When I try to run concurrent queries the Lucene query parser barfs.

After a bit of digging, I think I understand what is going on.  I was creating  an IndexLARQ and setting that as the global index, then running my queries.  The IndexLARQ constructor constructs a Lucene QueryParser object which it uses for all queries.  Lucene QueryParser objects are not thread safe, so multiple concurrent queries cause the parser the barf.

I have had a go at patching the HEAD from SVN.  Basically I make the QueryParser object in IndexLARQ ThreadLocal.

The problem with this is that there is a constructor to IndexLARQ which takes an externally provided QueryParser object and QueryParser is not clonable.  I could replicate the query parser for each thread provided I know its a QueryParser and not a subclass of QueryParser.  If someone passed in a subclass of QueryParser I'd go creating the wrong class of objects as a replica.

Whilst this scenario is not very likely, since I think the constructor should be deprecated anyway, what I've done is esentially left that constructor alone.  Creating an IndexLARQ with that contructor will continue to construct one that is not thread safe.  The other constructors will construct threadsafe instances.

Attached are:

a modified IndexLARQ.java that fixes the problem as I've described.
TestLARQConcurrent.java - a test case
larqConcurrentPatch - a patch file that applies the changes

Oops - Just noticed the license notice on the test case file - you will want to change that if you use this. 

hmmm - there doesn't seem to be a button here for attaching files."
SCB-1476,SagaStartAnnotationProcessorTimeoutWrapper should handle SagaStart.autoClose(),"As we introduce autoClose attribute into SagaStart annotation, SagaStartAnnotationProcessorTimeoutWrapper should handle the autoClose is false case.
",Bug,"SagaStartAnnotationProcessorTimeoutWrapper should handle SagaStart.autoClose() As we introduce autoClose attribute into SagaStart annotation, SagaStartAnnotationProcessorTimeoutWrapper should handle the autoClose is false case.
"
SCB-1377,The Notice file of ServiceComb-Pack need to updated,"The project name in the Notice file is still ServiceComb Saga, we need to change it into ServiceComb Pack.",Bug,"The Notice file of ServiceComb-Pack need to updated The project name in the Notice file is still ServiceComb Saga, we need to change it into ServiceComb Pack."
SCB-1275,BMI example cannot be started,"{code}
Error creating bean with name 'standardJacksonObjectMapperBuilderCustomizer' defined in class path resource [org/springframework/boot/autoconfigure/jackson/JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration.class]: Unsatisfied dependency expressed through method 'standardJacksonObjectMapperBuilderCustomizer' parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties': Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: javax/validation/valueextraction/ValueExtractorDeclarationException
{code}",Bug,"BMI example cannot be started {code}
Error creating bean with name 'standardJacksonObjectMapperBuilderCustomizer' defined in class path resource [org/springframework/boot/autoconfigure/jackson/JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration.class]: Unsatisfied dependency expressed through method 'standardJacksonObjectMapperBuilderCustomizer' parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties': Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: javax/validation/valueextraction/ValueExtractorDeclarationException
{code}"
SCB-1118,EventScanner should catch the exception to keep it running.,"If there is an exception thrown during the pollEvents， the executor could supress the subsequce execution.  We need to catch the exception in the pollEvents method to keep the EventScanner running. 

Here is the[ github issue|https://github.com/apache/servicecomb-pack/issues/382] for it.",Bug,"EventScanner should catch the exception to keep it running. If there is an exception thrown during the pollEvents, the executor could supress the subsequce execution.  We need to catch the exception in the pollEvents method to keep the EventScanner running. 

Here is the[ github issue|https://github.com/apache/servicecomb-pack/issues/382] for it."
SCB-1098,Pack pom need to be updated,"When verify the release candidate of servicecomb-pack, I just found there are some pom artifact id and parent artifact id need to be updated, otherwise the demo could not be built.
",Bug,"Pack pom need to be updated When verify the release candidate of servicecomb-pack, I just found there are some pom artifact id and parent artifact id need to be updated, otherwise the demo could not be built.
"
SCB-1094,Java doc build error in tcc-inventory,"When doing the release build.  There is a javadoc build error
{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.9.1:jar (attach-javadocs) on project tcc-inventory: MavenReportException: Error while creating archive:
[ERROR] Exit code: 1 - javadoc: error - class file for javax.interceptor.InterceptorBinding not found
[ERROR]
[ERROR] Command line was: /Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/bin/javadoc @options @packages
[ERROR]
[ERROR] Refer to the generated Javadoc files in '/servicecomb/servicecomb-pack/demo/tcc-spring-demo/inventory/target/apidocs' dir.
[ERROR]
[ERROR] -> [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR] mvn <goals> -rf :tcc-inventory
{code}",Bug,"Java doc build error in tcc-inventory When doing the release build.  There is a javadoc build error
{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.9.1:jar (attach-javadocs) on project tcc-inventory: MavenReportException: Error while creating archive:
[ERROR] Exit code: 1 - javadoc: error - class file for javax.interceptor.InterceptorBinding not found
[ERROR]
[ERROR] Command line was: /Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/bin/javadoc @options @packages
[ERROR]
[ERROR] Refer to the generated Javadoc files in '/servicecomb/servicecomb-pack/demo/tcc-spring-demo/inventory/target/apidocs' dir.
[ERROR]
[ERROR] -> [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR] mvn <goals> -rf :tcc-inventory
{code}"
SCB-1085,Page in Chinese? http://servicecomb.apache.org/developers/use-jira/,"The page http://servicecomb.apache.org/developers/use-jira/ seems to be mostly in Chinese, and does not make sense for English speakers at whom the rest of the website seems to be aimed.",Bug,"Page in Chinese? http://servicecomb.apache.org/developers/use-jira/ The page http://servicecomb.apache.org/developers/use-jira/ seems to be mostly in Chinese, and does not make sense for English speakers at whom the rest of the website seems to be aimed."
SCB-1081,CompositeOmegaCallback's compensate(TxEvent event) method has concurrency issues,"CompositeOmegaCallback类的public void compensate(TxEvent event)方法可能会有并发异常

 
{code:java}
public void compensate(TxEvent event) {
 Map<String, OmegaCallback> serviceCallbacks = callbacks.getOrDefault(event.serviceName(), emptyMap());
if (serviceCallbacks.isEmpty()) {
 throw new AlphaException(""No such omega callback found for service "" + event.serviceName());
 }
OmegaCallback omegaCallback = serviceCallbacks.get(event.instanceId());
 if (omegaCallback == null) {
 LOG.info(""Cannot find the service with the instanceId {}, call the other instance."", event.instanceId());
 omegaCallback = serviceCallbacks.values().iterator().next();
 }
try {
 omegaCallback.compensate(event);
 } catch (Exception e) {
 serviceCallbacks.values().remove(omegaCallback);
 throw e;
 }
 }
{code}
线程可能通过了 if (omegaCallback == null) 的判断条件但是在omegaCallback = serviceCallbacks.values().iterator().next()之前失去了cpu执行权,由于其他线程对serviceCallbacks这个map的操作,目前看alpha端有两种情况:一种是接收到omega端的onDisconnected请求将对应omega端实例从map中移除;一种是执行pendingTask的线程重新进行补偿时失败执行下面这部分代码catch (Exception e) {
 serviceCallbacks.values().remove(omegaCallback);
 throw e;
 }时也会移除map中对应的omega端实例。

 

这部分代码由于是并发异常,发生的可能性本来就非常小,所以比较难以发现和复现。我是对源码在特定位置做了些修改然后复现出来的
{code:java}
if (omegaCallback == null) {
 LOG.info(""Cannot find the service with the instanceId {}, call the other instance."", event.instanceId());
 try {
 TimeUnit.SECONDS.sleep(2);
 } catch (InterruptedException e) {
 e.printStackTrace();
 }

 omegaCallback = serviceCallbacks.values().iterator().next();

}{code}
 
{code:java}
try {

 throw new RuntimeException();
// omegaCallback.compensate(event);
 } catch (Exception e) {{code}
 

下面是测试代码
{code:java}
@Test
public void compensateWithConcurrency() throws InterruptedException {

 ConcurrentHashMap<String, OmegaCallback> serviceCallbacks = new ConcurrentHashMap();
 serviceCallbacks.put(instanceId1One,callback1One);
 callbacks.put(serviceName1,serviceCallbacks);
 new Thread(new Runnable() {
 @Override
 public void run() {
 compositeOmegaCallback.compensate(eventOf(serviceName1,instanceId1Two,TxStartedEvent));
 }
 }).start();


 TimeUnit.SECONDS.sleep(1);

 new Thread(new Runnable() {
 @Override
 public void run() {
 compositeOmegaCallback.compensate(eventOf(serviceName1,instanceId1One,TxStartedEvent));
 }
 }).start();


 TimeUnit.SECONDS.sleep(3);

}{code}",Bug,"CompositeOmegaCallback's compensate(TxEvent event) method has concurrency issues CompositeOmegaCallbackLei De public void compensate(TxEvent event)Fang Fa Ke Neng Hui You Bing Fa Yi Chang 

 
{code:java}
public void compensate(TxEvent event) {
 Map<String, OmegaCallback> serviceCallbacks = callbacks.getOrDefault(event.serviceName(), emptyMap());
if (serviceCallbacks.isEmpty()) {
 throw new AlphaException(""No such omega callback found for service "" + event.serviceName());
 }
OmegaCallback omegaCallback = serviceCallbacks.get(event.instanceId());
 if (omegaCallback == null) {
 LOG.info(""Cannot find the service with the instanceId {}, call the other instance."", event.instanceId());
 omegaCallback = serviceCallbacks.values().iterator().next();
 }
try {
 omegaCallback.compensate(event);
 } catch (Exception e) {
 serviceCallbacks.values().remove(omegaCallback);
 throw e;
 }
 }
{code}
Xian Cheng Ke Neng Tong Guo Liao  if (omegaCallback == null) De Pan Duan Tiao Jian Dan Shi Zai omegaCallback = serviceCallbacks.values().iterator().next()Zhi Qian Shi Qu Liao cpuZhi Xing Quan ,You Yu Qi Ta Xian Cheng Dui serviceCallbacksZhe Ge mapDe Cao Zuo ,Mu Qian Kan alphaDuan You Liang Chong Qing Kuang :Yi Chong Shi Jie Shou Dao omegaDuan De onDisconnectedQing Qiu Jiang Dui Ying omegaDuan Shi Li Cong mapZhong Yi Chu ;Yi Chong Shi Zhi Xing pendingTaskDe Xian Cheng Zhong Xin Jin Xing Bu Chang Shi Shi Bai Zhi Xing Xia Mian Zhe Bu Fen Dai Ma catch (Exception e) {
 serviceCallbacks.values().remove(omegaCallback);
 throw e;
 }Shi Ye Hui Yi Chu mapZhong Dui Ying De omegaDuan Shi Li . 

 

Zhe Bu Fen Dai Ma You Yu Shi Bing Fa Yi Chang ,Fa Sheng De Ke Neng Xing Ben Lai Jiu Fei Chang Xiao ,Suo Yi Bi Jiao Nan Yi Fa Xian He Fu Xian . Wo Shi Dui Yuan Ma Zai Te Ding Wei Zhi Zuo Liao Xie Xiu Gai Ran Hou Fu Xian Chu Lai De 
{code:java}
if (omegaCallback == null) {
 LOG.info(""Cannot find the service with the instanceId {}, call the other instance."", event.instanceId());
 try {
 TimeUnit.SECONDS.sleep(2);
 } catch (InterruptedException e) {
 e.printStackTrace();
 }

 omegaCallback = serviceCallbacks.values().iterator().next();

}{code}
 
{code:java}
try {

 throw new RuntimeException();
// omegaCallback.compensate(event);
 } catch (Exception e) {{code}
 

Xia Mian Shi Ce Shi Dai Ma 
{code:java}
@Test
public void compensateWithConcurrency() throws InterruptedException {

 ConcurrentHashMap<String, OmegaCallback> serviceCallbacks = new ConcurrentHashMap();
 serviceCallbacks.put(instanceId1One,callback1One);
 callbacks.put(serviceName1,serviceCallbacks);
 new Thread(new Runnable() {
 @Override
 public void run() {
 compositeOmegaCallback.compensate(eventOf(serviceName1,instanceId1Two,TxStartedEvent));
 }
 }).start();


 TimeUnit.SECONDS.sleep(1);

 new Thread(new Runnable() {
 @Override
 public void run() {
 compositeOmegaCallback.compensate(eventOf(serviceName1,instanceId1One,TxStartedEvent));
 }
 }).start();


 TimeUnit.SECONDS.sleep(3);

}{code}"
SCB-971,Saga TCC Demo ,"When I run the tcc demo and curl -X POST http://${host_address}:8083/ordering/order/UserC/ProductA/2/2, saga works well.

But one hour later, I invoke the service  with ""curl -X POST http://${host_address}:8083/ordering/order/UserC/ProductA/2/2"" again, it returns ""\{""timestamp"":1540188973814,""status"":500,""error"":""Internal Server Error"",""exception"":""org.springframework.web.client.HttpServerErrorException"",""message"":""500 null"",""path"":""/ordering/order/UserC/ProductA/2/2""}"", and the command "" curl -X http://${host_address}:8082/orderings"" returns 
[\{""userName"":""UserC"",""productName"":""ProductA"",""units"":2,""confirmed"":false,""cancelled"":true},\{""userName"":""UserC"",""productName"":""ProductA"",""units"":2,""confirmed"":false,""cancelled"":false}] ,both ""confirmed"" and ""cancelled"" are marked as false.

The stack trace is here.
{code}
Caused by: javax.persistence.RollbackException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.7.1.v20171221-bd47e8f): org.eclipse.persistence.exceptions.DatabaseException
alpha_1      | Internal Exception: org.postgresql.util.PSQLException: The connection attempt failed.
alpha_1      | Error Code: 0
alpha_1      | Query: InsertObjectQuery(GlobalTxEvent{surrogateId=null, globalTxId='6ce54fa3-0cb5-403f-badf-81134d290a17', localTxId='6ce54fa3-0cb5-403f-badf-81134d290a17', parentTxId='', serviceName='ordering', instanceId='ordering-172.21.0.6', txType='ENDED', status='Failed', creationTime=Mon Oct 22 06:16:13 GMT 2018, lastModified=Mon Oct 22 06:16:13 GMT 2018})
alpha_1      | 	at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:159) ~[org.eclipse.persistence.jpa-2.7.1.jar!/:?]
alpha_1      | 	at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[spring-orm-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
alpha_1      | 	... 19 more
alpha_1      | Caused by: org.eclipse.persistence.exceptions.DatabaseException: 
alpha_1      | Internal Exception: org.postgresql.util.PSQLException: The connection attempt failed.
alpha_1      | Error Code: 0
alpha_1      | Query: InsertObjectQuery(GlobalTxEvent{surrogateId=null, globalTxId='6ce54fa3-0cb5-403f-badf-81134d290a17', localTxId='6ce54fa3-0cb5-403f-badf-81134d290a17', parentTxId='', serviceName='ordering', instanceId='ordering-172.21.0.6', txType='ENDED', status='Failed', creationTime=Mon Oct 22 06:16:13 GMT 2018, lastModified=Mon Oct 22 06:16:13 GMT 2018})
alpha_1      | 	at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:316) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.JNDIConnector.connect(JNDIConnector.java:147) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.DatasourceLogin.connectToDatasource(DatasourceLogin.java:170) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.connectInternal(DatasourceAccessor.java:346) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.connectInternal(DatabaseAccessor.java:313) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.reconnect(DatasourceAccessor.java:581) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.reconnect(DatabaseAccessor.java:1660) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.incrementCallCount(DatasourceAccessor.java:321) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.beginTransaction(DatasourceAccessor.java:254) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.retryTransaction(ClientSession.java:786) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.basicBeginTransaction(AbstractSession.java:747) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.addWriteConnection(ClientSession.java:755) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ServerSession.acquireClientConnection(ServerSession.java:268) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:280) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:270) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:256) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.insertObject(DatasourceCallQueryMechanism.java:405) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:165) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:180) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.insertObjectForWrite(DatabaseQueryMechanism.java:502) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.InsertObjectQuery.executeCommit(InsertObjectQuery.java:80) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.InsertObjectQuery.executeCommitWithChangeSet(InsertObjectQuery.java:90) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.executeWriteWithChangeSet(DatabaseQueryMechanism.java:314) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.WriteObjectQuery.executeDatabaseQuery(WriteObjectQuery.java:58) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:911) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.DatabaseQuery.executeInUnitOfWork(DatabaseQuery.java:810) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWorkObjectLevelModifyQuery(ObjectLevelModifyQuery.java:108) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWork(ObjectLevelModifyQuery.java:85) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:2979) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1892) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1874) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1824) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitNewObjectsForClassWithChangeSet(CommitManager.java:227) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsForClassWithChangeSet(CommitManager.java:194) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsWithChangeSet(CommitManager.java:139) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.writeAllObjectsWithChangeSet(AbstractSession.java:4384) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabase(UnitOfWorkImpl.java:1491) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabaseWithChangeSet(UnitOfWorkImpl.java:1581) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.RepeatableWriteUnitOfWork.commitRootUnitOfWork(RepeatableWriteUnitOfWork.java:278) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitAndResume(UnitOfWorkImpl.java:1218) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
ordering_1   | 2018-10-22 06:16:13.805 ERROR 6 --- [nio-8080-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.web.client.HttpServerErrorException: 500 null] with root cause
ordering_1   | 
ordering_1   | org.springframework.web.client.HttpServerErrorException: 500 null
ordering_1   | 	at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:89) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:708) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:661) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:621) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.client.RestTemplate.postForEntity(RestTemplate.java:415) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.servicecomb.saga.demo.pack.ordering.OrderingController.ordering(OrderingController.java:54) ~[classes!/:0.3.0-SNAPSHOT]
ordering_1   | 	at org.apache.servicecomb.saga.demo.pack.ordering.OrderingController$$FastClassBySpringCGLIB$$17c52a68.invoke(<generated>) ~[classes!/:0.3.0-SNAPSHOT]
ordering_1   | 	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:736) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:84) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.servicecomb.saga.omega.transaction.tcc.TccStartAspect.advise(TccStartAspect.java:54) ~[omega-transaction-0.3.0-SNAPSHOT.jar!/:0.3.0-SNAPSHOT]
ordering_1   | 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]
ordering_1   | 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151]
ordering_1   | 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]
ordering_1   | 	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]
ordering_1   | 	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:627) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:616) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:671) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.servicecomb.saga.demo.pack.ordering.OrderingController$$EnhancerBySpringCGLIB$$5a72fd16.ordering(<generated>) ~[classes!/:0.3.0-SNAPSHOT]
ordering_1   | 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]
ordering_1   | 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151]
ordering_1   | 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]
ordering_1   | 	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]
ordering_1   | 	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ~[tomcat-embed-websocket-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.14.RELEASE.jar!/:1.5.14.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.14.RELEASE.jar!/:1.5.14.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.14.RELEASE.jar!/:1.5.14.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:496) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1468) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_151]
ordering_1   | 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151]
ordering_1   | 	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]
ordering_1   | 
alpha_1      | 	at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:134) ~[org.eclipse.persistence.jpa-2.7.1.jar!/:?]
alpha_1      | 	at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[spring-orm-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
alpha_1      | 	... 19 more
alpha_1      | Caused by: org.postgresql.util.PSQLException: The connection attempt failed.
alpha_1      | 	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:272) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:215) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.postgresql.Driver.makeConnection(Driver.java:404) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.postgresql.Driver.connect(Driver.java:272) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.PooledConnection.connectUsingDriver(PooledConnection.java:319) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.PooledConnection.connect(PooledConnection.java:212) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.ConnectionPool.createConnection(ConnectionPool.java:736) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:668) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:198) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:132) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.JNDIConnector.connect(JNDIConnector.java:135) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.DatasourceLogin.connectToDatasource(DatasourceLogin.java:170) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.connectInternal(DatasourceAccessor.java:346) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.connectInternal(DatabaseAccessor.java:313) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.reconnect(DatasourceAccessor.java:581) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.reconnect(DatabaseAccessor.java:1660) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.incrementCallCount(DatasourceAccessor.java:321) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.beginTransaction(DatasourceAccessor.java:254) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.retryTransaction(ClientSession.java:786) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.basicBeginTransaction(AbstractSession.java:747) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.addWriteConnection(ClientSession.java:755) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ServerSession.acquireClientConnection(ServerSession.java:268) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:280) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:270) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:256) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.insertObject(DatasourceCallQueryMechanism.java:405) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:165) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:180) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.insertObjectForWrite(DatabaseQueryMechanism.java:502) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.InsertObjectQuery.executeCommit(InsertObjectQuery.java:80) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.InsertObjectQuery.executeCommitWithChangeSet(InsertObjectQuery.java:90) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.executeWriteWithChangeSet(DatabaseQueryMechanism.java:314) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.WriteObjectQuery.executeDatabaseQuery(WriteObjectQuery.java:58) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:911) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.DatabaseQuery.executeInUnitOfWork(DatabaseQuery.java:810) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWorkObjectLevelModifyQuery(ObjectLevelModifyQuery.java:108) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWork(ObjectLevelModifyQuery.java:85) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:2979) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1892) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1874) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1824) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitNewObjectsForClassWithChangeSet(CommitManager.java:227) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsForClassWithChangeSet(CommitManager.java:194) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsWithChangeSet(CommitManager.java:139) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.writeAllObjectsWithChangeSet(AbstractSession.java:4384) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabase(UnitOfWorkImpl.java:1491) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabaseWithChangeSet(UnitOfWorkImpl.java:1581) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.RepeatableWriteUnitOfWork.commitRootUnitOfWork(RepeatableWriteUnitOfWork.java:278) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitAndResume(UnitOfWorkImpl.java:1218) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:134) ~[org.eclipse.persistence.jpa-2.7.1.jar!/:?]
alpha_1      | 	at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[spring-orm-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
alpha_1      | 	... 19 more
alpha_1      | Caused by: java.net.UnknownHostException: postgresql.servicecomb.io
alpha_1      | 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184) ~[?:1.8.0_151]
alpha_1      | 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_",Bug,"Saga TCC Demo  When I run the tcc demo and curl -X POST http://${host_address}:8083/ordering/order/UserC/ProductA/2/2, saga works well.

But one hour later, I invoke the service  with ""curl -X POST http://${host_address}:8083/ordering/order/UserC/ProductA/2/2"" again, it returns ""\{""timestamp"":1540188973814,""status"":500,""error"":""Internal Server Error"",""exception"":""org.springframework.web.client.HttpServerErrorException"",""message"":""500 null"",""path"":""/ordering/order/UserC/ProductA/2/2""}"", and the command "" curl -X http://${host_address}:8082/orderings"" returns 
[\{""userName"":""UserC"",""productName"":""ProductA"",""units"":2,""confirmed"":false,""cancelled"":true},\{""userName"":""UserC"",""productName"":""ProductA"",""units"":2,""confirmed"":false,""cancelled"":false}] ,both ""confirmed"" and ""cancelled"" are marked as false.

The stack trace is here.
{code}
Caused by: javax.persistence.RollbackException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.7.1.v20171221-bd47e8f): org.eclipse.persistence.exceptions.DatabaseException
alpha_1      | Internal Exception: org.postgresql.util.PSQLException: The connection attempt failed.
alpha_1      | Error Code: 0
alpha_1      | Query: InsertObjectQuery(GlobalTxEvent{surrogateId=null, globalTxId='6ce54fa3-0cb5-403f-badf-81134d290a17', localTxId='6ce54fa3-0cb5-403f-badf-81134d290a17', parentTxId='', serviceName='ordering', instanceId='ordering-172.21.0.6', txType='ENDED', status='Failed', creationTime=Mon Oct 22 06:16:13 GMT 2018, lastModified=Mon Oct 22 06:16:13 GMT 2018})
alpha_1      | 	at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:159) ~[org.eclipse.persistence.jpa-2.7.1.jar!/:?]
alpha_1      | 	at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[spring-orm-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
alpha_1      | 	... 19 more
alpha_1      | Caused by: org.eclipse.persistence.exceptions.DatabaseException: 
alpha_1      | Internal Exception: org.postgresql.util.PSQLException: The connection attempt failed.
alpha_1      | Error Code: 0
alpha_1      | Query: InsertObjectQuery(GlobalTxEvent{surrogateId=null, globalTxId='6ce54fa3-0cb5-403f-badf-81134d290a17', localTxId='6ce54fa3-0cb5-403f-badf-81134d290a17', parentTxId='', serviceName='ordering', instanceId='ordering-172.21.0.6', txType='ENDED', status='Failed', creationTime=Mon Oct 22 06:16:13 GMT 2018, lastModified=Mon Oct 22 06:16:13 GMT 2018})
alpha_1      | 	at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:316) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.JNDIConnector.connect(JNDIConnector.java:147) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.DatasourceLogin.connectToDatasource(DatasourceLogin.java:170) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.connectInternal(DatasourceAccessor.java:346) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.connectInternal(DatabaseAccessor.java:313) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.reconnect(DatasourceAccessor.java:581) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.reconnect(DatabaseAccessor.java:1660) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.incrementCallCount(DatasourceAccessor.java:321) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.beginTransaction(DatasourceAccessor.java:254) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.retryTransaction(ClientSession.java:786) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.basicBeginTransaction(AbstractSession.java:747) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.addWriteConnection(ClientSession.java:755) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ServerSession.acquireClientConnection(ServerSession.java:268) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:280) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:270) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:256) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.insertObject(DatasourceCallQueryMechanism.java:405) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:165) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:180) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.insertObjectForWrite(DatabaseQueryMechanism.java:502) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.InsertObjectQuery.executeCommit(InsertObjectQuery.java:80) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.InsertObjectQuery.executeCommitWithChangeSet(InsertObjectQuery.java:90) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.executeWriteWithChangeSet(DatabaseQueryMechanism.java:314) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.WriteObjectQuery.executeDatabaseQuery(WriteObjectQuery.java:58) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:911) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.DatabaseQuery.executeInUnitOfWork(DatabaseQuery.java:810) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWorkObjectLevelModifyQuery(ObjectLevelModifyQuery.java:108) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWork(ObjectLevelModifyQuery.java:85) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:2979) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1892) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1874) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1824) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitNewObjectsForClassWithChangeSet(CommitManager.java:227) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsForClassWithChangeSet(CommitManager.java:194) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsWithChangeSet(CommitManager.java:139) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.writeAllObjectsWithChangeSet(AbstractSession.java:4384) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabase(UnitOfWorkImpl.java:1491) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabaseWithChangeSet(UnitOfWorkImpl.java:1581) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.RepeatableWriteUnitOfWork.commitRootUnitOfWork(RepeatableWriteUnitOfWork.java:278) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitAndResume(UnitOfWorkImpl.java:1218) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
ordering_1   | 2018-10-22 06:16:13.805 ERROR 6 --- [nio-8080-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.web.client.HttpServerErrorException: 500 null] with root cause
ordering_1   | 
ordering_1   | org.springframework.web.client.HttpServerErrorException: 500 null
ordering_1   | 	at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:89) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:708) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:661) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:621) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.client.RestTemplate.postForEntity(RestTemplate.java:415) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.servicecomb.saga.demo.pack.ordering.OrderingController.ordering(OrderingController.java:54) ~[classes!/:0.3.0-SNAPSHOT]
ordering_1   | 	at org.apache.servicecomb.saga.demo.pack.ordering.OrderingController$$FastClassBySpringCGLIB$$17c52a68.invoke(<generated>) ~[classes!/:0.3.0-SNAPSHOT]
ordering_1   | 	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:736) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:84) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.servicecomb.saga.omega.transaction.tcc.TccStartAspect.advise(TccStartAspect.java:54) ~[omega-transaction-0.3.0-SNAPSHOT.jar!/:0.3.0-SNAPSHOT]
ordering_1   | 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]
ordering_1   | 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151]
ordering_1   | 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]
ordering_1   | 	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]
ordering_1   | 	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:627) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:616) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:671) ~[spring-aop-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.servicecomb.saga.demo.pack.ordering.OrderingController$$EnhancerBySpringCGLIB$$5a72fd16.ordering(<generated>) ~[classes!/:0.3.0-SNAPSHOT]
ordering_1   | 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_151]
ordering_1   | 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_151]
ordering_1   | 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_151]
ordering_1   | 	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_151]
ordering_1   | 	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at javax.servlet.http.HttpServlet.service(HttpServlet.java:661) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) ~[spring-webmvc-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ~[tomcat-embed-websocket-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) ~[spring-boot-1.5.14.RELEASE.jar!/:1.5.14.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:111) ~[spring-boot-actuator-1.5.14.RELEASE.jar!/:1.5.14.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) ~[spring-boot-actuator-1.5.14.RELEASE.jar!/:1.5.14.RELEASE]
ordering_1   | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) ~[tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:496) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1468) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_151]
ordering_1   | 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151]
ordering_1   | 	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.31.jar!/:8.5.31]
ordering_1   | 	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]
ordering_1   | 
alpha_1      | 	at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:134) ~[org.eclipse.persistence.jpa-2.7.1.jar!/:?]
alpha_1      | 	at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[spring-orm-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
alpha_1      | 	... 19 more
alpha_1      | Caused by: org.postgresql.util.PSQLException: The connection attempt failed.
alpha_1      | 	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:272) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:215) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.postgresql.Driver.makeConnection(Driver.java:404) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.postgresql.Driver.connect(Driver.java:272) ~[postgresql-9.4.1212.jre7.jar!/:9.4.1212.jre7]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.PooledConnection.connectUsingDriver(PooledConnection.java:319) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.PooledConnection.connect(PooledConnection.java:212) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.ConnectionPool.createConnection(ConnectionPool.java:736) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:668) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:198) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:132) ~[tomcat-jdbc-8.5.31.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.JNDIConnector.connect(JNDIConnector.java:135) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.DatasourceLogin.connectToDatasource(DatasourceLogin.java:170) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.connectInternal(DatasourceAccessor.java:346) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.connectInternal(DatabaseAccessor.java:313) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.reconnect(DatasourceAccessor.java:581) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.reconnect(DatabaseAccessor.java:1660) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.incrementCallCount(DatasourceAccessor.java:321) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.databaseaccess.DatasourceAccessor.beginTransaction(DatasourceAccessor.java:254) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.retryTransaction(ClientSession.java:786) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.basicBeginTransaction(AbstractSession.java:747) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.addWriteConnection(ClientSession.java:755) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ServerSession.acquireClientConnection(ServerSession.java:268) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:280) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:270) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:256) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.insertObject(DatasourceCallQueryMechanism.java:405) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:165) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:180) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.insertObjectForWrite(DatabaseQueryMechanism.java:502) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.InsertObjectQuery.executeCommit(InsertObjectQuery.java:80) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.InsertObjectQuery.executeCommitWithChangeSet(InsertObjectQuery.java:90) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.executeWriteWithChangeSet(DatabaseQueryMechanism.java:314) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.WriteObjectQuery.executeDatabaseQuery(WriteObjectQuery.java:58) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:911) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.DatabaseQuery.executeInUnitOfWork(DatabaseQuery.java:810) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWorkObjectLevelModifyQuery(ObjectLevelModifyQuery.java:108) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWork(ObjectLevelModifyQuery.java:85) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:2979) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1892) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1874) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1824) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitNewObjectsForClassWithChangeSet(CommitManager.java:227) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsForClassWithChangeSet(CommitManager.java:194) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsWithChangeSet(CommitManager.java:139) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.AbstractSession.writeAllObjectsWithChangeSet(AbstractSession.java:4384) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabase(UnitOfWorkImpl.java:1491) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabaseWithChangeSet(UnitOfWorkImpl.java:1581) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.RepeatableWriteUnitOfWork.commitRootUnitOfWork(RepeatableWriteUnitOfWork.java:278) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitAndResume(UnitOfWorkImpl.java:1218) ~[org.eclipse.persistence.core-2.7.1.jar!/:?]
alpha_1      | 	at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:134) ~[org.eclipse.persistence.jpa-2.7.1.jar!/:?]
alpha_1      | 	at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[spring-orm-4.3.18.RELEASE.jar!/:4.3.18.RELEASE]
alpha_1      | 	... 19 more
alpha_1      | Caused by: java.net.UnknownHostException: postgresql.servicecomb.io
alpha_1      | 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184) ~[?:1.8.0_151]
alpha_1      | 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:"
SCB-955,cancel/confirm includes more than one parameters will cause Alpha error,"16:03:29.229 [grpc-default-executor-14] ERROR io.grpc.internal.SerializingExecutor - Exception while executing runnable io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed@57d8c74b
java.lang.IllegalArgumentException: MethodInfo: confirm=void com.huawei.cse.houseapp.user.service.UserService.confirmTransactionTCC(long,double),cancel=void com.huawei.cse.houseapp.user.service.UserService.cancelTransactionTCC(long,double), has some bad formats.
 at org.apache.servicecomb.saga.alpha.server.tcc.jpa.EventConverter.getMethodName(EventConverter.java:156) ~[classes!/:0.3.0-SNAPSHOT]
 at org.apache.servicecomb.saga.alpha.server.tcc.jpa.EventConverter.convertToParticipatedEvent(EventConverter.java:136) ~[classes!/:0.3.0-S

 

 

We can reproduce this issue using this project: (install see readme.md)

https://github.com/huaweicse/HouseApp/tree/spring-boot-2.0-with-zipkin",Bug,"cancel/confirm includes more than one parameters will cause Alpha error 16:03:29.229 [grpc-default-executor-14] ERROR io.grpc.internal.SerializingExecutor - Exception while executing runnable io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed@57d8c74b
java.lang.IllegalArgumentException: MethodInfo: confirm=void com.huawei.cse.houseapp.user.service.UserService.confirmTransactionTCC(long,double),cancel=void com.huawei.cse.houseapp.user.service.UserService.cancelTransactionTCC(long,double), has some bad formats.
 at org.apache.servicecomb.saga.alpha.server.tcc.jpa.EventConverter.getMethodName(EventConverter.java:156) ~[classes!/:0.3.0-SNAPSHOT]
 at org.apache.servicecomb.saga.alpha.server.tcc.jpa.EventConverter.convertToParticipatedEvent(EventConverter.java:136) ~[classes!/:0.3.0-S

 

 

We can reproduce this issue using this project: (install see readme.md)

https://github.com/huaweicse/HouseApp/tree/spring-boot-2.0-with-zipkin"
SCB-831,Saga UT failed at LoadBalancedClusterMessageSenderTest on Windows environment,"UT will failed at : LoadBalancedClusterMessageSenderTest.stopSendingWhenClusterIsDown

It seems this assert

await().atMost(2, SECONDS).until(new Callable<Boolean>() {
    @Override
    public Boolean call() throws Exception {
        return connected.get(8080).size() == 2 || connected.get(8090).size() == 2;
    }
});

The  connected size will only be 1 not 2

I had found out that GrpcCompensateStreamObserver don't trigger onError when simulate connection closed in this case so LoadBalancedClusterMessageSender can't take PushBackReconnectRunnable from pendingTasks in order to reconnect server, then the connected count will be only 1, then test case failed

 ",Bug,"Saga UT failed at LoadBalancedClusterMessageSenderTest on Windows environment UT will failed at : LoadBalancedClusterMessageSenderTest.stopSendingWhenClusterIsDown

It seems this assert

await().atMost(2, SECONDS).until(new Callable<Boolean>() {
    @Override
    public Boolean call() throws Exception {
        return connected.get(8080).size() == 2 || connected.get(8090).size() == 2;
    }
});

The  connected size will only be 1 not 2

I had found out that GrpcCompensateStreamObserver don't trigger onError when simulate connection closed in this case so LoadBalancedClusterMessageSender can't take PushBackReconnectRunnable from pendingTasks in order to reconnect server, then the connected count will be only 1, then test case failed

 "
SCB-821,Add missing dependencyManagement for omega-transport-feign,Project failed to build with -Prelease due to missing version information of omega-transport-feign.,Bug,Add missing dependencyManagement for omega-transport-feign Project failed to build with -Prelease due to missing version information of omega-transport-feign.
SCB-741,Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'payloads' at row 1,"I encounter an Exception at Alpha Server
{code:java}
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'payloads' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3974) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3912) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2530) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2683) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2486) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeLargeUpdate(PreparedStatement.java:5104) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1998) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source) ~[na:na]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_102]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_102]
	at org.apache.tomcat.jdbc.pool.StatementFacade$StatementProxy.invoke(StatementFacade.java:114) ~[tomcat-jdbc-8.5.31.jar:na]
	at com.sun.proxy.$Proxy106.executeUpdate(Unknown Source) ~[na:na]
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeDirectNoSelect(DatabaseAccessor.java:895) ~[org.eclipse.persistence.core-2.7.1.jar:na]
	... 60 common frames omitted
{code}
I find it's because payload bytes is more than 10240
{code:java}
public class TxAbortedEvent extends TxEvent {
  public TxAbortedEvent(String globalTxId, String localTxId, String parentTxId, String compensationMethod, Throwable throwable) {
    super(EventType.TxAbortedEvent, globalTxId, localTxId, parentTxId, compensationMethod, 0, """", 0,
        stackTrace(throwable));
  }

  private static String stackTrace(Throwable e) {
    StringWriter writer = new StringWriter();
    e.printStackTrace(new PrintWriter(writer));
    return writer.toString();
  }
}
{code}
 ",Bug,"Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'payloads' at row 1 I encounter an Exception at Alpha Server
{code:java}
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'payloads' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3974) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3912) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2530) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2683) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2486) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2079) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeUpdateInternal(PreparedStatement.java:2013) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeLargeUpdate(PreparedStatement.java:5104) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1998) ~[mysql-connector-java-5.1.46.jar:5.1.46]
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source) ~[na:na]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_102]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_102]
	at org.apache.tomcat.jdbc.pool.StatementFacade$StatementProxy.invoke(StatementFacade.java:114) ~[tomcat-jdbc-8.5.31.jar:na]
	at com.sun.proxy.$Proxy106.executeUpdate(Unknown Source) ~[na:na]
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeDirectNoSelect(DatabaseAccessor.java:895) ~[org.eclipse.persistence.core-2.7.1.jar:na]
	... 60 common frames omitted
{code}
I find it's because payload bytes is more than 10240
{code:java}
public class TxAbortedEvent extends TxEvent {
  public TxAbortedEvent(String globalTxId, String localTxId, String parentTxId, String compensationMethod, Throwable throwable) {
    super(EventType.TxAbortedEvent, globalTxId, localTxId, parentTxId, compensationMethod, 0, """", 0,
        stackTrace(throwable));
  }

  private static String stackTrace(Throwable e) {
    StringWriter writer = new StringWriter();
    e.printStackTrace(new PrintWriter(writer));
    return writer.toString();
  }
}
{code}
 "
SCB-739,"It is useless for @SagaStart timeout,and it could not be compensated under @SagaStart","I don't know what SagaStart annotation timeout use, because the timeout is not work.
In the spring cloud demo,if hotel set a wrong address or port，the car service may not be compensated
{code:java}
 @SagaStart(timeout = 60000) //timeout no use,can not affect compensate 
  @PostMapping(""/booking/{name}/{rooms}/{cars}"")
  public String order(@PathVariable String name,  @PathVariable Integer rooms, @PathVariable Integer cars) {

    template.postForEntity(
        carServiceUrl + ""/order/{name}/{cars}"",
        null, String.class, name, cars);

   //if set a wrong hotel address,car service compensated method not be triggered
    template.postForEntity(
        hotelServiceUrl + ""/order/{name}/{rooms}"",
        null, String.class, name, rooms);
    
     postBooking();

     return name + "" booking "" + rooms + "" rooms and "" + cars + "" cars OK"";
}
{code}
 ",Bug,"It is useless for @SagaStart timeout,and it could not be compensated under @SagaStart I don't know what SagaStart annotation timeout use, because the timeout is not work.
In the spring cloud demo,if hotel set a wrong address or port,the car service may not be compensated
{code:java}
 @SagaStart(timeout = 60000) //timeout no use,can not affect compensate 
  @PostMapping(""/booking/{name}/{rooms}/{cars}"")
  public String order(@PathVariable String name,  @PathVariable Integer rooms, @PathVariable Integer cars) {

    template.postForEntity(
        carServiceUrl + ""/order/{name}/{cars}"",
        null, String.class, name, cars);

   //if set a wrong hotel address,car service compensated method not be triggered
    template.postForEntity(
        hotelServiceUrl + ""/order/{name}/{rooms}"",
        null, String.class, name, rooms);
    
     postBooking();

     return name + "" booking "" + rooms + "" rooms and "" + cars + "" cars OK"";
}
{code}
 "
SCB-584,DubboConsumerFilterTest fails on linux,"The DubboConsumerFilterTest fails with the following error:

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running SagaDubboProviderFilterTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.518 sec - in SagaDubboProviderFilterTest
Running SagaDubboConsumerFilterTest
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.017 sec <<< FAILURE! - in SagaDubboConsumerFilterTest
interceptTransactionIdInHeaderIfContextPresent(SagaDubboConsumerFilterTest) Time elapsed: 0.005 sec <<< FAILURE!
java.lang.AssertionError:

Expected: is ""cf4a9f4a-b9e5-43f5-a7d9-837fa96ee4c0""
 but: was ""3ef495de-2f2a-4afa-b991-237cd8de7e1e""
 at SagaDubboConsumerFilterTest.interceptTransactionIdInHeaderIfContextPresent(SagaDubboConsumerFilterTest.java:82)

 

 

 ",Bug,"DubboConsumerFilterTest fails on linux The DubboConsumerFilterTest fails with the following error:

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running SagaDubboProviderFilterTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.518 sec - in SagaDubboProviderFilterTest
Running SagaDubboConsumerFilterTest
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.017 sec <<< FAILURE! - in SagaDubboConsumerFilterTest
interceptTransactionIdInHeaderIfContextPresent(SagaDubboConsumerFilterTest) Time elapsed: 0.005 sec <<< FAILURE!
java.lang.AssertionError:

Expected: is ""cf4a9f4a-b9e5-43f5-a7d9-837fa96ee4c0""
 but: was ""3ef495de-2f2a-4afa-b991-237cd8de7e1e""
 at SagaDubboConsumerFilterTest.interceptTransactionIdInHeaderIfContextPresent(SagaDubboConsumerFilterTest.java:82)

 

 

 "
SCB-522,Compensation call could fail because of CompensationContext is instance related,"It's a critical situation, I could not provide a test case. But I can explain it with an example:

We deploy two service instance A and B with same codebase. We usually do this for high available.

If A did some operation, CompensationContext of A will cache instance of service bean, than later it would be used in compensation call if error happens.

But if A crash, the coordinator (aka alpha) will call an backup service instance, which is B, to compensate. Although there is no cached instance of service bean in CompensationContext of B, so compensation fail.

We expect any instance of same service should process compensation successfully, if it doesn't, it is a bug.",Bug,"Compensation call could fail because of CompensationContext is instance related It's a critical situation, I could not provide a test case. But I can explain it with an example:

We deploy two service instance A and B with same codebase. We usually do this for high available.

If A did some operation, CompensationContext of A will cache instance of service bean, than later it would be used in compensation call if error happens.

But if A crash, the coordinator (aka alpha) will call an backup service instance, which is B, to compensate. Although there is no cached instance of service bean in CompensationContext of B, so compensation fail.

We expect any instance of same service should process compensation successfully, if it doesn't, it is a bug."
SCB-407,Company Manager integration test failure ,"When running the integration test of manager-tests in [ServiceComb-Company-WorkShop |https://github.com/ServiceComb/ServiceComb-Company-WorkShop]1.x branch , we got the error here. 
{code:java}
2018-03-16 08:58:21,997 [ERROR]
Exception: org.apache.servicecomb.core.exception.CseException; No available address found. microserviceName=doorman, version=latest, discoveryGroupName=latest/
ServiceDefinitionException Code:cse.lb.no.available.address, Message:No available address found. microserviceName=doorman, version=latest, discoveryGroupName=latest/
at org.apache.servicecomb.core.exception.ExceptionUtils.createCseException(ExceptionUtils.java:57)
at org.apache.servicecomb.core.exception.ExceptionUtils.lbAddressNotFound(ExceptionUtils.java:88)
at org.apache.servicecomb.core.handler.impl.SimpleLoadBalanceHandler.handle(SimpleLoadBalanceHandler.java:64)
at org.apache.servicecomb.core.Invocation.next(Invocation.java:155)
at org.apache.servicecomb.core.handler.ShutdownHookHandler.handle(ShutdownHookHandler.java:68)
at org.apache.servicecomb.core.Invocation.next(Invocation.java:155)
at org.apache.servicecomb.core.provider.consumer.InvokerUtils.innerSyncInvoke(InvokerUtils.java:65)
at org.apache.servicecomb.provider.springmvc.reference.CseClientHttpRequest.doInvoke(CseClientHttpRequest.java:168)
at org.apache.servicecomb.provider.springmvc.reference.CseClientHttpRequest.invoke(CseClientHttpRequest.java:158)
at org.apache.servicecomb.provider.springmvc.reference.CseClientHttpRequest.execute(CseClientHttpRequest.java:119)
at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:652)
at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:613)
at org.springframework.web.client.RestTemplate.postForEntity(RestTemplate.java:407)
at org.apache.servicecomb.provider.springmvc.reference.RestTemplateWrapper.postForEntity(RestTemplateWrapper.java:130)
at org.apache.servicecomb.company.manager.AuthenticationService.validate(AuthenticationService.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.execute(MethodExecutionAction.java:116)
at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.executeWithArgs(MethodExecutionAction.java:93)
at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.execute(MethodExecutionAction.java:78)
at com.netflix.hystrix.contrib.javanica.command.GenericCommand$1.execute(GenericCommand.java:47)
at com.netflix.hystrix.contrib.javanica.command.AbstractHystrixCommand.process(AbstractHystrixCommand.java:145)
at com.netflix.hystrix.contrib.javanica.command.GenericCommand.run(GenericCommand.java:44)
{code}

Here are the log information before the exception is thrown
{code}
2018-03-16 08:58:21,704 [INFO] Flipping property: doorman.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 com.netflix.config.ChainedDynamicProperty$ChainLink.checkAndFlip(ChainedDynamicProperty.java:115)
2018-03-16 08:58:21,730 [INFO] Mapped URL path [/manager/**] onto handler of type [class org.springframework.cloud.netflix.zuul.web.ZuulController] org.springframework.web.servlet.handler.AbstractUrlHandlerMapping.registerHandler(AbstractUrlHandlerMapping.java:354)
2018-03-16 08:58:21,738 [INFO] Received request with query path: /doorman/rest/path/not/exist org.apache.servicecomb.company.manager.filters.AuthenticationAwareFilter.shouldFilter(AuthenticationAwareFilter.java:68)
2018-03-16 08:58:21,797 [INFO] Validating token eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJqb3JkYW4iLCJleHAiOjE1MjEyNDgzMDJ9.Y27L6MuVjF04nI40uGYbD7q4fliibh3ZM8wD40KC9hhLfdLG4sWjgCULAsDMedElooM_YnIKxWaHKXGxVyk3UQ org.apache.servicecomb.company.manager.AuthenticationService.validate(AuthenticationService.java:64)
2018-03-16 08:58:21,799 [INFO] create MicroserviceVersionRule, appId=company, microserviceName=doorman, versionRule=latest. org.apache.servicecomb.serviceregistry.consumer.MicroserviceVersions.createAndInitMicroserviceVersionRule(MicroserviceVersions.java:185)
2018-03-16 08:58:21,800 [INFO] add microserviceVersion, appId=company, microserviceName=doorman, version=0.0.1, versionRule=latest. org.apache.servicecomb.serviceregistry.consumer.MicroserviceVersionRule.addMicroserviceVersion(MicroserviceVersionRule.java:80)
2018-03-16 08:58:21,800 [INFO] set instances, appId=company, microserviceName=doorman, versionRule=latest, instanceId=19e6f52c28b511e8915b0242ac110003, endpoints=[rest://localhost:8080/]. org.apache.servicecomb.serviceregistry.consumer.MicroserviceVersionRule.lambda$setInstances$1(MicroserviceVersionRule.java:146)
2018-03-16 08:58:21,805 [INFO] load schema from service center, microservice=company:doorman:0.0.1, schemaId=authenticationRestEndpoint, result=true org.apache.servicecomb.core.definition.schema.ConsumerSchemaFactory.loadSwagger(ConsumerSchemaFactory.java:145)
2018-03-16 08:58:21,872 [INFO] register schema company/doorman/authenticationRestEndpoint org.apache.servicecomb.core.definition.loader.SchemaLoader.registerSchema(SchemaLoader.java:91)
2018-03-16 08:58:21,923 [INFO] generate org.apache.servicecomb.company.auth.endpoint.rest.Token in classLoader TomcatEmbeddedWebappClassLoader
  context: ROOT
  delegate: true
----------> Parent Classloader:
sun.misc.Launcher$AppClassLoader@4aa298b7
. org.apache.servicecomb.common.javassist.JavassistUtils.createClass(JavassistUtils.java:207)
2018-03-16 08:58:21,959 [INFO] generate cse.gen.company.doorman.authenticationRestEndpoint.AuthenticationControllerIntf in classLoader TomcatEmbeddedWebappClassLoader
  context: ROOT
  delegate: true
----------> Parent Classloader:
sun.misc.Launcher$AppClassLoader@4aa298b7
. org.apache.servicecomb.common.javassist.JavassistUtils.createClass(JavassistUtils.java:207)
2018-03-16 08:58:21,966 [INFO] found DiscoveryFilter: org.apache.servicecomb.serviceregistry.discovery.DiscoveryTree.sort(DiscoveryTree.java:53)
2018-03-16 08:58:21,967 [INFO] DiscoveryFilter org.apache.servicecomb.core.filter.EndpointDiscoveryFilter. org.apache.servicecomb.serviceregistry.discovery.DiscoveryTree.sort(DiscoveryTree.java:55)
2018-03-16 08:58:21,980 [INFO] add schema to service paths. company:doorman:authenticationRestEndpoint. org.apache.servicecomb.common.rest.locator.ServicePathManager.addSchema(ServicePathManager.java:91)
2018-03-16 08:58:21,981 [INFO] Found schema ids from service center, company:doorman:latest:[authenticationRestEndpoint] org.apache.servicecomb.core.definition.schema.ConsumerSchemaFactory.getOrCreateMicroserviceMeta(ConsumerSchemaFactory.java:102)
{code}",Bug,"Company Manager integration test failure  When running the integration test of manager-tests in [ServiceComb-Company-WorkShop |https://github.com/ServiceComb/ServiceComb-Company-WorkShop]1.x branch , we got the error here. 
{code:java}
2018-03-16 08:58:21,997 [ERROR]
Exception: org.apache.servicecomb.core.exception.CseException; No available address found. microserviceName=doorman, version=latest, discoveryGroupName=latest/
ServiceDefinitionException Code:cse.lb.no.available.address, Message:No available address found. microserviceName=doorman, version=latest, discoveryGroupName=latest/
at org.apache.servicecomb.core.exception.ExceptionUtils.createCseException(ExceptionUtils.java:57)
at org.apache.servicecomb.core.exception.ExceptionUtils.lbAddressNotFound(ExceptionUtils.java:88)
at org.apache.servicecomb.core.handler.impl.SimpleLoadBalanceHandler.handle(SimpleLoadBalanceHandler.java:64)
at org.apache.servicecomb.core.Invocation.next(Invocation.java:155)
at org.apache.servicecomb.core.handler.ShutdownHookHandler.handle(ShutdownHookHandler.java:68)
at org.apache.servicecomb.core.Invocation.next(Invocation.java:155)
at org.apache.servicecomb.core.provider.consumer.InvokerUtils.innerSyncInvoke(InvokerUtils.java:65)
at org.apache.servicecomb.provider.springmvc.reference.CseClientHttpRequest.doInvoke(CseClientHttpRequest.java:168)
at org.apache.servicecomb.provider.springmvc.reference.CseClientHttpRequest.invoke(CseClientHttpRequest.java:158)
at org.apache.servicecomb.provider.springmvc.reference.CseClientHttpRequest.execute(CseClientHttpRequest.java:119)
at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:652)
at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:613)
at org.springframework.web.client.RestTemplate.postForEntity(RestTemplate.java:407)
at org.apache.servicecomb.provider.springmvc.reference.RestTemplateWrapper.postForEntity(RestTemplateWrapper.java:130)
at org.apache.servicecomb.company.manager.AuthenticationService.validate(AuthenticationService.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.execute(MethodExecutionAction.java:116)
at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.executeWithArgs(MethodExecutionAction.java:93)
at com.netflix.hystrix.contrib.javanica.command.MethodExecutionAction.execute(MethodExecutionAction.java:78)
at com.netflix.hystrix.contrib.javanica.command.GenericCommand$1.execute(GenericCommand.java:47)
at com.netflix.hystrix.contrib.javanica.command.AbstractHystrixCommand.process(AbstractHystrixCommand.java:145)
at com.netflix.hystrix.contrib.javanica.command.GenericCommand.run(GenericCommand.java:44)
{code}

Here are the log information before the exception is thrown
{code}
2018-03-16 08:58:21,704 [INFO] Flipping property: doorman.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 com.netflix.config.ChainedDynamicProperty$ChainLink.checkAndFlip(ChainedDynamicProperty.java:115)
2018-03-16 08:58:21,730 [INFO] Mapped URL path [/manager/**] onto handler of type [class org.springframework.cloud.netflix.zuul.web.ZuulController] org.springframework.web.servlet.handler.AbstractUrlHandlerMapping.registerHandler(AbstractUrlHandlerMapping.java:354)
2018-03-16 08:58:21,738 [INFO] Received request with query path: /doorman/rest/path/not/exist org.apache.servicecomb.company.manager.filters.AuthenticationAwareFilter.shouldFilter(AuthenticationAwareFilter.java:68)
2018-03-16 08:58:21,797 [INFO] Validating token eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJqb3JkYW4iLCJleHAiOjE1MjEyNDgzMDJ9.Y27L6MuVjF04nI40uGYbD7q4fliibh3ZM8wD40KC9hhLfdLG4sWjgCULAsDMedElooM_YnIKxWaHKXGxVyk3UQ org.apache.servicecomb.company.manager.AuthenticationService.validate(AuthenticationService.java:64)
2018-03-16 08:58:21,799 [INFO] create MicroserviceVersionRule, appId=company, microserviceName=doorman, versionRule=latest. org.apache.servicecomb.serviceregistry.consumer.MicroserviceVersions.createAndInitMicroserviceVersionRule(MicroserviceVersions.java:185)
2018-03-16 08:58:21,800 [INFO] add microserviceVersion, appId=company, microserviceName=doorman, version=0.0.1, versionRule=latest. org.apache.servicecomb.serviceregistry.consumer.MicroserviceVersionRule.addMicroserviceVersion(MicroserviceVersionRule.java:80)
2018-03-16 08:58:21,800 [INFO] set instances, appId=company, microserviceName=doorman, versionRule=latest, instanceId=19e6f52c28b511e8915b0242ac110003, endpoints=[rest://localhost:8080/]. org.apache.servicecomb.serviceregistry.consumer.MicroserviceVersionRule.lambda$setInstances$1(MicroserviceVersionRule.java:146)
2018-03-16 08:58:21,805 [INFO] load schema from service center, microservice=company:doorman:0.0.1, schemaId=authenticationRestEndpoint, result=true org.apache.servicecomb.core.definition.schema.ConsumerSchemaFactory.loadSwagger(ConsumerSchemaFactory.java:145)
2018-03-16 08:58:21,872 [INFO] register schema company/doorman/authenticationRestEndpoint org.apache.servicecomb.core.definition.loader.SchemaLoader.registerSchema(SchemaLoader.java:91)
2018-03-16 08:58:21,923 [INFO] generate org.apache.servicecomb.company.auth.endpoint.rest.Token in classLoader TomcatEmbeddedWebappClassLoader
  context: ROOT
  delegate: true
----------> Parent Classloader:
sun.misc.Launcher$AppClassLoader@4aa298b7
. org.apache.servicecomb.common.javassist.JavassistUtils.createClass(JavassistUtils.java:207)
2018-03-16 08:58:21,959 [INFO] generate cse.gen.company.doorman.authenticationRestEndpoint.AuthenticationControllerIntf in classLoader TomcatEmbeddedWebappClassLoader
  context: ROOT
  delegate: true
----------> Parent Classloader:
sun.misc.Launcher$AppClassLoader@4aa298b7
. org.apache.servicecomb.common.javassist.JavassistUtils.createClass(JavassistUtils.java:207)
2018-03-16 08:58:21,966 [INFO] found DiscoveryFilter: org.apache.servicecomb.serviceregistry.discovery.DiscoveryTree.sort(DiscoveryTree.java:53)
2018-03-16 08:58:21,967 [INFO] DiscoveryFilter org.apache.servicecomb.core.filter.EndpointDiscoveryFilter. org.apache.servicecomb.serviceregistry.discovery.DiscoveryTree.sort(DiscoveryTree.java:55)
2018-03-16 08:58:21,980 [INFO] add schema to service paths. company:doorman:authenticationRestEndpoint. org.apache.servicecomb.common.rest.locator.ServicePathManager.addSchema(ServicePathManager.java:91)
2018-03-16 08:58:21,981 [INFO] Found schema ids from service center, company:doorman:latest:[authenticationRestEndpoint] org.apache.servicecomb.core.definition.schema.ConsumerSchemaFactory.getOrCreateMicroserviceMeta(ConsumerSchemaFactory.java:102)
{code}"
SCB-130,Update the Git PR template,We need to update the Git PR template with Apache ServiceComb JIRA.,Bug,Update the Git PR template We need to update the Git PR template with Apache ServiceComb JIRA.
